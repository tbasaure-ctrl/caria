# Auditor√≠a de Sistemas - Proyecto Caria
**Fecha**: 2025-11-11
**Estado**: Implementaci√≥n completa en progreso

---

## RESUMEN EJECUTIVO

Los 4 sistemas especializados est√°n **implementados y funcionales**, pero hay **mejoras cr√≠ticas** pendientes antes de producci√≥n. La arquitectura desacoplada funciona correctamente, pero algunos componentes necesitan refinamiento.

### Estado General
- ‚úÖ **Sistema I (HMM)**: Implementado, modelo entrenado, necesita mejoras en normalizaci√≥n
- ‚ö†Ô∏è **Sistema II (RAG)**: Implementado, necesita configuraci√≥n de pgvector y completar enriquecimiento
- ‚úÖ **Sistema III (Factores)**: Completamente implementado, listo para uso
- ‚ö†Ô∏è **Sistema IV (DCF)**: Implementado, necesita manejo de deuda neta y FCF negativo

---

## SISTEMA I: Motor de R√©gimen HMM

### Archivo: `src/caria/models/regime/hmm_regime_detector.py`

#### ‚úÖ Funcionalidades Correctas
- Implementaci√≥n completa de HMM no supervisado con `hmmlearn`
- 4 estados latentes: expansion, slowdown, recession, stress
- Features macro bien seleccionadas: yield_curve_slope, VIX, sentiment, credit_spread
- M√©todos save/load implementados correctamente
- Normalizaci√≥n z-score de features
- Predicci√≥n de reg√≠menes hist√≥ricos y actuales

#### ‚ö†Ô∏è PROBLEMAS IDENTIFICADOS

**P1.1 - CR√çTICO: Normalizaci√≥n inconsistente en predicci√≥n**
- **Ubicaci√≥n**: `predict_proba()` l√≠neas 223-225
- **Problema**: Normaliza usando estad√≠sticas de las features **actuales** en lugar de las del **entrenamiento**
```python
# ‚ùå INCORRECTO (l√≠nea 224)
feature_array = (feature_array - np.nanmean(feature_array)) / (np.nanstd(feature_array) + 1e-6)
```
- **Impacto**: Predicciones inconsistentes entre entrenamiento y producci√≥n
- **Soluci√≥n**: Guardar mean/std durante `fit()` y reutilizarlas en `predict_proba()`

**P1.2 - MEDIO: Mapeo hardcodeado de estados a reg√≠menes**
- **Ubicaci√≥n**: l√≠neas 236-241
- **Problema**: Asume orden fijo (0=expansion, 1=slowdown, 2=recession, 3=stress) sin validar caracter√≠sticas de cada estado
- **Soluci√≥n**: Analizar caracter√≠sticas de cada estado post-entrenamiento (means, covarianzas) para asignar etiquetas sem√°nticas din√°micamente

**P1.3 - MENOR: Validaci√≥n m√≠nima de features**
- **Problema**: Solo valida >= 2 features y >= 100 observaciones
- **Soluci√≥n**: Agregar validaci√≥n de calidad de datos (missing values, outliers)

#### üìã Recomendaciones de Mejora
1. Agregar persistencia de scaler (mean/std) junto con el modelo
2. Implementar an√°lisis autom√°tico de caracter√≠sticas de estados HMM
3. Agregar m√©tricas de confianza m√°s sofisticadas (entropy, transition probabilities)
4. Considerar HMM jer√°rquico (estados dentro de reg√≠menes)

---

## SISTEMA II: Servicio RAG (Socio Racional)

### Archivo: `src/caria/services/rag_service.py`

#### ‚úÖ Funcionalidades Correctas
- Estructura completa con embeddings, vector store, retriever
- Soporte para LLM local (Ollama + transformers como fallback)
- An√°lisis cr√≠tico con identificaci√≥n de sesgos
- Manejo graceful de errores (fallback a an√°lisis simple)
- Parsing estructurado de respuestas LLM

#### ‚ö†Ô∏è PROBLEMAS IDENTIFICADOS

**P2.1 - CR√çTICO: Enriquecimiento de consultas incompleto**
- **Ubicaci√≥n**: `enrich_query()` l√≠neas 90-103
- **Problema**: No carga fundamentals ni prices desde base de datos
```python
# TODO: Cargar fundamentals y prices desde base de datos (l√≠nea 91)
```
- **Impacto**: Contexto empobrecido para an√°lisis
- **Soluci√≥n**: Integrar con base de datos de fundamentals y prices

**P2.2 - MEDIO: B√∫squeda h√≠brida no implementada**
- **Ubicaci√≥n**: `_hybrid_search()` l√≠neas 105-126
- **Problema**: Solo hace b√∫squeda vectorial pura, sin filtros SQL
- **Soluci√≥n**: Implementar filtros SQL por ticker, fecha, themes en pgvector

**P2.3 - MENOR: Dependencia externa de pgvector**
- **Problema**: RAG completamente deshabilitado si PostgreSQL no est√° disponible
- **Soluci√≥n**: Implementar fallback a b√∫squeda local (FAISS, Chroma)

#### üìã Recomendaciones de Mejora
1. Implementar carga de datos estructurados (fundamentals, prices, macro)
2. Agregar filtros SQL en b√∫squeda h√≠brida
3. Implementar cach√© de embeddings para queries comunes
4. Agregar m√©tricas de calidad de respuestas (RAGAS)
5. Considerar re-ranking de chunks recuperados

---

## SISTEMA III: Motor de Factores Cuantitativos

### Archivo: `src/caria/models/factors/factor_screener.py`

#### ‚úÖ Funcionalidades Correctas
- Implementaci√≥n completa de 5 factores can√≥nicos
- Normalizaci√≥n por percentiles (rank-based)
- Cross-sectional ranking por fecha
- Pesos ajustables por factor
- `RegimeAwareFactorScreener` con pesos din√°micos por r√©gimen
- Composite score bien dise√±ado

#### ‚ö†Ô∏è PROBLEMAS IDENTIFICADOS

**P3.1 - MENOR: Validaci√≥n de columnas insuficiente**
- **Ubicaci√≥n**: M√©todos `_calculate_*_score()`
- **Problema**: Asume existencia de columnas espec√≠ficas sin validaci√≥n completa
- **Ejemplo**: `_calculate_momentum_score()` intenta calcular returns si no existe
- **Soluci√≥n**: Validar todas las columnas necesarias y dar warnings claros

**P3.2 - MENOR: Manejo de datos missing**
- **Problema**: `fillna(0.5)` puede introducir bias en ranking
- **Soluci√≥n**: Considerar exclusi√≥n de stocks con features faltantes o imputaci√≥n m√°s sofisticada

#### üìã Recomendaciones de Mejora
1. Agregar validaci√≥n exhaustiva de columnas requeridas
2. Implementar manejo robusto de missing values (imputaci√≥n, exclusi√≥n)
3. Agregar an√°lisis de feature importance (cu√°les factores dominan el ranking)
4. Considerar pesos adaptativos por sector/industria
5. Agregar backtesting de estrategia de factores

#### üéØ EXCELENTE DISE√ëO
- La separaci√≥n de factores individuales permite an√°lisis granular
- RegimeAwareFactorScreener es un dise√±o brillante que conecta Sistema I y III
- Rank normalization evita outliers dominando el score

---

## SISTEMA IV: Motor de Valuaci√≥n DCF

### Archivo: `src/caria/models/valuation/dcf_valuator.py`

#### ‚úÖ Funcionalidades Correctas
- Implementaci√≥n DCF completa con proyecci√≥n de FCF
- Ajuste din√°mico de WACC seg√∫n r√©gimen macro
- C√°lculo correcto de valor terminal
- Generaci√≥n de explicaciones interpretables
- Soporte para proyecciones de NLP (Sistema II)

#### ‚ö†Ô∏è PROBLEMAS IDENTIFICADOS

**P4.1 - MEDIO: Simplificaci√≥n excesiva de deuda**
- **Ubicaci√≥n**: l√≠nea 149
- **Problema**: Asume sin deuda neta
```python
# Valor por acci√≥n (asumiendo sin deuda neta por simplicidad)
fair_value_per_share = enterprise_value / shares_outstanding
```
- **Impacto**: Valuaciones incorrectas para empresas con deuda significativa
- **Soluci√≥n**: Incorporar net debt y cash en el c√°lculo

**P4.2 - MEDIO: No maneja FCF negativo**
- **Problema**: Si `current_fcf` es negativo, proyecciones son incorrectas
- **Soluci√≥n**: Validar FCF positivo o usar metodolog√≠a alternativa (revenue multiple)

**P4.3 - MENOR: Terminal growth fijo**
- **Problema**: 3% puede ser alto para algunas industrias o bajo para otras
- **Soluci√≥n**: Ajustar terminal growth por industria o r√©gimen

#### üìã Recomendaciones de Mejora
1. Agregar c√°lculo de Enterprise Value ‚Üí Equity Value (- debt + cash)
2. Implementar validaci√≥n de FCF y metodolog√≠as alternativas para FCF negativo
3. Ajustar terminal growth por industria/r√©gimen
4. Agregar an√°lisis de sensibilidad (WACC ¬±1%, growth ¬±1%)
5. Implementar DCF con m√∫ltiples escenarios (bull/base/bear)

---

## AUDITOR√çA DE DATOS

### Data Silver
‚úÖ `data/silver/macro/` - Datos macro procesados
‚úÖ `data/silver/regime/` - Predicciones de r√©gimen HMM

### Data Gold
‚úÖ `data/gold/train.parquet` - Dataset de entrenamiento
‚úÖ `data/gold/val.parquet` - Dataset de validaci√≥n
‚úÖ `data/gold/test.parquet` - Dataset de prueba
‚úÖ `data/gold/metadata/` - Metadatos

### Modelos
‚úÖ `models/regime_hmm_model.pkl` - Modelo HMM entrenado
‚ö†Ô∏è Modelos legacy (quality_model.pkl, momentum_model.pkl, etc.) - **DEPRECATED**

---

## AUDITOR√çA DE API

### Archivo: `services/api/app.py`

#### ‚úÖ Funcionalidades Correctas
- FastAPI bien estructurada con 4 routers
- Inicializaci√≥n de todos los servicios (Regime, Factor, Valuation)
- Manejo graceful de errores (servicios opcionales)
- Healthcheck endpoint completo
- Path resolution correcto entre services/ y caria_data/

#### ‚ö†Ô∏è OBSERVACIONES
- RAG opcional (no bloquea API si PostgreSQL no disponible)
- Modelo legacy opcional (CARIA_MODEL_CHECKPOINT)

---

## PRIORIDADES DE CORRECCI√ìN

### üî¥ CR√çTICAS (Antes de producci√≥n)
1. **P1.1**: Normalizaci√≥n inconsistente en HMM (Sistema I)
2. **P2.1**: Enriquecimiento de consultas incompleto (Sistema II)
3. **P4.1**: Incorporar deuda neta en DCF (Sistema IV)

### üü° IMPORTANTES (Corto plazo)
4. **P1.2**: Mapeo autom√°tico de estados HMM
5. **P2.2**: B√∫squeda h√≠brida SQL + vectorial
6. **P4.2**: Manejo de FCF negativo
7. **P3.1**: Validaci√≥n de columnas en factores

### üü¢ MEJORAS (Mediano plazo)
8. An√°lisis de feature importance en factores
9. An√°lisis de sensibilidad en DCF
10. Cach√© de embeddings en RAG
11. Fallback local para RAG sin PostgreSQL

---

## CONCLUSI√ìN

**Estado General**: ‚úÖ BUENO - Arquitectura s√≥lida, implementaci√≥n funcional

**Listo para desarrollo**: ‚úÖ S√ç
**Listo para producci√≥n**: ‚ö†Ô∏è NO (necesita correcciones cr√≠ticas)

### Siguientes Pasos Recomendados
1. Corregir P1.1 (normalizaci√≥n HMM) - **30 minutos**
2. Completar P2.1 (enriquecimiento RAG) - **2 horas**
3. Corregir P4.1 (deuda neta DCF) - **1 hora**
4. Levantar API y probar endpoints - **1 hora**
5. Configurar pgvector y cargar embeddings - **2 horas**

**Tiempo estimado para correcciones cr√≠ticas**: 6-8 horas
