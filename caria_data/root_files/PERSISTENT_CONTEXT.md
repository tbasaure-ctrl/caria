# PERSISTENT CONTEXT ‚Äî Wise Adviser

Este archivo debe ser incluido en cada sesi√≥n de Cursor para mantener contexto.

## Visi√≥n General

**Wise Adviser** es tu compa√±ero racional de inversi√≥n. No predice precios, te ayuda a pensar claramente combinando:

1. **An√°lisis Cuantitativo**: DCF, m√∫ltiplos, reverse DCF
2. **Contexto Macro**: R√©gimen de mercado (normal, crisis, mania, QE)
3. **Se√±ales Micro**: Calidad de negocio (ROIC, reinversi√≥n)
4. **Sabidur√≠a Hist√≥rica**: 9,500 chunks de Graham, Buffett, Fisher, Marks
5. **Detecci√≥n de Sesgos**: FOMO, confirmation bias, recency bias

## Objetivos del Sistema

- ‚úÖ Valuaci√≥n fundamentada (DCF + m√∫ltiplos)
- ‚úÖ Contexto de r√©gimen (macro environment)
- ‚úÖ Sabidur√≠a aplicable (RAG retrieval)
- ‚úÖ Preguntas reflexivas (challenge assumptions)
- ‚úÖ Detecci√≥n de sesgos (behavioral finance)

## Archivos Cr√≠ticos (Prioridad para Indexar)

### Must-Read (Cursor debe leer siempre)
1. `AI_CONTEXT.md` ‚Äî Arquitectura, convenciones, prompts
2. `data_schema/schema.yaml` ‚Äî Estructura de datos
3. `data_schema/data_dictionary.csv` ‚Äî Diccionario de campos

### C√≥digo Core
4. `src/valuation/valuation_engine.py` ‚Äî Motor de valuaci√≥n
5. `src/models/wise_adviser_model.py` ‚Äî Modelo principal
6. `src/models/encoders.py` ‚Äî Encoders multi-modales
7. `src/retrieval/mcp_server.py` ‚Äî RAG server
8. `scripts/embed_and_index.py` ‚Äî Pipeline de embeddings

### Notebooks de Referencia
9. `notebooks/eda_valuation.ipynb` ‚Äî Exploraci√≥n de valuaci√≥n
10. `notebooks/wisdom_embedding_test.ipynb` ‚Äî Tests de embeddings

## Workflow T√≠pico

### An√°lisis de un Ticker
```
Usuario: "Analiza NVDA"
  ‚Üì
1. Valuation Engine ‚Üí DCF + m√∫ltiplos
2. MCP Search ‚Üí Wisdom chunks (themes: [valuation, risk])
3. Regime Detection ‚Üí Contexto macro actual
4. Bias Check ‚Üí Detectar FOMO/overconfidence
5. Reflexive Output ‚Üí N√∫meros + Sabidur√≠a + Preguntas
```

### Agregar Nueva Sabidur√≠a
```
1. Editar: raw/chunks/wisdom_corpus_unified.jsonl
2. Ejecutar: python scripts/embed_and_index.py
3. Verificar: Query MCP /search con nuevo tema
```

### Entrenar Modelo
```
1. Preparar datos: scripts/01_download_data.py
2. Feature engineering: src/features/
3. Entrenar: scripts/02_train_model.py --epochs 50
4. Evaluar: notebooks/model_evaluation.ipynb
```

## Reglas para Cursor (IMPORTANTE)

### üî¥ Nunca hacer sin confirmar:
- Ejecutar scripts que modifiquen datos
- Entrenar modelos (consume tiempo/GPU)
- Modificar schema sin migration
- Eliminar checkpoints

### üü¢ Siempre hacer:
- Leer AI_CONTEXT.md antes de modificar c√≥digo
- Verificar point-in-time correctness en features
- Agregar tests para nuevas funcionalidades
- Documentar cambios en schema
- Usar @Folders para incluir contexto relevante

### üü° Preguntar antes:
- Refactorings grandes
- Cambios en arquitectura del modelo
- Nuevas dependencias externas

## Prompts Est√°ndar (Copiar/Pegar)

### An√°lisis Completo de Ticker
```
@Folders: src/valuation/, data_schema/

Analiza {TICKER} usando:
1. Valuaci√≥n (DCF + m√∫ltiplos) de valuation_engine.py
2. Wisdom retrieval (MCP search con themes: [valuation, discipline])
3. R√©gimen actual (si modelo entrenado)
4. Preguntas reflexivas

Output: Resumen ejecutivo con n√∫meros + sabidur√≠a + verdict
```

### Refactoring con Tests
```
@Folders: src/features/, tests/

Refactoriza {MODULO} para:
1. Separar concerns (ingestion vs processing)
2. Mejorar testability
3. Mantener backward compatibility

Proponer cambios como PR con tests incluidos.
```

### Debug de Embeddings
```
@Folders: scripts/, infrastructure/mcp_server/

El MCP search no retorna resultados esperados para query: "{QUERY}"

Debug:
1. Verificar embedding generation en embed_and_index.py
2. Check √≠ndice en pgvector (SELECT COUNT(*) FROM wisdom_chunks)
3. Test filters en MCP /search endpoint
4. Revisar similarity threshold
```

## Estado Actual del Proyecto

### ‚úÖ Completado
- [ ] Estructura base del repo
- [ ] Valuaci√≥n (DCF + m√∫ltiplos)
- [ ] Wisdom corpus (9.5K chunks)
- [ ] Schema de datos definido
- [ ] Docker compose setup

### üîÑ En Progreso
- [ ] Embeddings indexados en pgvector
- [ ] MCP server funcional
- [ ] Feature engineering completo
- [ ] Tests de integraci√≥n

### ‚è≥ Pendiente
- [ ] Modelo entrenado (encoders + fusion)
- [ ] Regime detection en producci√≥n
- [ ] Backtesting framework
- [ ] UI web

## Datos Sensibles (NO commitear)

Variables en `.env` (template en `.env.example`):
- `FMP_API_KEY` ‚Äî Financial Modeling Prep
- `FRED_API_KEY` ‚Äî Federal Reserve data
- `OPENAI_API_KEY` ‚Äî Para embeddings
- `POSTGRES_PASSWORD` ‚Äî DB password

## Comandos √ötiles

### Setup Inicial
```bash
# Instalar dependencias
poetry install

# Levantar infraestructura
cd infrastructure && docker-compose up -d

# Verificar DB
psql -h localhost -U wise_user -d wise_adviser_db -c "SELECT COUNT(*) FROM wisdom_chunks;"

# Generar embeddings
python scripts/embed_and_index.py --input raw/chunks/
```

### Testing
```bash
# Tests completos
pytest tests/ -v --cov=src

# Test espec√≠fico
pytest tests/test_valuation_engine.py -v

# Test de point-in-time
pytest tests/test_point_in_time.py -v
```

### Debugging
```bash
# Logs de entrenamiento
tail -f models/logs/training_latest.log

# Health check MCP server
curl http://localhost:8000/health

# Test MCP search
curl -X POST http://localhost:8000/search \
  -H "Content-Type: application/json" \
  -d '{"query": "valuation margin of safety", "top_k": 5}'
```

## Contacto y Soporte

Para issues o preguntas:
- Check `docs/FAQ.md`
- Review `notebooks/troubleshooting.ipynb`
- Ver logs en `models/logs/`

---

**Este archivo debe estar siempre abierto en Cursor** para mantener contexto persistente.

√öltima actualizaci√≥n: 2025-01-07
