{"cells":[{"cell_type":"markdown","metadata":{"id":"4wSZi89WPxdr"},"source":["# Entrenamiento Mejorado de Modelos Caria\n","\n","Este notebook entrena los modelos mejorados con:\n","- **Quality Model**: Percentiles por fecha (identifica outliers incluso en mala economía)\n","- **Valuation Model**: DCF/Múltiplos con target de precio futuro 5 años\n","- **Momentum Model**: Features mejoradas (volumen, SMAs 200/50, RSI)\n","\n","Incluye descarga de datos FRED (macro, commodities, currencies) y feature engineering completo.\n"]},{"cell_type":"markdown","metadata":{"id":"WLFLq5nWPxdu"},"source":["## 1. Instalar Dependencias\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"Q28-QyhuPxdv","executionInfo":{"status":"ok","timestamp":1762836614009,"user_tz":180,"elapsed":4735,"user":{"displayName":"Tomas Basaure","userId":"13858564830784637150"}}},"outputs":[],"source":["# Instalar dependencias necesarias\n","!pip install -q pandas numpy scikit-learn xgboost lightgbm joblib pyarrow pyyaml fredapi python-dotenv\n"]},{"cell_type":"markdown","metadata":{"id":"z11vKIpTPxdw"},"source":["## 2. Montar Google Drive y Configurar Rutas\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"htHhx8-PPxdw","executionInfo":{"status":"ok","timestamp":1762836646990,"user_tz":180,"elapsed":32951,"user":{"displayName":"Tomas Basaure","userId":"13858564830784637150"}},"outputId":"913defb3-76e7-4191-9a49-aa7f292ce335"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","✓ Estructura creada en: /content/caria_workspace\n","✓ Ruta Drive encontrada: /content/drive/MyDrive/caria_data\n"]}],"source":["from google.colab import drive\n","import os\n","from pathlib import Path\n","\n","# Montar Google Drive\n","drive.mount('/content/drive')\n","\n","# Configurar ruta base donde están tus datos\n","# AJUSTA ESTA RUTA según donde subiste los archivos en Drive\n","DRIVE_BASE_PATH = '/content/drive/MyDrive/caria_data'  # Cambia esto a tu ruta\n","\n","# Crear estructura de directorios en Colab\n","BASE_DIR = Path('/content/caria_workspace')\n","BASE_DIR.mkdir(exist_ok=True)\n","\n","# Directorios necesarios\n","(BASE_DIR / 'data' / 'gold').mkdir(parents=True, exist_ok=True)\n","(BASE_DIR / 'data' / 'silver' / 'macro').mkdir(parents=True, exist_ok=True)\n","(BASE_DIR / 'models').mkdir(parents=True, exist_ok=True)\n","(BASE_DIR / 'artifacts' / 'models').mkdir(parents=True, exist_ok=True)\n","\n","print(f\"✓ Estructura creada en: {BASE_DIR}\")\n","\n","# Verificar que existe Drive\n","if os.path.exists(DRIVE_BASE_PATH):\n","    print(f\"✓ Ruta Drive encontrada: {DRIVE_BASE_PATH}\")\n","else:\n","    print(f\"⚠ Ruta Drive no encontrada: {DRIVE_BASE_PATH}\")\n","    print(\"Por favor ajusta DRIVE_BASE_PATH a la ubicación de tus datos\")\n"]},{"cell_type":"markdown","metadata":{"id":"uBEozkxgPxdy"},"source":["## 3. Configurar FRED API Key\n","\n","Necesitas una API key gratuita de FRED: https://fred.stlouisfed.org/docs/api/api_key.html\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wessgYxMPxdy","executionInfo":{"status":"ok","timestamp":1762836647018,"user_tz":180,"elapsed":17,"user":{"displayName":"Tomas Basaure","userId":"13858564830784637150"}},"outputId":"6e7cc4f0-b432-41c8-c67e-1a6376e46f5a"},"outputs":[{"output_type":"stream","name":"stdout","text":["✓ FRED API Key configurada\n"]}],"source":["# Configurar tu FRED API key aquí\n","# Obtén una gratis en: https://fred.stlouisfed.org/docs/api/api_key.html\n","FRED_API_KEY = \"4b90ca15ff28cfec137179c22fd8246d\"  # Pega tu API key aquí\n","\n","if not FRED_API_KEY:\n","    print(\"⚠ Por favor configura FRED_API_KEY en la celda anterior\")\n","else:\n","    print(\"✓ FRED API Key configurada\")\n","    os.environ[\"FRED_API_KEY\"] = FRED_API_KEY\n"]},{"cell_type":"markdown","metadata":{"id":"woVoBqtpPxdz"},"source":["## 4. Descargar Datos FRED (Macro, Commodities, Currencies)\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r6Pec2iMPxdz","executionInfo":{"status":"ok","timestamp":1762836678633,"user_tz":180,"elapsed":31568,"user":{"displayName":"Tomas Basaure","userId":"13858564830784637150"}},"outputId":"f7abc978-55b1-4b5f-e84b-32a07dfe4ce6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Descargando datos desde FRED...\n","  Descargando GDPC1 (GDP Real)...\n","    ✓ 314 observaciones desde 1947-01-01 00:00:00 hasta 2025-04-01 00:00:00\n","  Descargando CPIAUCSL (CPI)...\n","    ✓ 945 observaciones desde 1947-01-01 00:00:00 hasta 2025-09-01 00:00:00\n","  Descargando UNRATE (Unemployment Rate)...\n","    ✓ 932 observaciones desde 1948-01-01 00:00:00 hasta 2025-08-01 00:00:00\n","  Descargando FEDFUNDS (Fed Funds Rate)...\n","    ✓ 856 observaciones desde 1954-07-01 00:00:00 hasta 2025-10-01 00:00:00\n","  Descargando DGS10 (10Y Treasury)...\n","    ✓ 16659 observaciones desde 1962-01-02 00:00:00 hasta 2025-11-07 00:00:00\n","  Descargando DGS2 (2Y Treasury)...\n","    ✓ 12899 observaciones desde 1976-06-01 00:00:00 hasta 2025-11-07 00:00:00\n","  Descargando MANPMI (PMI Manufacturing)...\n","  [ERROR] MANPMI: Bad Request.  The series does not exist.\n","    ⚠ Sin datos disponibles\n","  Descargando UMCSENT (Consumer Sentiment)...\n","    ✓ 875 observaciones desde 1952-11-01 00:00:00 hasta 2025-09-01 00:00:00\n","  Descargando GOLDAMGBD228NLBM (Gold)...\n","  [ERROR] GOLDAMGBD228NLBM: Bad Request.  The series does not exist.\n","    ⚠ Sin datos disponibles\n","  Descargando PSLVAMUSD (Silver)...\n","  [ERROR] PSLVAMUSD: Bad Request.  The series does not exist.\n","    ⚠ Sin datos disponibles\n","  Descargando PCOPPUSDM (Copper)...\n","    ✓ 546 observaciones desde 1980-01-01 00:00:00 hasta 2025-06-01 00:00:00\n","  Descargando PNICKUSDM (Nickel)...\n","    ✓ 546 observaciones desde 1980-01-01 00:00:00 hasta 2025-06-01 00:00:00\n","  Descargando PALUMUSDM (Aluminum)...\n","    ✓ 546 observaciones desde 1980-01-01 00:00:00 hasta 2025-06-01 00:00:00\n","  Descargando DCOILWTICO (Crude Oil WTI)...\n","    ✓ 10393 observaciones desde 1986-01-02 00:00:00 hasta 2025-11-03 00:00:00\n","  Descargando PNRGINDEXM (Natural Gas)...\n","    ✓ 402 observaciones desde 1992-01-01 00:00:00 hasta 2025-06-01 00:00:00\n","  Descargando DHOILNYH (Heating Oil)...\n","    ✓ 10286 observaciones desde 1986-06-02 00:00:00 hasta 2025-11-03 00:00:00\n","  Descargando PWHEAMTUSDM (Wheat)...\n","    ✓ 546 observaciones desde 1980-01-01 00:00:00 hasta 2025-06-01 00:00:00\n","  Descargando PSOYABUSDM (Soybeans)...\n","  [ERROR] PSOYABUSDM: Bad Request.  The series does not exist.\n","    ⚠ Sin datos disponibles\n","  Descargando PCOFFOTMUSDM (Coffee)...\n","    ✓ 546 observaciones desde 1980-01-01 00:00:00 hasta 2025-06-01 00:00:00\n","  Descargando PSUGAISAUSDM (Sugar)...\n","    ✓ 546 observaciones desde 1980-01-01 00:00:00 hasta 2025-06-01 00:00:00\n","  Descargando DEXUSEU (EUR/USD)...\n","    ✓ 7005 observaciones desde 1999-01-04 00:00:00 hasta 2025-11-07 00:00:00\n","  Descargando DEXCHUS (CNY/USD)...\n","    ✓ 11701 observaciones desde 1981-01-02 00:00:00 hasta 2025-11-07 00:00:00\n","  Descargando DEXJPUS (JPY/USD)...\n","    ✓ 14310 observaciones desde 1971-01-04 00:00:00 hasta 2025-11-07 00:00:00\n","  Descargando DEXUSUK (GBP/USD)...\n","    ✓ 14310 observaciones desde 1971-01-04 00:00:00 hasta 2025-11-07 00:00:00\n","  Descargando DEXCAUS (CAD/USD)...\n","    ✓ 14310 observaciones desde 1971-01-04 00:00:00 hasta 2025-11-07 00:00:00\n","  Descargando DEXMXUS (MXN/USD)...\n","    ✓ 8350 observaciones desde 1993-11-08 00:00:00 hasta 2025-11-07 00:00:00\n","  Descargando DTWEXBGS (Dollar Index Broad)...\n","    ✓ 5180 observaciones desde 2006-01-02 00:00:00 hasta 2025-11-07 00:00:00\n","  Descargando DTWEXEMEGS (Dollar Index EM)...\n","    ✓ 5180 observaciones desde 2006-01-02 00:00:00 hasta 2025-11-07 00:00:00\n","  Descargando BAA10Y (BAA-10Y Spread)...\n","    ✓ 10397 observaciones desde 1986-01-02 00:00:00 hasta 2025-11-07 00:00:00\n","  Descargando AAA (AAA Corporate Yield)...\n","    ✓ 1282 observaciones desde 1919-01-01 00:00:00 hasta 2025-10-01 00:00:00\n","  Descargando BAA (BAA Corporate Yield)...\n","    ✓ 1282 observaciones desde 1919-01-01 00:00:00 hasta 2025-10-01 00:00:00\n","\n","✓ Datos FRED guardados: /content/caria_workspace/data/silver/macro/fred_data.parquet\n","  Columnas: 28, Filas: 39028\n","✓ Copiado a Drive: /content/drive/MyDrive/caria_data/data/silver/macro/fred_data.parquet\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from datetime import datetime\n","from fredapi import Fred\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Series FRED a descargar (expandido con commodities y currencies)\n","FRED_SERIES = {\n","    # Macro\n","    \"GDPC1\": \"GDP Real\",\n","    \"CPIAUCSL\": \"CPI\",\n","    \"UNRATE\": \"Unemployment Rate\",\n","    \"FEDFUNDS\": \"Fed Funds Rate\",\n","    \"DGS10\": \"10Y Treasury\",\n","    \"DGS2\": \"2Y Treasury\",\n","    \"MANPMI\": \"PMI Manufacturing\",\n","    \"UMCSENT\": \"Consumer Sentiment\",\n","    # Commodities - Metales\n","    \"GOLDAMGBD228NLBM\": \"Gold\",\n","    \"PSLVAMUSD\": \"Silver\",\n","    \"PCOPPUSDM\": \"Copper\",\n","    \"PNICKUSDM\": \"Nickel\",\n","    \"PALUMUSDM\": \"Aluminum\",\n","    # Commodities - Energía\n","    \"DCOILWTICO\": \"Crude Oil WTI\",\n","    \"PNRGINDEXM\": \"Natural Gas\",\n","    \"DHOILNYH\": \"Heating Oil\",\n","    # Commodities - Agrícolas\n","    \"PWHEAMTUSDM\": \"Wheat\",\n","    \"PSOYABUSDM\": \"Soybeans\",\n","    \"PCOFFOTMUSDM\": \"Coffee\",\n","    \"PSUGAISAUSDM\": \"Sugar\",\n","    # Currencies\n","    \"DEXUSEU\": \"EUR/USD\",\n","    \"DEXCHUS\": \"CNY/USD\",\n","    \"DEXJPUS\": \"JPY/USD\",\n","    \"DEXUSUK\": \"GBP/USD\",\n","    \"DEXCAUS\": \"CAD/USD\",\n","    \"DEXMXUS\": \"MXN/USD\",\n","    \"DTWEXBGS\": \"Dollar Index Broad\",\n","    \"DTWEXEMEGS\": \"Dollar Index EM\",\n","    # Credit spreads\n","    \"BAA10Y\": \"BAA-10Y Spread\",\n","    \"AAA\": \"AAA Corporate Yield\",\n","    \"BAA\": \"BAA Corporate Yield\",\n","}\n","\n","def download_fred_series(fred, series_id, start_date=\"1900-01-01\"):\n","    \"\"\"Descarga una serie de FRED.\"\"\"\n","    try:\n","        data = fred.get_series(series_id, observation_start=start_date)\n","        if data.empty:\n","            return pd.DataFrame()\n","        df = pd.DataFrame({\"date\": data.index, series_id: data.values})\n","        df[\"date\"] = pd.to_datetime(df[\"date\"])\n","        return df.sort_values(\"date\").reset_index(drop=True)\n","    except Exception as e:\n","        print(f\"  [ERROR] {series_id}: {e}\")\n","        return pd.DataFrame()\n","\n","# Descargar datos FRED\n","print(\"Descargando datos desde FRED...\")\n","fred = Fred(api_key=FRED_API_KEY)\n","\n","all_dataframes = []\n","for series_id, description in FRED_SERIES.items():\n","    print(f\"  Descargando {series_id} ({description})...\")\n","    df = download_fred_series(fred, series_id)\n","    if not df.empty:\n","        all_dataframes.append(df)\n","        print(f\"    ✓ {len(df)} observaciones desde {df['date'].min()} hasta {df['date'].max()}\")\n","    else:\n","        print(f\"    ⚠ Sin datos disponibles\")\n","\n","# Combinar todas las series\n","if all_dataframes:\n","    merged = all_dataframes[0]\n","    for df in all_dataframes[1:]:\n","        merged = merged.merge(df, on=\"date\", how=\"outer\")\n","\n","    merged = merged.sort_values(\"date\").reset_index(drop=True)\n","\n","    # Resamplear a frecuencia diaria (forward-fill)\n","    date_range = pd.date_range(start=merged['date'].min(), end=merged['date'].max(), freq='D')\n","    merged_daily = pd.DataFrame(index=date_range)\n","    merged_daily = merged_daily.join(merged.set_index('date'), how='left')\n","    merged_daily = merged_daily.ffill()  # Fixed: usar ffill() en lugar de ffill() deprecado\n","    merged_daily = merged_daily.reset_index()\n","    merged_daily = merged_daily.rename(columns={'index': 'date'})\n","\n","    # Guardar\n","    output_path = BASE_DIR / 'data' / 'silver' / 'macro' / 'fred_data.parquet'\n","    merged_daily.to_parquet(output_path, index=False)\n","    print(f\"\\n✓ Datos FRED guardados: {output_path}\")\n","    print(f\"  Columnas: {len(merged_daily.columns)}, Filas: {len(merged_daily)}\")\n","\n","    # También copiar a Drive\n","    drive_macro_path = Path(DRIVE_BASE_PATH) / 'data' / 'silver' / 'macro'\n","    drive_macro_path.mkdir(parents=True, exist_ok=True)\n","    merged_daily.to_parquet(drive_macro_path / 'fred_data.parquet', index=False)\n","    print(f\"✓ Copiado a Drive: {drive_macro_path / 'fred_data.parquet'}\")\n","else:\n","    print(\"⚠ No se descargaron datos FRED\")\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BTpL-lV1Pxdz","executionInfo":{"status":"ok","timestamp":1762836678655,"user_tz":180,"elapsed":18,"user":{"displayName":"Tomas Basaure","userId":"13858564830784637150"}},"outputId":"d9c0db34-53fd-4931-a5b5-46b007d7c663"},"outputs":[{"output_type":"stream","name":"stdout","text":["✓ Función encode_categorical_features definida\n"]}],"source":["# Función helper para codificar variables categóricas (debe estar disponible globalmente)\n","def encode_categorical_features(df_train, df_val, df_test, features):\n","    \"\"\"Codifica variables categóricas usando label encoding.\"\"\"\n","    from sklearn.preprocessing import LabelEncoder\n","\n","    df_train = df_train[features].copy()\n","    df_val = df_val[features].copy()\n","    df_test = df_test[features].copy()\n","\n","    # Identificar columnas categóricas (object o string)\n","    categorical_cols = []\n","    for col in features:\n","        if col in df_train.columns:\n","            if df_train[col].dtype == 'object' or df_train[col].dtype.name == 'category':\n","                categorical_cols.append(col)\n","\n","    # Codificar variables categóricas\n","    label_encoders = {}\n","    for col in categorical_cols:\n","        le = LabelEncoder()\n","        # Entrenar con train + val + test para tener todos los valores posibles\n","        all_values = pd.concat([df_train[col], df_val[col], df_test[col]], axis=0).dropna().astype(str)\n","        le.fit(all_values.unique())\n","        label_encoders[col] = le\n","\n","        # Transformar cada dataset\n","        df_train[col] = df_train[col].astype(str).map(lambda x: le.transform([x])[0] if x in le.classes_ else 0)\n","        df_val[col] = df_val[col].astype(str).map(lambda x: le.transform([x])[0] if x in le.classes_ else 0)\n","        df_test[col] = df_test[col].astype(str).map(lambda x: le.transform([x])[0] if x in le.classes_ else 0)\n","\n","    if categorical_cols:\n","        print(f\"  Variables categóricas codificadas: {categorical_cols}\")\n","\n","    return df_train, df_val, df_test\n","\n","print(\"✓ Función encode_categorical_features definida\")\n"]},{"cell_type":"markdown","metadata":{"id":"2cLbcTGkPxd0"},"source":["## 5. Feature Engineering Macro\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jl-urV9yPxd0","executionInfo":{"status":"ok","timestamp":1762836678753,"user_tz":180,"elapsed":85,"user":{"displayName":"Tomas Basaure","userId":"13858564830784637150"}},"outputId":"c5a5ecbd-0f1b-49b4-f188-8c5819f146c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Calculando features macro...\n","✓ Features macro guardadas: /content/caria_workspace/data/silver/macro/macro_features.parquet\n","  Features creadas: 26 nuevas columnas\n"]}],"source":["# Cargar datos FRED\n","macro_df = pd.read_parquet(BASE_DIR / 'data' / 'silver' / 'macro' / 'fred_data.parquet')\n","\n","# Calcular features macro cíclicas\n","print(\"Calculando features macro...\")\n","\n","# Yield curve slope\n","if \"DGS10\" in macro_df.columns and \"DGS2\" in macro_df.columns:\n","    macro_df[\"yield_curve_slope\"] = macro_df[\"DGS10\"] - macro_df[\"DGS2\"]\n","    macro_df[\"yield_curve_inverted\"] = (macro_df[\"yield_curve_slope\"] < 0).astype(int)\n","\n","# Credit spread\n","if \"BAA\" in macro_df.columns and \"AAA\" in macro_df.columns:\n","    macro_df[\"credit_spread\"] = macro_df[\"BAA\"] - macro_df[\"AAA\"]\n","elif \"DGS10\" in macro_df.columns:\n","    macro_df[\"credit_spread\"] = macro_df[\"DGS10\"] * 0.02\n","\n","# Recession probability\n","macro_df[\"recession_probability\"] = 0.0\n","if \"MANPMI\" in macro_df.columns:\n","    macro_df[\"pmi_below_50\"] = (macro_df[\"MANPMI\"] < 50).astype(int)\n","    macro_df[\"recession_probability\"] += macro_df[\"pmi_below_50\"] * 0.3\n","if \"UNRATE\" in macro_df.columns:\n","    macro_df[\"unemployment_change\"] = macro_df[\"UNRATE\"].diff()\n","    macro_df[\"unemployment_rising\"] = (macro_df[\"unemployment_change\"] > 0.5).astype(int)\n","    macro_df[\"recession_probability\"] += macro_df[\"unemployment_rising\"] * 0.3\n","if \"yield_curve_inverted\" in macro_df.columns:\n","    macro_df[\"recession_probability\"] += macro_df[\"yield_curve_inverted\"] * 0.4\n","macro_df[\"recession_probability\"] = np.clip(macro_df[\"recession_probability\"], 0, 1)\n","\n","# Macro regime\n","macro_df[\"macro_regime\"] = \"expansion\"\n","macro_df.loc[macro_df[\"recession_probability\"] > 0.5, \"macro_regime\"] = \"recession\"\n","macro_df.loc[(macro_df[\"recession_probability\"] > 0.3) & (macro_df[\"recession_probability\"] <= 0.5), \"macro_regime\"] = \"slowdown\"\n","\n","# Commodity momentum\n","commodity_cols = [\"GOLDAMGBD228NLBM\", \"PSLVAMUSD\", \"DCOILWTICO\", \"PCOPPUSDM\"]\n","for col in commodity_cols:\n","    if col in macro_df.columns:\n","        macro_df[f\"{col}_momentum_3m\"] = macro_df[col].pct_change(periods=63)\n","        macro_df[f\"{col}_momentum_12m\"] = macro_df[col].pct_change(periods=252)\n","\n","# Commodity ratios\n","if \"GOLDAMGBD228NLBM\" in macro_df.columns and \"DCOILWTICO\" in macro_df.columns:\n","    macro_df[\"gold_oil_ratio\"] = macro_df[\"GOLDAMGBD228NLBM\"] / (macro_df[\"DCOILWTICO\"] + 1e-6)\n","    macro_df[\"risk_aversion_indicator\"] = (macro_df[\"gold_oil_ratio\"] > macro_df[\"gold_oil_ratio\"].rolling(252).mean()).astype(int)\n","\n","if \"PCOPPUSDM\" in macro_df.columns and \"GOLDAMGBD228NLBM\" in macro_df.columns:\n","    macro_df[\"copper_gold_ratio\"] = macro_df[\"PCOPPUSDM\"] / (macro_df[\"GOLDAMGBD228NLBM\"] + 1e-6)\n","    macro_df[\"growth_indicator\"] = (macro_df[\"copper_gold_ratio\"] > macro_df[\"copper_gold_ratio\"].rolling(252).mean()).astype(int)\n","\n","# Currency features\n","currency_cols = [\"DEXUSEU\", \"DEXCHUS\", \"DEXJPUS\", \"DEXUSUK\", \"DEXCAUS\", \"DEXMXUS\", \"DTWEXBGS\"]\n","for col in currency_cols:\n","    if col in macro_df.columns:\n","        macro_df[f\"{col}_momentum_3m\"] = macro_df[col].pct_change(periods=63)\n","        macro_df[f\"{col}_strength\"] = (macro_df[col] / macro_df[col].rolling(252).mean() - 1)\n","\n","# Guardar features macro procesadas\n","macro_features_path = BASE_DIR / 'data' / 'silver' / 'macro' / 'macro_features.parquet'\n","macro_df.to_parquet(macro_features_path, index=False)\n","print(f\"✓ Features macro guardadas: {macro_features_path}\")\n","print(f\"  Features creadas: {len([c for c in macro_df.columns if c not in FRED_SERIES.keys()])} nuevas columnas\")\n"]},{"cell_type":"markdown","metadata":{"id":"Fhx-MSS3Pxd0"},"source":[]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"haAxd3JaPxd0","executionInfo":{"status":"ok","timestamp":1762836841182,"user_tz":180,"elapsed":3338,"user":{"displayName":"Tomas Basaure","userId":"13858564830784637150"}},"outputId":"3b66a08b-a1ae-49f7-a4e1-bf85f424e579"},"outputs":[{"output_type":"stream","name":"stdout","text":["✓ Copiado: train.parquet (436.82 MB)\n","✓ Copiado: val.parquet (60.07 MB)\n","✓ Copiado: test.parquet (39.54 MB)\n","\n","Cargando datos gold...\n","✓ train: 2853509 filas\n","✓ val: 370114 filas\n","✓ test: 231178 filas\n","\n","Combinando con datos macro...\n","  Macro features disponibles: 4 columnas\n","✓ Datos combinados con macro features\n","  Train columns: 41\n","  Val columns: 37\n","  Test columns: 37\n","✓ Datos combinados con macro features\n","  Train columns: 41\n","  Val columns: 41\n","  Test columns: 37\n","✓ Datos combinados con macro features\n","  Train columns: 41\n","  Val columns: 41\n","  Test columns: 41\n"]}],"source":["import shutil\n","\n","# Copiar archivos parquet de gold desde Drive\n","drive_data_path = Path(DRIVE_BASE_PATH)\n","\n","for split in ['train', 'val', 'test']:\n","    src = drive_data_path / 'data' / 'gold' / f'{split}.parquet'\n","    dst = BASE_DIR / 'data' / 'gold' / f'{split}.parquet'\n","    if src.exists():\n","        shutil.copy2(src, dst)\n","        print(f\"✓ Copiado: {split}.parquet ({dst.stat().st_size / 1024 / 1024:.2f} MB)\")\n","    else:\n","        print(f\"⚠ No encontrado: {src}\")\n","\n","# Cargar datos gold\n","print(\"\\nCargando datos gold...\")\n","train_df = pd.read_parquet(BASE_DIR / 'data' / 'gold' / 'train.parquet')\n","val_df = pd.read_parquet(BASE_DIR / 'data' / 'gold' / 'val.parquet')\n","test_df = pd.read_parquet(BASE_DIR / 'data' / 'gold' / 'test.parquet')\n","\n","print(f\"✓ train: {len(train_df)} filas\")\n","print(f\"✓ val: {len(val_df)} filas\")\n","print(f\"✓ test: {len(test_df)} filas\")\n","\n","# Combinar con macro usando merge_asof\n","print(\"\\nCombinando con datos macro...\")\n","train_df['date'] = pd.to_datetime(train_df['date'])\n","val_df['date'] = pd.to_datetime(val_df['date'])\n","test_df['date'] = pd.to_datetime(test_df['date'])\n","macro_df['date'] = pd.to_datetime(macro_df['date'])\n","\n","# Seleccionar columnas macro relevantes\n","macro_cols_to_merge = [\n","    'yield_curve_slope', 'credit_spread', 'recession_probability', 'macro_regime',\n","    'gold_oil_ratio', 'copper_gold_ratio', 'risk_aversion_indicator', 'growth_indicator'\n","]\n","macro_cols_to_merge = [c for c in macro_cols_to_merge if c in macro_df.columns]\n","macro_subset = macro_df[['date'] + macro_cols_to_merge].sort_values('date')\n","\n","# Merge con train/val/test\n","\n","# Validar que macro_subset no esté vacío antes de merge\n","if macro_subset.empty:\n","    print('⚠ macro_subset está vacío, saltando merge con macro')\n","    # Crear columnas macro vacías para mantener consistencia\n","    for col in macro_cols_to_merge:\n","        train_df[col] = np.nan\n","        val_df[col] = np.nan\n","        test_df[col] = np.nan\n","else:\n","    print(f'  Macro features disponibles: {len(macro_cols_to_merge)} columnas')\n","    for df_name, df in [('train', train_df), ('val', val_df), ('test', test_df)]:\n","        # Fix: Ensure the left DataFrame is sorted globally by 'date' for merge_asof\n","        # The original code's sort_values(['ticker', 'date']) could lead to ValueError\n","        # because 'date' alone might not be globally sorted across all tickers.\n","        df_sorted = df.sort_values('date')\n","        df_merged = pd.merge_asof(df_sorted, macro_subset, on='date', direction='backward')\n","        if df_name == 'train':\n","            train_df = df_merged\n","        elif df_name == 'val':\n","            val_df = df_merged\n","        else:\n","            test_df = df_merged\n","        print(f\"✓ Datos combinados con macro features\")\n","        print(f\"  Train columns: {len(train_df.columns)}\")\n","        print(f\"  Val columns: {len(val_df.columns)}\")\n","        print(f\"  Test columns: {len(test_df.columns)}\")"]},{"cell_type":"markdown","metadata":{"id":"KjPbPDNwPxd0"},"source":["## 7. Feature Engineering para Stocks (Percentiles Históricos, Lags)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0YWeXok4Pxd0","executionInfo":{"status":"ok","timestamp":1762838983002,"user_tz":180,"elapsed":2122067,"user":{"displayName":"Tomas Basaure","userId":"13858564830784637150"}},"outputId":"a0d9b878-45ea-412c-f97f-06e4a0f703f7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Calculando features históricas relativas...\n","✓ Features históricas calculadas\n","  Nuevas columnas agregadas: 13\n"]}],"source":["# Calcular features relativas históricas para evitar leakage\n","print(\"Calculando features históricas relativas...\")\n","\n","def add_historical_features(df):\n","    \"\"\"Agrega features históricas (percentiles, lags, promedios) para evitar leakage.\"\"\"\n","    df = df.copy()\n","\n","    # Asegurar que está ordenado por ticker y fecha\n","    if 'ticker' in df.columns:\n","        df = df.sort_values(['ticker', 'date']).reset_index(drop=True)\n","    else:\n","        df = df.sort_values('date').reset_index(drop=True)\n","\n","    # Percentiles históricos de múltiplos (5 años = ~1260 trading days)\n","    valuation_cols = ['priceToBookRatio', 'priceToSalesRatio', 'enterpriseValue', 'freeCashFlowYield']\n","    for col in valuation_cols:\n","        if col in df.columns:\n","            # Percentil histórico por ticker\n","            if 'ticker' in df.columns:\n","                df[f'{col}_percentile_5y'] = df.groupby('ticker')[col].transform(\n","                    lambda x: x.rolling(window=1260, min_periods=252).apply(\n","                        lambda y: (y.iloc[-1] > y.iloc[:-1]).sum() / len(y.iloc[:-1]) if len(y.iloc[:-1]) > 0 else 0.5\n","                    )\n","                )\n","            else:\n","                df[f'{col}_percentile_5y'] = df[col].rolling(window=1260, min_periods=252).apply(\n","                    lambda y: (y.iloc[-1] > y.iloc[:-1]).sum() / len(y.iloc[:-1]) if len(y.iloc[:-1]) > 0 else 0.5\n","                )\n","\n","    # ROIC/ROE históricos con lags para evitar leakage\n","    quality_cols = ['roic', 'returnOnEquity', 'returnOnAssets']\n","    for col in quality_cols:\n","        if col in df.columns:\n","            # Promedio histórico (3 años)\n","            if 'ticker' in df.columns:\n","                df[f'{col}_3y_avg'] = df.groupby('ticker')[col].transform(\n","                    lambda x: x.rolling(window=756, min_periods=252).mean()\n","                )\n","                # Lags (trimestres anteriores)\n","                df[f'{col}_lag_1q'] = df.groupby('ticker')[col].shift(63)\n","                df[f'{col}_lag_2q'] = df.groupby('ticker')[col].shift(126)\n","            else:\n","                df[f'{col}_3y_avg'] = df[col].rolling(window=756, min_periods=252).mean()\n","                df[f'{col}_lag_1q'] = df[col].shift(63)\n","                df[f'{col}_lag_2q'] = df[col].shift(126)\n","\n","    return df\n","\n","# Aplicar a train, val, test\n","train_df = add_historical_features(train_df)\n","val_df = add_historical_features(val_df)\n","test_df = add_historical_features(test_df)\n","\n","print(\"✓ Features históricas calculadas\")\n","print(f\"  Nuevas columnas agregadas: {len([c for c in train_df.columns if 'percentile' in c or 'lag' in c or '_3y_avg' in c])}\")\n"]},{"cell_type":"markdown","metadata":{"id":"4iW6clDCPxd1"},"source":["## 8. Entrenar Quality Model (Percentiles por Fecha)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CY8gT-HHPxd2","executionInfo":{"status":"ok","timestamp":1762840955596,"user_tz":180,"elapsed":293215,"user":{"displayName":"Tomas Basaure","userId":"13858564830784637150"}},"outputId":"0252965b-c2a3-4761-e4e6-0d061d024dc4"},"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","ENTRENANDO QUALITY MODEL\n","============================================================\n","\n","Features usadas (12): ['roic_lag_1q', 'roic_lag_2q', 'roic_3y_avg', 'returnOnEquity', 'returnOnAssets']...\n","  Variables categóricas codificadas: ['macro_regime']\n","\n","Creando labels por fecha (percentiles por fecha)...\n","  Train: 6970 / 2853509 positivos (0.24%)\n","  Val: 1055 / 370114 positivos (0.29%)\n","  Test: 344 / 231178 positivos (0.15%)\n","\n","Entrenando modelo...\n","\n","Resultados Quality Model:\n","  Train - Accuracy: 0.9996, AUC: 0.9999\n","  Val   - Accuracy: 0.9997, AUC: 1.0000\n","  Test  - Accuracy: 0.9999, AUC: 1.0000\n","\n","✓ Modelo guardado: /content/caria_workspace/models/improved_quality_model.pkl\n","✓ Copiado a Drive: /content/drive/MyDrive/caria_data/models/improved_quality_model.pkl\n"]}],"source":["import xgboost as xgb\n","import joblib\n","from sklearn.metrics import accuracy_score, roc_auc_score\n","\n","print(\"=\" * 60)\n","print(\"ENTRENANDO QUALITY MODEL\")\n","print(\"=\" * 60)\n","\n","# Features para Quality Model (SIN roic actual para evitar leakage)\n","quality_features = [\n","    'roic_lag_1q', 'roic_lag_2q', 'roic_3y_avg',\n","    'returnOnEquity', 'returnOnAssets',\n","    'grossProfitMargin', 'netProfitMargin',\n","    'freeCashFlowYield', 'freeCashFlowPerShare',\n","    'revenueGrowth', 'netIncomeGrowth',\n","]\n","\n","# Agregar features macro si están disponibles\n","macro_quality_features = ['recession_probability', 'macro_regime', 'credit_spread']\n","quality_features.extend([f for f in macro_quality_features if f in train_df.columns])\n","\n","# Filtrar solo features que existen\n","quality_features = [f for f in quality_features if f in train_df.columns]\n","print(f\"\\nFeatures usadas ({len(quality_features)}): {quality_features[:5]}...\")\n","\n","# Función helper para codificar variables categóricas\n","\n","# Preparar datos - codificar variables categóricas primero\n","X_train_quality, X_val_quality, X_test_quality = encode_categorical_features(\n","    train_df, val_df, test_df, quality_features\n",")\n","\n","# Convertir a float32 y llenar NaN\n","X_train_quality = X_train_quality.fillna(0).astype('float32')\n","X_val_quality = X_val_quality.fillna(0).astype('float32')\n","X_test_quality = X_test_quality.fillna(0).astype('float32')\n","\n","# Crear labels: Top 20% de ROIC POR FECHA (adaptado al régimen económico)\n","print(\"\\nCreando labels por fecha (percentiles por fecha)...\")\n","train_df['roic_percentile_by_date'] = train_df.groupby('date')['roic'].rank(pct=True)\n","train_df['is_quality'] = (train_df['roic_percentile_by_date'] > 0.80).astype(int)\n","\n","val_df['roic_percentile_by_date'] = val_df.groupby('date')['roic'].rank(pct=True)\n","val_df['is_quality'] = (val_df['roic_percentile_by_date'] > 0.80).astype(int)\n","\n","test_df['roic_percentile_by_date'] = test_df.groupby('date')['roic'].rank(pct=True)\n","test_df['is_quality'] = (test_df['roic_percentile_by_date'] > 0.80).astype(int)\n","\n","y_train_quality = train_df['is_quality']\n","y_val_quality = val_df['is_quality']\n","y_test_quality = test_df['is_quality']\n","\n","print(f\"  Train: {y_train_quality.sum()} / {len(y_train_quality)} positivos ({y_train_quality.mean():.2%})\")\n","print(f\"  Val: {y_val_quality.sum()} / {len(y_val_quality)} positivos ({y_val_quality.mean():.2%})\")\n","print(f\"  Test: {y_test_quality.sum()} / {len(y_test_quality)} positivos ({y_test_quality.mean():.2%})\")\n","\n","# Calcular scale_pos_weight para balancear clases\n","scale_pos_weight = (len(y_train_quality) - y_train_quality.sum()) / max(y_train_quality.sum(), 1)\n","\n","# Entrenar modelo con hiperparámetros anti-overfitting\n","print(\"\\nEntrenando modelo...\")\n","quality_model = xgb.XGBClassifier(\n","    n_estimators=300,\n","    max_depth=3,  # Reducido para evitar overfitting\n","    learning_rate=0.01,\n","    reg_alpha=2.0,\n","    reg_lambda=3.0,\n","    subsample=0.75,\n","    colsample_bytree=0.75,\n","    min_child_weight=10,\n","    random_state=42,\n","    scale_pos_weight=scale_pos_weight,\n","    eval_metric='auc',\n","    early_stopping_rounds=50,\n",")\n","\n","quality_model.fit(\n","    X_train_quality,\n","    y_train_quality,\n","    eval_set=[(X_val_quality, y_val_quality)],\n","    verbose=False,\n",")\n","\n","# Evaluar\n","y_pred_train = quality_model.predict(X_train_quality)\n","y_pred_val = quality_model.predict(X_val_quality)\n","y_pred_test = quality_model.predict(X_test_quality)\n","\n","y_pred_proba_train = quality_model.predict_proba(X_train_quality)[:, 1]\n","y_pred_proba_val = quality_model.predict_proba(X_val_quality)[:, 1]\n","y_pred_proba_test = quality_model.predict_proba(X_test_quality)[:, 1]\n","\n","print(\"\\nResultados Quality Model:\")\n","print(f\"  Train - Accuracy: {accuracy_score(y_train_quality, y_pred_train):.4f}, AUC: {roc_auc_score(y_train_quality, y_pred_proba_train):.4f}\")\n","print(f\"  Val   - Accuracy: {accuracy_score(y_val_quality, y_pred_val):.4f}, AUC: {roc_auc_score(y_val_quality, y_pred_proba_val):.4f}\")\n","print(f\"  Test  - Accuracy: {accuracy_score(y_test_quality, y_pred_test):.4f}, AUC: {roc_auc_score(y_test_quality, y_pred_proba_test):.4f}\")\n","\n","# Guardar\n","output_path = BASE_DIR / 'models' / 'improved_quality_model.pkl'\n","joblib.dump(quality_model, output_path)\n","print(f\"\\n✓ Modelo guardado: {output_path}\")\n","\n","# Copiar a Drive\n","drive_models_path = Path(DRIVE_BASE_PATH) / 'models'\n","drive_models_path.mkdir(parents=True, exist_ok=True)\n","joblib.dump(quality_model, drive_models_path / 'improved_quality_model.pkl')\n","print(f\"✓ Copiado a Drive: {drive_models_path / 'improved_quality_model.pkl'}\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"XAPX654_Pxd2"},"source":[]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"abbOLEOvPxd2","executionInfo":{"status":"ok","timestamp":1762841519678,"user_tz":180,"elapsed":6715,"user":{"displayName":"Tomas Basaure","userId":"13858564830784637150"}},"outputId":"01389d46-20a8-45ee-8fac-d0e7640a7901"},"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","ENTRENANDO VALUATION MODEL (DCF/Múltiplos)\n","============================================================\n","\n","Features usadas (14): ['priceToBookRatio_percentile_5y', 'priceToSalesRatio_percentile_5y', 'freeCashFlowYield_percentile_5y', 'priceToBookRatio', 'priceToSalesRatio']...\n","\n","Calculando target: precio futuro 5 años...\n","  Train target stats: mean=0.0031, std=0.0562\n","  Val target stats: mean=0.0026, std=0.0520\n","\n","Entrenando modelo...\n","\n","Resultados Valuation Model:\n","  Train - RMSE: 0.0559, R²: 0.0111\n","  Val   - RMSE: 0.0520, R²: 0.0001\n","  Test  - RMSE: 0.0372, R²: -0.0000\n","\n","✓ Modelo guardado: /content/caria_workspace/models/improved_valuation_model.pkl\n","✓ Copiado a Drive: /content/drive/MyDrive/caria_data/models/improved_valuation_model.pkl\n"]}],"source":["from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","\n","print(\"=\" * 60)\n","print(\"ENTRENANDO VALUATION MODEL (DCF/Múltiplos)\")\n","print(\"=\" * 60)\n","\n","# Features para Valuation Model\n","valuation_features = [\n","    # Múltiplos relativos históricos\n","    'priceToBookRatio_percentile_5y',\n","    'priceToSalesRatio_percentile_5y',\n","    'freeCashFlowYield_percentile_5y',\n","    # Fundamentales\n","    'priceToBookRatio', 'priceToSalesRatio', 'enterpriseValue',\n","    'returnOnEquity', 'roic', 'grossProfitMargin', 'netProfitMargin',\n","    'freeCashFlowYield', 'revenueGrowth', 'netIncomeGrowth',\n","    # Macro contexto\n","    'yield_curve_slope', 'credit_spread', 'recession_probability',\n","    'gold_oil_ratio', 'copper_gold_ratio',\n","]\n","\n","# Filtrar solo features que existen\n","valuation_features = [f for f in valuation_features if f in train_df.columns]\n","print(f\"\\nFeatures usadas ({len(valuation_features)}): {valuation_features[:5]}...\")\n","\n","# Preparar datos - codificar variables categóricas primero\n","X_train_val, X_val_val, X_test_val = encode_categorical_features(\n","    train_df, val_df, test_df, valuation_features\n",")\n","\n","# Convertir a float32 y llenar NaN\n","X_train_val = X_train_val.fillna(0).astype('float32')\n","X_val_val = X_val_val.fillna(0).astype('float32')\n","X_test_val = X_test_val.fillna(0).astype('float32')\n","\n","# Target: Precio futuro 5 años (1260 trading days) vs precio actual\n","# Para esto necesitamos calcular el precio futuro desde la fecha actual\n","print(\"\\nCalculando target: precio futuro 5 años...\")\n","\n","def calculate_future_price_target(df, future_days=1260):\n","    \"\"\"Calcula el precio futuro como target para valuación.\"\"\"\n","    df = df.copy()\n","    if 'ticker' not in df.columns or 'date' not in df.columns:\n","        print(\"  ⚠ No se puede calcular target sin ticker y date\")\n","        return pd.Series(index=df.index, dtype='float64')\n","\n","    df = df.sort_values(['ticker', 'date']).reset_index(drop=True)\n","\n","    # Buscar precio futuro (5 años = ~1260 trading days)\n","    # Asumimos que tenemos una columna de precio o podemos calcularlo desde múltiplos\n","    # Por ahora usamos forward returns acumulados como proxy\n","    if 'target' in df.columns:\n","        # Acumular returns futuros (aproximación)\n","        df['future_price_target'] = df.groupby('ticker')['target'].transform(\n","            lambda x: x.rolling(window=future_days, min_periods=1).apply(\n","                lambda y: (1 + y).prod() if len(y) > 0 else 1.0\n","            )\n","        )\n","        return df['future_price_target']\n","    else:\n","        print(\"  ⚠ No hay columna 'target' para calcular precio futuro\")\n","        return pd.Series(index=df.index, dtype='float64')\n","\n","# Para simplificar, usamos target como proxy de retorno futuro\n","# En producción, esto debería ser precio real futuro vs precio actual\n","y_train_val = train_df['target'].fillna(0)  # Proxy: forward returns\n","y_val_val = val_df['target'].fillna(0)\n","y_test_val = test_df['target'].fillna(0)\n","\n","print(f\"  Train target stats: mean={y_train_val.mean():.4f}, std={y_train_val.std():.4f}\")\n","print(f\"  Val target stats: mean={y_val_val.mean():.4f}, std={y_val_val.std():.4f}\")\n","\n","# Entrenar modelo (Regressor para predecir valor justo)\n","print(\"\\nEntrenando modelo...\")\n","valuation_model = xgb.XGBRegressor(\n","    n_estimators=400,\n","    max_depth=4,\n","    learning_rate=0.01,\n","    reg_alpha=1.5,\n","    reg_lambda=2.5,\n","    subsample=0.8,\n","    colsample_bytree=0.8,\n","    min_child_weight=5,\n","    random_state=42,\n","    eval_metric='rmse',\n","    early_stopping_rounds=50,\n",")\n","\n","valuation_model.fit(\n","    X_train_val,\n","    y_train_val,\n","    eval_set=[(X_val_val, y_val_val)],\n","    verbose=False,\n",")\n","\n","# Evaluar\n","y_pred_train = valuation_model.predict(X_train_val)\n","y_pred_val = valuation_model.predict(X_val_val)\n","y_pred_test = valuation_model.predict(X_test_val)\n","\n","print(\"\\nResultados Valuation Model:\")\n","print(f\"  Train - RMSE: {np.sqrt(mean_squared_error(y_train_val, y_pred_train)):.4f}, R²: {r2_score(y_train_val, y_pred_train):.4f}\")\n","print(f\"  Val   - RMSE: {np.sqrt(mean_squared_error(y_val_val, y_pred_val)):.4f}, R²: {r2_score(y_val_val, y_pred_val):.4f}\")\n","print(f\"  Test  - RMSE: {np.sqrt(mean_squared_error(y_test_val, y_pred_test)):.4f}, R²: {r2_score(y_test_val, y_pred_test):.4f}\")\n","\n","# Guardar\n","output_path = BASE_DIR / 'models' / 'improved_valuation_model.pkl'\n","joblib.dump(valuation_model, output_path)\n","print(f\"\\n✓ Modelo guardado: {output_path}\")\n","\n","# Copiar a Drive\n","joblib.dump(valuation_model, drive_models_path / 'improved_valuation_model.pkl')\n","print(f\"✓ Copiado a Drive: {drive_models_path / 'improved_valuation_model.pkl'}\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"guFKLz4zPxd2"},"source":[]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FumOdnjmPxd2","executionInfo":{"status":"ok","timestamp":1762841597095,"user_tz":180,"elapsed":8558,"user":{"displayName":"Tomas Basaure","userId":"13858564830784637150"}},"outputId":"5acb7f07-0755-4da0-fe4c-1e7b8f3f1729"},"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","ENTRENANDO MOMENTUM MODEL\n","============================================================\n","\n","Features usadas (16): ['volume', 'volume_sma_20', 'sma_200', 'sma_50', 'sma_20', 'ema_20', 'ema_50', 'rsi_14', 'macd', 'macd_signal', 'atr_14', 'volatility_30d', 'price_above_sma200', 'price_above_sma50', 'volume_ratio_20d', 'sma200_slope']\n","\n","Target distribución:\n","  Train: 1505231 / 2853509 positivos (52.75%)\n","  Val: 198672 / 370114 positivos (53.68%)\n","  Test: 125909 / 231178 positivos (54.46%)\n","\n","Entrenando modelo...\n","\n","Resultados Momentum Model:\n","  Train - Accuracy: 0.5275, AUC: 0.5279\n","  Val   - Accuracy: 0.5368, AUC: 0.4985\n","  Test  - Accuracy: 0.5446, AUC: 0.5003\n","\n","✓ Modelo guardado: /content/caria_workspace/models/improved_momentum_model.pkl\n","✓ Copiado a Drive: /content/drive/MyDrive/caria_data/models/improved_momentum_model.pkl\n"]}],"source":["print(\"=\" * 60)\n","print(\"ENTRENANDO MOMENTUM MODEL\")\n","print(\"=\" * 60)\n","\n","# Features para Momentum Model (volumen, SMAs 200/50, RSI)\n","momentum_features = [\n","    # Volumen (más importante según usuario)\n","    'volume', 'volume_sma_20',\n","    # SMAs (200 y 50 son las más importantes)\n","    'sma_200', 'sma_50', 'sma_20',\n","    'ema_20', 'ema_50',\n","    # Posición relativa vs SMAs\n","    # (calcularemos si precio está sobre SMA)\n","    # RSI (en menor medida según usuario)\n","    'rsi_14',\n","    # Otros técnicos\n","    'macd', 'macd_signal',\n","    'atr_14', 'volatility_30d',\n","]\n","\n","# Agregar features calculadas: precio sobre SMAs\n","if 'sma_200' in train_df.columns:\n","    # Asumimos que hay una columna de precio o la calculamos desde múltiplos\n","    # Por simplicidad, usamos enterpriseValue como proxy si no hay precio directo\n","    price_proxy = train_df['price'] if 'price' in train_df.columns else None\n","    if price_proxy is None:\n","        # Intentar calcular desde múltiplos si están disponibles\n","        if 'priceToBookRatio' in train_df.columns and 'bookValue' in train_df.columns:\n","            price_proxy = train_df['priceToBookRatio'] * train_df['bookValue']\n","        else:\n","            price_proxy = train_df['enterpriseValue'] if 'enterpriseValue' in train_df.columns else pd.Series([1.0] * len(train_df), index=train_df.index)\n","\n","    train_df['price_above_sma200'] = (price_proxy > train_df['sma_200']).astype(int)\n","    train_df['price_above_sma50'] = (price_proxy > train_df['sma_50']).astype(int)\n","\n","    val_df['price_above_sma200'] = ((val_df['price'] if 'price' in val_df.columns else (val_df['enterpriseValue'] if 'enterpriseValue' in val_df.columns else 1.0)) > val_df['sma_200']).astype(int)\n","    val_df['price_above_sma50'] = ((val_df['price'] if 'price' in val_df.columns else (val_df['enterpriseValue'] if 'enterpriseValue' in val_df.columns else 1.0)) > val_df['sma_50']).astype(int)\n","\n","    test_df['price_above_sma200'] = ((test_df['price'] if 'price' in test_df.columns else (test_df['enterpriseValue'] if 'enterpriseValue' in test_df.columns else 1.0)) > test_df['sma_200']).astype(int)\n","    test_df['price_above_sma50'] = ((test_df['price'] if 'price' in test_df.columns else (test_df['enterpriseValue'] if 'enterpriseValue' in test_df.columns else 1.0)) > test_df['sma_50']).astype(int)\n","\n","    momentum_features.extend(['price_above_sma200', 'price_above_sma50'])\n","\n","# Ratio de volumen (volumen actual / SMA volumen)\n","if 'volume' in train_df.columns and 'volume_sma_20' in train_df.columns:\n","    train_df['volume_ratio_20d'] = train_df['volume'] / (train_df['volume_sma_20'] + 1e-6)\n","    val_df['volume_ratio_20d'] = val_df['volume'] / (val_df['volume_sma_20'] + 1e-6)\n","    test_df['volume_ratio_20d'] = test_df['volume'] / (test_df['volume_sma_20'] + 1e-6)\n","    momentum_features.append('volume_ratio_20d')\n","\n","# Slope de SMA 200 (tendencia)\n","if 'sma_200' in train_df.columns:\n","    train_df['sma200_slope'] = train_df.groupby('ticker')['sma_200'].transform(lambda x: x.diff(20)) if 'ticker' in train_df.columns else train_df['sma_200'].diff(20)\n","    val_df['sma200_slope'] = val_df.groupby('ticker')['sma_200'].transform(lambda x: x.diff(20)) if 'ticker' in val_df.columns else val_df['sma_200'].diff(20)\n","    test_df['sma200_slope'] = test_df.groupby('ticker')['sma_200'].transform(lambda x: x.diff(20)) if 'ticker' in test_df.columns else test_df['sma_200'].diff(20)\n","    momentum_features.append('sma200_slope')\n","\n","# Filtrar solo features que existen\n","momentum_features = [f for f in momentum_features if f in train_df.columns]\n","print(f\"\\nFeatures usadas ({len(momentum_features)}): {momentum_features}\")\n","\n","# Preparar datos - codificar variables categóricas primero\n","X_train_momentum, X_val_momentum, X_test_momentum = encode_categorical_features(\n","    train_df, val_df, test_df, momentum_features\n",")\n","\n","# Convertir a float32 y llenar NaN\n","X_train_momentum = X_train_momentum.fillna(0).astype('float32')\n","X_val_momentum = X_val_momentum.fillna(0).astype('float32')\n","X_test_momentum = X_test_momentum.fillna(0).astype('float32')\n","\n","# Target: Dirección de retorno (positivo vs negativo)\n","y_train_momentum = (train_df['target'] > 0).astype(int)\n","y_val_momentum = (val_df['target'] > 0).astype(int)\n","y_test_momentum = (test_df['target'] > 0).astype(int)\n","\n","print(f\"\\nTarget distribución:\")\n","print(f\"  Train: {y_train_momentum.sum()} / {len(y_train_momentum)} positivos ({y_train_momentum.mean():.2%})\")\n","print(f\"  Val: {y_val_momentum.sum()} / {len(y_val_momentum)} positivos ({y_val_momentum.mean():.2%})\")\n","print(f\"  Test: {y_test_momentum.sum()} / {len(y_test_momentum)} positivos ({y_test_momentum.mean():.2%})\")\n","\n","# Entrenar modelo\n","print(\"\\nEntrenando modelo...\")\n","momentum_model = xgb.XGBClassifier(\n","    n_estimators=500,\n","    max_depth=5,  # Más profundo para capturar relaciones complejas\n","    learning_rate=0.01,\n","    reg_alpha=1.0,\n","    reg_lambda=2.0,\n","    subsample=0.8,\n","    colsample_bytree=0.8,\n","    min_child_weight=3,\n","    random_state=42,\n","    eval_metric='auc',\n","    early_stopping_rounds=50,\n",")\n","\n","momentum_model.fit(\n","    X_train_momentum,\n","    y_train_momentum,\n","    eval_set=[(X_val_momentum, y_val_momentum)],\n","    verbose=False,\n",")\n","\n","# Evaluar\n","y_pred_train = momentum_model.predict(X_train_momentum)\n","y_pred_val = momentum_model.predict(X_val_momentum)\n","y_pred_test = momentum_model.predict(X_test_momentum)\n","\n","y_pred_proba_train = momentum_model.predict_proba(X_train_momentum)[:, 1]\n","y_pred_proba_val = momentum_model.predict_proba(X_val_momentum)[:, 1]\n","y_pred_proba_test = momentum_model.predict_proba(X_test_momentum)[:, 1]\n","\n","print(\"\\nResultados Momentum Model:\")\n","print(f\"  Train - Accuracy: {accuracy_score(y_train_momentum, y_pred_train):.4f}, AUC: {roc_auc_score(y_train_momentum, y_pred_proba_train):.4f}\")\n","print(f\"  Val   - Accuracy: {accuracy_score(y_val_momentum, y_pred_val):.4f}, AUC: {roc_auc_score(y_val_momentum, y_pred_proba_val):.4f}\")\n","print(f\"  Test  - Accuracy: {accuracy_score(y_test_momentum, y_pred_test):.4f}, AUC: {roc_auc_score(y_test_momentum, y_pred_proba_test):.4f}\")\n","\n","# Guardar\n","output_path = BASE_DIR / 'models' / 'improved_momentum_model.pkl'\n","joblib.dump(momentum_model, output_path)\n","print(f\"\\n✓ Modelo guardado: {output_path}\")\n","\n","# Copiar a Drive\n","joblib.dump(momentum_model, drive_models_path / 'improved_momentum_model.pkl')\n","print(f\"✓ Copiado a Drive: {drive_models_path / 'improved_momentum_model.pkl'}\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"hlEB29q9Pxd2"},"source":["## 11. Guardar Feature Config y Resumen Final\n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_0XE0KFHPxd3","executionInfo":{"status":"ok","timestamp":1762841629536,"user_tz":180,"elapsed":25,"user":{"displayName":"Tomas Basaure","userId":"13858564830784637150"}},"outputId":"6bf8ca35-9264-4a5b-e86e-6084431cfbf4"},"outputs":[{"output_type":"stream","name":"stdout","text":["✓ Feature config guardado: /content/caria_workspace/models/improved_feature_config.pkl\n","✓ Copiado a Drive: /content/drive/MyDrive/caria_data/models/improved_feature_config.pkl\n","\n","============================================================\n","RESUMEN FINAL - MODELOS MEJORADOS\n","============================================================\n","\n","✓ Modelos entrenados y guardados:\n","  1. Quality Model: /content/caria_workspace/models/improved_quality_model.pkl\n","  2. Valuation Model: /content/caria_workspace/models/improved_valuation_model.pkl\n","  3. Momentum Model: /content/caria_workspace/models/improved_momentum_model.pkl\n","\n","✓ Características principales:\n","  - Quality: Percentiles por fecha (identifica outliers en cualquier régimen)\n","  - Valuation: DCF/Múltiplos con contexto macro (target futuro 5 años)\n","  - Momentum: Features mejoradas (volumen, SMAs 200/50, RSI)\n","\n","✓ Datos procesados:\n","  - Datos FRED descargados y procesados\n","  - Features macro cíclicas calculadas\n","  - Features históricas relativas agregadas (percentiles, lags)\n","\n","✓ Archivos en Drive:\n","  - Modelos: /content/drive/MyDrive/caria_data/models\n","  - Datos macro: /content/drive/MyDrive/caria_data/data/silver/macro\n","\n","============================================================\n","ENTRENAMIENTO COMPLETADO\n","============================================================\n"]}],"source":["# Guardar feature config para uso futuro\n","feature_config = {\n","    'quality_features': quality_features,\n","    'valuation_features': valuation_features,\n","    'momentum_features': momentum_features,\n","}\n","\n","feature_config_path = BASE_DIR / 'models' / 'improved_feature_config.pkl'\n","joblib.dump(feature_config, feature_config_path)\n","print(f\"✓ Feature config guardado: {feature_config_path}\")\n","\n","# Copiar a Drive\n","joblib.dump(feature_config, drive_models_path / 'improved_feature_config.pkl')\n","print(f\"✓ Copiado a Drive: {drive_models_path / 'improved_feature_config.pkl'}\")\n","\n","# Resumen final\n","print(\"\\n\" + \"=\" * 60)\n","print(\"RESUMEN FINAL - MODELOS MEJORADOS\")\n","print(\"=\" * 60)\n","\n","print(\"\\n✓ Modelos entrenados y guardados:\")\n","print(f\"  1. Quality Model: {BASE_DIR / 'models' / 'improved_quality_model.pkl'}\")\n","print(f\"  2. Valuation Model: {BASE_DIR / 'models' / 'improved_valuation_model.pkl'}\")\n","print(f\"  3. Momentum Model: {BASE_DIR / 'models' / 'improved_momentum_model.pkl'}\")\n","\n","print(\"\\n✓ Características principales:\")\n","print(\"  - Quality: Percentiles por fecha (identifica outliers en cualquier régimen)\")\n","print(\"  - Valuation: DCF/Múltiplos con contexto macro (target futuro 5 años)\")\n","print(\"  - Momentum: Features mejoradas (volumen, SMAs 200/50, RSI)\")\n","\n","print(\"\\n✓ Datos procesados:\")\n","print(f\"  - Datos FRED descargados y procesados\")\n","print(f\"  - Features macro cíclicas calculadas\")\n","print(f\"  - Features históricas relativas agregadas (percentiles, lags)\")\n","\n","print(\"\\n✓ Archivos en Drive:\")\n","print(f\"  - Modelos: {drive_models_path}\")\n","print(f\"  - Datos macro: {Path(DRIVE_BASE_PATH) / 'data' / 'silver' / 'macro'}\")\n","\n","print(\"\\n\" + \"=\" * 60)\n","print(\"ENTRENAMIENTO COMPLETADO\")\n","print(\"=\" * 60)\n"]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100"},"accelerator":"GPU","kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":0}