{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "header"
            },
            "source": [
                "# üî¨ CARIA-SR Extended Validation (1980+, Multi-Asset)\n",
                "\n",
                "**Extended Testing:**\n",
                "- US Equities (1980-present)\n",
                "- Global Indices (Europe, Japan, EM)\n",
                "- Crypto (BTC, ETH)\n",
                "\n",
                "**Phases:** 8-14 + Max Drawdown Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "setup"
            },
            "outputs": [],
            "source": [
                "# @title 1. Setup\n",
                "!pip install -q yfinance pandas numpy scipy scikit-learn statsmodels seaborn matplotlib pyarrow requests\n",
                "\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "import os\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import yfinance as yf\n",
                "import requests\n",
                "import warnings\n",
                "from datetime import datetime\n",
                "import statsmodels.formula.api as smf\n",
                "from sklearn.covariance import LedoitWolf\n",
                "\n",
                "warnings.filterwarnings('ignore')\n",
                "np.random.seed(42)\n",
                "sns.set_style('whitegrid')\n",
                "\n",
                "WORK_DIR = '/content/drive/MyDrive/CARIA_Extended'\n",
                "os.makedirs(f'{WORK_DIR}/figures', exist_ok=True)\n",
                "os.makedirs(f'{WORK_DIR}/tables', exist_ok=True)\n",
                "\n",
                "# Extended date range\n",
                "START_DATE = \"1980-01-01\"\n",
                "END_DATE = datetime.now().strftime(\"%Y-%m-%d\")\n",
                "\n",
                "print(f\"‚úÖ Output: {WORK_DIR}\")\n",
                "print(f\"üìÖ Date Range: {START_DATE} to {END_DATE}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "download_multi"
            },
            "outputs": [],
            "source": [
                "# @title 2. Download Multi-Asset Data\n",
                "\n",
                "# Define asset universes\n",
                "ASSETS = {\n",
                "    'US_Equity': {\n",
                "        'main': '^GSPC',  # S&P 500\n",
                "        'vol': '^VIX',\n",
                "        'safe': 'TLT',\n",
                "        'sectors': ['XLF', 'XLK', 'XLE', 'XLV', 'XLI', 'XLY', 'XLP', 'XLB', 'XLU', 'XLRE', 'XLC'],\n",
                "        'start': '1980-01-01'\n",
                "    },\n",
                "    'Global_Indices': {\n",
                "        'main': 'SPY',\n",
                "        'vol': '^VIX',\n",
                "        'safe': 'TLT',\n",
                "        'sectors': ['EWJ', 'EWG', 'EWU', 'EWC', 'EWA', 'EWZ', 'EWY', 'EWT', 'EWH', 'EWS', 'EEM', 'VGK'],\n",
                "        'start': '2000-01-01'\n",
                "    },\n",
                "    'Crypto': {\n",
                "        'main': 'BTC-USD',\n",
                "        'vol': '^VIX',  # Use VIX as proxy (no crypto vol index)\n",
                "        'safe': 'TLT',\n",
                "        'sectors': ['BTC-USD', 'ETH-USD', 'BNB-USD', 'SOL-USD', 'XRP-USD', 'ADA-USD', 'DOGE-USD', 'DOT-USD'],\n",
                "        'start': '2017-01-01'\n",
                "    }\n",
                "}\n",
                "\n",
                "all_data = {}\n",
                "\n",
                "for asset_class, config in ASSETS.items():\n",
                "    print(f\"\\nüì• Downloading {asset_class}...\")\n",
                "    \n",
                "    # Download main index\n",
                "    try:\n",
                "        main = yf.download(config['main'], start=config['start'], end=END_DATE, progress=False)['Close']\n",
                "        main = main.rename('price') if isinstance(main, pd.Series) else main.iloc[:, 0].rename('price')\n",
                "    except:\n",
                "        main = pd.Series(dtype=float)\n",
                "    \n",
                "    # Download volatility\n",
                "    try:\n",
                "        vol = yf.download(config['vol'], start=config['start'], end=END_DATE, progress=False)['Close']\n",
                "        vol = vol.rename('volatility') if isinstance(vol, pd.Series) else vol.iloc[:, 0].rename('volatility')\n",
                "    except:\n",
                "        vol = pd.Series(dtype=float)\n",
                "    \n",
                "    # Download safe asset\n",
                "    try:\n",
                "        safe = yf.download(config['safe'], start=config['start'], end=END_DATE, progress=False)['Close']\n",
                "        safe = safe.rename('safe') if isinstance(safe, pd.Series) else safe.iloc[:, 0].rename('safe')\n",
                "    except:\n",
                "        safe = pd.Series(dtype=float)\n",
                "    \n",
                "    # Download sectors/constituents for cross-sectional analysis\n",
                "    sectors = yf.download(config['sectors'], start=config['start'], end=END_DATE, progress=False)['Close']\n",
                "    if isinstance(sectors, pd.Series):\n",
                "        sectors = sectors.to_frame()\n",
                "    \n",
                "    all_data[asset_class] = {\n",
                "        'main': main,\n",
                "        'vol': vol,\n",
                "        'safe': safe,\n",
                "        'sectors': sectors\n",
                "    }\n",
                "    \n",
                "    print(f\"   Main: {len(main)} days, Sectors: {sectors.shape[1]} assets\")\n",
                "\n",
                "print(\"\\n‚úÖ All data downloaded\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "structural_fn"
            },
            "outputs": [],
            "source": [
                "# @title 3. Core Functions\n",
                "\n",
                "def cov_to_corr(S):\n",
                "    d = np.sqrt(np.diag(S))\n",
                "    d = np.where(d == 0, 1e-10, d)\n",
                "    C = S / np.outer(d, d)\n",
                "    return np.nan_to_num((C + C.T) / 2)\n",
                "\n",
                "def eig_metrics(C, k_frac=0.2):\n",
                "    w = np.sort(np.linalg.eigvalsh(C))[::-1]\n",
                "    w = np.maximum(w, 1e-10)\n",
                "    k = max(1, int(np.ceil(k_frac * len(w))))\n",
                "    ar = np.sum(w[:k]) / np.sum(w)\n",
                "    p = w / np.sum(w)\n",
                "    ent = -np.sum(p * np.log(p + 1e-10)) / np.log(len(w)) if len(w) > 1 else 0.5\n",
                "    return float(ar), float(ent)\n",
                "\n",
                "def calculate_structural_metrics(sectors_df, window=252, step=5, min_assets=5):\n",
                "    \"\"\"Calculate AR and Entropy from cross-sectional data.\"\"\"\n",
                "    returns = np.log(sectors_df).diff()\n",
                "    good = returns.notna().mean() >= 0.8\n",
                "    returns = returns.loc[:, good]\n",
                "    \n",
                "    if returns.shape[1] < min_assets:\n",
                "        print(f\"   Warning: Only {returns.shape[1]} assets with good coverage\")\n",
                "        return pd.DataFrame()\n",
                "    \n",
                "    struct = pd.DataFrame(index=returns.index, columns=['absorption_ratio', 'entropy'], dtype=float)\n",
                "    lw = LedoitWolf()\n",
                "    \n",
                "    for t in range(window, len(returns), step):\n",
                "        W = returns.iloc[t-window:t]\n",
                "        W = W.loc[:, W.notna().mean() >= 0.8]\n",
                "        if W.shape[1] < min_assets:\n",
                "            continue\n",
                "        W = W.apply(lambda s: s.fillna(s.mean()))\n",
                "        X = W.values - np.nanmean(W.values, axis=0)\n",
                "        try:\n",
                "            C = cov_to_corr(lw.fit(X).covariance_)\n",
                "        except:\n",
                "            C = np.corrcoef(X, rowvar=False)\n",
                "            C = np.nan_to_num((C + C.T) / 2)\n",
                "        ar, ent = eig_metrics(C)\n",
                "        struct.iloc[t] = [ar, ent]\n",
                "    \n",
                "    return struct.ffill().bfill()\n",
                "\n",
                "def add_signals(df, window_z=252, window_memory=60):\n",
                "    \"\"\"Add Z-scores and Peak Memory signals.\"\"\"\n",
                "    roll_mean = df['absorption_ratio'].rolling(window=window_z).mean()\n",
                "    roll_std = df['absorption_ratio'].rolling(window=window_z).std()\n",
                "    df['absorp_z'] = (df['absorption_ratio'] - roll_mean) / roll_std\n",
                "    df['caria_peak'] = df['absorp_z'].rolling(window=window_memory).max()\n",
                "    return df\n",
                "\n",
                "def get_max_drawdown(equity):\n",
                "    peak = equity.cummax()\n",
                "    return float((equity / peak - 1.0).min())\n",
                "\n",
                "def run_minsky_hedge(df, entry_peak=1.0, exit_peak=0.5, vix_entry=20):\n",
                "    \"\"\"Run Minsky Hedge with persistence logic.\"\"\"\n",
                "    df = df.copy()\n",
                "    df['daily_ret'] = np.log(df['price']).diff()\n",
                "    df['safe_ret'] = np.log(df['safe']).diff()\n",
                "    \n",
                "    # State machine\n",
                "    in_hedge = False\n",
                "    states = []\n",
                "    \n",
                "    for i in range(len(df)):\n",
                "        peak = df['caria_peak'].iloc[i]\n",
                "        vix = df['volatility'].iloc[i] if 'volatility' in df.columns else 15\n",
                "        \n",
                "        if pd.isna(peak):\n",
                "            states.append(False)\n",
                "            continue\n",
                "            \n",
                "        if not in_hedge:\n",
                "            if vix < vix_entry and peak > entry_peak:\n",
                "                in_hedge = True\n",
                "        else:\n",
                "            if peak < exit_peak:\n",
                "                in_hedge = False\n",
                "        states.append(in_hedge)\n",
                "    \n",
                "    df['in_hedge'] = states\n",
                "    df['strategy_ret'] = np.where(df['in_hedge'], df['safe_ret'], df['daily_ret'])\n",
                "    \n",
                "    df['cum_bnh'] = (1 + df['daily_ret'].fillna(0)).cumprod()\n",
                "    df['cum_strat'] = (1 + df['strategy_ret'].fillna(0)).cumprod()\n",
                "    \n",
                "    return df\n",
                "\n",
                "print(\"‚úÖ Functions defined\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "run_all"
            },
            "outputs": [],
            "source": [
                "# @title 4. Run Analysis for All Asset Classes\n",
                "\n",
                "results = {}\n",
                "\n",
                "for asset_class, data in all_data.items():\n",
                "    print(f\"\\n{'='*60}\")\n",
                "    print(f\"üìä Analyzing: {asset_class}\")\n",
                "    print(f\"{'='*60}\")\n",
                "    \n",
                "    sectors = data['sectors']\n",
                "    if sectors.empty or sectors.shape[1] < 3:\n",
                "        print(f\"   ‚ö†Ô∏è Insufficient data for {asset_class}\")\n",
                "        continue\n",
                "    \n",
                "    # Calculate structural metrics\n",
                "    print(f\"   Calculating structural metrics ({sectors.shape[1]} assets)...\")\n",
                "    struct = calculate_structural_metrics(sectors, window=min(252, len(sectors)//3), min_assets=3)\n",
                "    \n",
                "    if struct.empty:\n",
                "        print(f\"   ‚ö†Ô∏è Could not calculate metrics for {asset_class}\")\n",
                "        continue\n",
                "    \n",
                "    # Merge with market data\n",
                "    idx = struct.index.intersection(data['main'].index).intersection(data['vol'].index)\n",
                "    if len(idx) < 500:\n",
                "        idx = struct.index.intersection(data['main'].index)\n",
                "    \n",
                "    df = struct.loc[idx].copy()\n",
                "    df['price'] = data['main'].reindex(idx)\n",
                "    df['volatility'] = data['vol'].reindex(idx).ffill()\n",
                "    df['safe'] = data['safe'].reindex(idx).ffill()\n",
                "    \n",
                "    # Add signals\n",
                "    df = add_signals(df)\n",
                "    df['future_ret_22'] = df['price'].pct_change(22).shift(-22)\n",
                "    df = df.dropna()\n",
                "    \n",
                "    print(f\"   Dataset: {len(df)} observations\")\n",
                "    print(f\"   Period: {df.index.min().date()} to {df.index.max().date()}\")\n",
                "    \n",
                "    if len(df) < 500:\n",
                "        print(f\"   ‚ö†Ô∏è Insufficient observations for {asset_class}\")\n",
                "        continue\n",
                "    \n",
                "    # Run Quantile Regression\n",
                "    print(f\"   Running Quantile Regression...\")\n",
                "    \n",
                "    # Use volatility-based filtering if VIX available\n",
                "    if 'volatility' in df.columns and df['volatility'].notna().sum() > 100:\n",
                "        low_vol = df[df['volatility'] < df['volatility'].quantile(0.6)].copy()\n",
                "    else:\n",
                "        low_vol = df.copy()\n",
                "    \n",
                "    try:\n",
                "        mod_base = smf.quantreg('future_ret_22 ~ absorp_z', low_vol)\n",
                "        res_base = mod_base.fit(q=0.05)\n",
                "        \n",
                "        mod_peak = smf.quantreg('future_ret_22 ~ absorp_z + caria_peak', low_vol)\n",
                "        res_peak = mod_peak.fit(q=0.05)\n",
                "        \n",
                "        imp = ((res_peak.prsquared - res_base.prsquared) / res_base.prsquared) * 100 if res_base.prsquared > 0 else 0\n",
                "        \n",
                "        print(f\"   Base R¬≤: {res_base.prsquared:.5f}\")\n",
                "        print(f\"   Peak R¬≤: {res_peak.prsquared:.5f}\")\n",
                "        print(f\"   üî• Improvement: {imp:.1f}%\")\n",
                "    except Exception as e:\n",
                "        print(f\"   ‚ö†Ô∏è QR Error: {e}\")\n",
                "        imp = 0\n",
                "    \n",
                "    # Run Minsky Hedge\n",
                "    print(f\"   Running Minsky Hedge...\")\n",
                "    df = run_minsky_hedge(df)\n",
                "    \n",
                "    years = len(df) / 252\n",
                "    dd_bnh = get_max_drawdown(df['cum_bnh'])\n",
                "    dd_strat = get_max_drawdown(df['cum_strat'])\n",
                "    cagr_bnh = (df['cum_bnh'].iloc[-1])**(1/years) - 1 if years > 0 else 0\n",
                "    cagr_strat = (df['cum_strat'].iloc[-1])**(1/years) - 1 if years > 0 else 0\n",
                "    \n",
                "    print(f\"   Benchmark: DD={dd_bnh:.1%}, CAGR={cagr_bnh:.1%}\")\n",
                "    print(f\"   Minsky:    DD={dd_strat:.1%}, CAGR={cagr_strat:.1%}\")\n",
                "    print(f\"   Time in Hedge: {df['in_hedge'].mean()*100:.1f}%\")\n",
                "    \n",
                "    results[asset_class] = {\n",
                "        'df': df,\n",
                "        'qr_improvement': imp,\n",
                "        'dd_bnh': dd_bnh,\n",
                "        'dd_strat': dd_strat,\n",
                "        'cagr_bnh': cagr_bnh,\n",
                "        'cagr_strat': cagr_strat,\n",
                "        'hedge_time': df['in_hedge'].mean()\n",
                "    }\n",
                "\n",
                "print(\"\\n‚úÖ Analysis complete\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "summary_table"
            },
            "outputs": [],
            "source": [
                "# @title 5. Summary Table\n",
                "\n",
                "summary_rows = []\n",
                "for asset_class, res in results.items():\n",
                "    summary_rows.append({\n",
                "        'Asset Class': asset_class,\n",
                "        'QR Improvement (%)': f\"{res['qr_improvement']:.1f}\",\n",
                "        'Benchmark DD': f\"{res['dd_bnh']:.1%}\",\n",
                "        'Minsky DD': f\"{res['dd_strat']:.1%}\",\n",
                "        'DD Reduction': f\"{res['dd_bnh'] - res['dd_strat']:.1%}\",\n",
                "        'Benchmark CAGR': f\"{res['cagr_bnh']:.1%}\",\n",
                "        'Minsky CAGR': f\"{res['cagr_strat']:.1%}\",\n",
                "        'Time in Hedge': f\"{res['hedge_time']*100:.1f}%\"\n",
                "    })\n",
                "\n",
                "summary_df = pd.DataFrame(summary_rows)\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"MULTI-ASSET CARIA-SR VALIDATION SUMMARY\")\n",
                "print(\"=\"*80)\n",
                "print(summary_df.to_string(index=False))\n",
                "\n",
                "summary_df.to_csv(f'{WORK_DIR}/tables/Multi_Asset_Summary.csv', index=False)\n",
                "print(f\"\\n‚úÖ Saved to {WORK_DIR}/tables/Multi_Asset_Summary.csv\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "equity_curves"
            },
            "outputs": [],
            "source": [
                "# @title 6. Equity Curves (All Asset Classes)\n",
                "\n",
                "n_assets = len(results)\n",
                "if n_assets > 0:\n",
                "    fig, axes = plt.subplots(n_assets, 1, figsize=(14, 5*n_assets))\n",
                "    if n_assets == 1:\n",
                "        axes = [axes]\n",
                "    \n",
                "    for ax, (asset_class, res) in zip(axes, results.items()):\n",
                "        df = res['df']\n",
                "        ax.plot(df.index, df['cum_bnh'], label=f\"Buy&Hold (DD:{res['dd_bnh']:.1%})\", color='gray', alpha=0.6)\n",
                "        ax.plot(df.index, df['cum_strat'], label=f\"Minsky (DD:{res['dd_strat']:.1%})\", color='blue', linewidth=2)\n",
                "        ax.set_yscale('log')\n",
                "        ax.set_title(f'{asset_class}: QR Improvement = {res[\"qr_improvement\"]:.1f}%', fontsize=14, fontweight='bold')\n",
                "        ax.legend(loc='upper left')\n",
                "        ax.grid(True, alpha=0.3)\n",
                "        \n",
                "        # Highlight hedge periods\n",
                "        hedge_starts = df[df['in_hedge'] & ~df['in_hedge'].shift(1).fillna(False)].index\n",
                "        hedge_ends = df[~df['in_hedge'] & df['in_hedge'].shift(1).fillna(False)].index\n",
                "        for start in hedge_starts[:20]:  # Limit to 20 for clarity\n",
                "            ax.axvline(x=start, color='red', alpha=0.2, linewidth=0.5)\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.savefig(f'{WORK_DIR}/figures/Multi_Asset_Equity.png', dpi=300)\n",
                "    plt.show()\n",
                "else:\n",
                "    print(\"No results to plot\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "crisis_dd"
            },
            "outputs": [],
            "source": [
                "# @title 7. Crisis-Specific Drawdown Analysis\n",
                "\n",
                "CRISES = {\n",
                "    'Black Monday 1987': ('1987-08-01', '1987-12-31'),\n",
                "    'Dot-Com Crash': ('2000-03-01', '2002-10-31'),\n",
                "    'GFC 2008': ('2007-10-01', '2009-03-31'),\n",
                "    'Euro Crisis 2011': ('2011-07-01', '2011-10-31'),\n",
                "    'COVID 2020': ('2020-02-01', '2020-04-30'),\n",
                "    'Rate Hikes 2022': ('2022-01-01', '2022-10-31')\n",
                "}\n",
                "\n",
                "crisis_results = []\n",
                "\n",
                "for asset_class, res in results.items():\n",
                "    df = res['df']\n",
                "    \n",
                "    for crisis_name, (start, end) in CRISES.items():\n",
                "        try:\n",
                "            period = df.loc[start:end]\n",
                "            if len(period) < 20:\n",
                "                continue\n",
                "            \n",
                "            dd_bnh = get_max_drawdown(period['cum_bnh'] / period['cum_bnh'].iloc[0])\n",
                "            dd_strat = get_max_drawdown(period['cum_strat'] / period['cum_strat'].iloc[0])\n",
                "            hedge_pct = period['in_hedge'].mean() * 100\n",
                "            \n",
                "            crisis_results.append({\n",
                "                'Asset': asset_class,\n",
                "                'Crisis': crisis_name,\n",
                "                'BnH DD': f\"{dd_bnh:.1%}\",\n",
                "                'Minsky DD': f\"{dd_strat:.1%}\",\n",
                "                'Protection': f\"{dd_bnh - dd_strat:.1%}\",\n",
                "                'Hedge %': f\"{hedge_pct:.0f}%\"\n",
                "            })\n",
                "        except:\n",
                "            pass\n",
                "\n",
                "if crisis_results:\n",
                "    crisis_df = pd.DataFrame(crisis_results)\n",
                "    print(\"\\n\" + \"=\"*80)\n",
                "    print(\"CRISIS-SPECIFIC DRAWDOWN ANALYSIS\")\n",
                "    print(\"=\"*80)\n",
                "    print(crisis_df.to_string(index=False))\n",
                "    crisis_df.to_csv(f'{WORK_DIR}/tables/Crisis_Drawdowns.csv', index=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "bootstrap"
            },
            "outputs": [],
            "source": [
                "# @title 8. Bootstrap Confidence Intervals (All Assets)\n",
                "\n",
                "n_boot = 500  # Reduced for speed\n",
                "bootstrap_results = []\n",
                "\n",
                "for asset_class, res in results.items():\n",
                "    print(f\"\\nBootstrapping {asset_class}...\")\n",
                "    df = res['df'].copy()\n",
                "    \n",
                "    improvements = []\n",
                "    for i in range(n_boot):\n",
                "        sample = df.sample(n=len(df), replace=True)\n",
                "        try:\n",
                "            r_base = smf.quantreg('future_ret_22 ~ absorp_z', sample).fit(q=0.05).prsquared\n",
                "            r_peak = smf.quantreg('future_ret_22 ~ absorp_z + caria_peak', sample).fit(q=0.05).prsquared\n",
                "            if r_base > 0:\n",
                "                improvements.append((r_peak - r_base) / r_base)\n",
                "        except:\n",
                "            pass\n",
                "    \n",
                "    if improvements:\n",
                "        bootstrap_results.append({\n",
                "            'Asset': asset_class,\n",
                "            'Mean Improvement': f\"{np.mean(improvements):.1%}\",\n",
                "            '95% CI Lower': f\"{np.percentile(improvements, 2.5):.1%}\",\n",
                "            '95% CI Upper': f\"{np.percentile(improvements, 97.5):.1%}\",\n",
                "            'P(Imp > 0)': f\"{np.mean(np.array(improvements) > 0):.1%}\"\n",
                "        })\n",
                "\n",
                "if bootstrap_results:\n",
                "    boot_df = pd.DataFrame(bootstrap_results)\n",
                "    print(\"\\n\" + \"=\"*60)\n",
                "    print(\"BOOTSTRAP RESULTS\")\n",
                "    print(\"=\"*60)\n",
                "    print(boot_df.to_string(index=False))\n",
                "    boot_df.to_csv(f'{WORK_DIR}/tables/Bootstrap_Results.csv', index=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "final"
            },
            "outputs": [],
            "source": [
                "# @title 9. Final Summary\n",
                "\n",
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"üî¨ CARIA-SR EXTENDED VALIDATION COMPLETE\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "print(f\"\\nüìä Asset Classes Tested: {len(results)}\")\n",
                "for asset_class, res in results.items():\n",
                "    print(f\"\\n   {asset_class}:\")\n",
                "    print(f\"      QR Improvement: {res['qr_improvement']:.1f}%\")\n",
                "    print(f\"      DD Reduction: {res['dd_bnh'] - res['dd_strat']:.1%}\")\n",
                "\n",
                "print(f\"\\nüìÅ Files saved to: {WORK_DIR}\")\n",
                "print(\"\\n‚úÖ DONE!\")"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}