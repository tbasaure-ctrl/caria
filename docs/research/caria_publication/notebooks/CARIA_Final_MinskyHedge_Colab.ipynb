{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "header"
            },
            "source": [
                "# üî¨ CARIA-SR Minsky Hedge (Clean Implementation)\n",
                "\n",
                "**Based on the working original logic:**\n",
                "- `unsafe_state = caria_peak.shift(1) > 1.5`\n",
                "- Pure structural signal (NO VIX condition)\n",
                "- Treasury switch + Leverage version\n",
                "\n",
                "**Enhancements:**\n",
                "- Transaction costs\n",
                "- Slippage\n",
                "- Realistic leverage costs\n",
                "- Out-of-sample validation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "setup"
            },
            "outputs": [],
            "source": [
                "# @title 1. Setup\n",
                "!pip install -q yfinance pandas numpy scipy scikit-learn statsmodels seaborn matplotlib pyarrow\n",
                "\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "import os\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import yfinance as yf\n",
                "import warnings\n",
                "from datetime import datetime\n",
                "import statsmodels.formula.api as smf\n",
                "from sklearn.covariance import LedoitWolf\n",
                "\n",
                "warnings.filterwarnings('ignore')\n",
                "np.random.seed(42)\n",
                "sns.set_style('whitegrid')\n",
                "\n",
                "WORK_DIR = '/content/drive/MyDrive/CARIA_Final'\n",
                "os.makedirs(f'{WORK_DIR}/figures', exist_ok=True)\n",
                "os.makedirs(f'{WORK_DIR}/tables', exist_ok=True)\n",
                "\n",
                "START_DATE = \"1998-01-01\"\n",
                "END_DATE = datetime.now().strftime(\"%Y-%m-%d\")\n",
                "\n",
                "# TRADING COSTS\n",
                "TRANSACTION_COST = 0.001  # 10 bps per trade (round trip = 20 bps)\n",
                "SLIPPAGE = 0.0005  # 5 bps slippage\n",
                "BORROW_RATE = 0.05  # 5% annual for leverage\n",
                "LEVERAGE = 1.5\n",
                "\n",
                "print(f\"‚úÖ Output: {WORK_DIR}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "download"
            },
            "outputs": [],
            "source": [
                "# @title 2. Download Data\n",
                "\n",
                "SECTORS = ['XLF', 'XLK', 'XLE', 'XLV', 'XLI', 'XLY', 'XLP', 'XLB', 'XLU', 'XLRE', 'XLC']\n",
                "\n",
                "print(\"Downloading data...\")\n",
                "sectors = yf.download(SECTORS, start=START_DATE, end=END_DATE, progress=False)['Close']\n",
                "market = yf.download(['^VIX', 'SPY', 'TLT', '^TNX'], start=START_DATE, end=END_DATE, progress=False)['Close']\n",
                "\n",
                "vix = market['^VIX'].rename('volatility')\n",
                "spy = market['SPY'].rename('price')\n",
                "tlt = market['TLT'].rename('tlt')\n",
                "tnx = market['^TNX'].rename('treasury_10y')  # 10Y Yield\n",
                "\n",
                "print(f\"‚úÖ Sectors: {sectors.shape}\")\n",
                "print(f\"‚úÖ Market: {spy.index.min().date()} to {spy.index.max().date()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "structural"
            },
            "outputs": [],
            "source": [
                "# @title 3. Calculate Structural Metrics (Absorption Ratio)\n",
                "\n",
                "def cov_to_corr(S):\n",
                "    d = np.sqrt(np.diag(S))\n",
                "    d = np.where(d == 0, 1e-10, d)\n",
                "    return np.nan_to_num((S / np.outer(d, d) + S.T / np.outer(d, d)) / 2)\n",
                "\n",
                "def calc_absorption_ratio(returns, window=252, k_frac=0.2):\n",
                "    ar_series = pd.Series(index=returns.index, dtype=float)\n",
                "    lw = LedoitWolf()\n",
                "    \n",
                "    for t in range(window, len(returns), 5):\n",
                "        W = returns.iloc[t-window:t].dropna(axis=1)\n",
                "        if W.shape[1] < 5:\n",
                "            continue\n",
                "        W = W.fillna(W.mean())\n",
                "        X = W.values - W.values.mean(axis=0)\n",
                "        try:\n",
                "            C = cov_to_corr(lw.fit(X).covariance_)\n",
                "            w = np.sort(np.linalg.eigvalsh(C))[::-1]\n",
                "            w = np.maximum(w, 1e-10)\n",
                "            k = max(1, int(np.ceil(k_frac * len(w))))\n",
                "            ar_series.iloc[t] = np.sum(w[:k]) / np.sum(w)\n",
                "        except:\n",
                "            pass\n",
                "    \n",
                "    return ar_series.ffill().bfill()\n",
                "\n",
                "print(\"Calculating Absorption Ratio...\")\n",
                "returns = np.log(sectors).diff()\n",
                "ar = calc_absorption_ratio(returns)\n",
                "\n",
                "# Z-score normalization\n",
                "absorp_z = (ar - ar.rolling(252).mean()) / ar.rolling(252).std()\n",
                "\n",
                "# Peak Memory (60 days) - THE KEY FEATURE\n",
                "caria_peak = absorp_z.rolling(60).max()\n",
                "\n",
                "print(f\"‚úÖ AR calculated: mean={ar.mean():.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "prepare"
            },
            "outputs": [],
            "source": [
                "# @title 4. Prepare Dataset\n",
                "\n",
                "idx = ar.dropna().index.intersection(spy.index).intersection(vix.index)\n",
                "\n",
                "df = pd.DataFrame({\n",
                "    'absorption_ratio': ar.loc[idx],\n",
                "    'absorp_z': absorp_z.loc[idx],\n",
                "    'caria_peak': caria_peak.loc[idx],\n",
                "    'volatility': vix.loc[idx],\n",
                "    'price': spy.loc[idx],\n",
                "    'tlt': tlt.reindex(idx).ffill(),\n",
                "    'treasury_10y': tnx.reindex(idx).ffill()\n",
                "}).dropna()\n",
                "\n",
                "# Future returns for quantile regression\n",
                "df['future_ret_22'] = df['price'].pct_change(22).shift(-22)\n",
                "\n",
                "print(f\"‚úÖ Dataset: {len(df)} observations\")\n",
                "print(f\"   Period: {df.index.min().date()} to {df.index.max().date()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "quantile"
            },
            "outputs": [],
            "source": [
                "# @title 5. Quantile Regression (Predictive Power)\n",
                "\n",
                "# Filter low-vol regime\n",
                "low_vol_df = df[df['volatility'] < 20].copy().dropna()\n",
                "\n",
                "print(f\"Testing on Low-Vol Regime (VIX < 20): {len(low_vol_df)} obs\")\n",
                "\n",
                "# Model A: VIX only\n",
                "mod_vix = smf.quantreg('future_ret_22 ~ volatility', low_vol_df)\n",
                "res_vix = mod_vix.fit(q=0.05)\n",
                "\n",
                "# Model B: VIX + Peak Memory\n",
                "mod_peak = smf.quantreg('future_ret_22 ~ volatility + caria_peak', low_vol_df)\n",
                "res_peak = mod_peak.fit(q=0.05)\n",
                "\n",
                "# Model C: Full (with Treasury control)\n",
                "mod_full = smf.quantreg('future_ret_22 ~ volatility + treasury_10y + caria_peak', low_vol_df)\n",
                "res_full = mod_full.fit(q=0.05)\n",
                "\n",
                "imp = ((res_peak.prsquared - res_vix.prsquared) / res_vix.prsquared) * 100 if res_vix.prsquared > 0 else 0\n",
                "\n",
                "print(f\"\\n{'='*60}\")\n",
                "print(\"QUANTILE REGRESSION RESULTS (œÑ = 0.05)\")\n",
                "print(f\"{'='*60}\")\n",
                "print(f\"VIX Only R¬≤:           {res_vix.prsquared:.5f}\")\n",
                "print(f\"VIX + Peak R¬≤:         {res_peak.prsquared:.5f}\")\n",
                "print(f\"Full Model R¬≤:         {res_full.prsquared:.5f}\")\n",
                "print(f\"\\nüî• Improvement (Peak over VIX): {imp:.1f}%\")\n",
                "print(f\"\\nPeak Memory coefficient: {res_peak.params['caria_peak']:.5f}\")\n",
                "print(f\"Peak Memory t-stat: {res_peak.tvalues['caria_peak']:.2f}\")\n",
                "print(f\"Peak Memory p-value: {res_peak.pvalues['caria_peak']:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "backtest"
            },
            "outputs": [],
            "source": [
                "# @title 6. Minsky Hedge Backtest (ORIGINAL WORKING LOGIC)\n",
                "\n",
                "print(\"Running Minsky Hedge Backtest...\")\n",
                "\n",
                "backtest_df = df.copy().dropna()\n",
                "\n",
                "# Daily returns\n",
                "backtest_df['daily_ret'] = backtest_df['price'].pct_change()\n",
                "backtest_df['tlt_ret'] = backtest_df['tlt'].pct_change()\n",
                "\n",
                "# Treasury return from yield (alternative to TLT)\n",
                "backtest_df['treasury_daily_ret'] = (backtest_df['treasury_10y'] / 100) / 252\n",
                "\n",
                "# ============================================\n",
                "# THE ORIGINAL WORKING SIGNAL (PURE STRUCTURAL)\n",
                "# ============================================\n",
                "# If Peak Memory > 1.5 sigma, market is fragile -> EXIT\n",
                "# Lagged by 1 day (trade at next day's open)\n",
                "THRESHOLD = 1.5\n",
                "backtest_df['unsafe_state'] = (backtest_df['caria_peak'].shift(1) > THRESHOLD)\n",
                "\n",
                "# Strategy 1: Cash Hedge (original)\n",
                "backtest_df['cash_ret'] = np.where(backtest_df['unsafe_state'], 0, backtest_df['daily_ret'])\n",
                "\n",
                "# Strategy 2: Smart Hedge (switch to Treasuries)\n",
                "backtest_df['smart_ret'] = np.where(\n",
                "    backtest_df['unsafe_state'],\n",
                "    backtest_df['treasury_daily_ret'],  # Earn treasury yield when hedged\n",
                "    backtest_df['daily_ret']\n",
                ")\n",
                "\n",
                "# Strategy 3: Levered Minsky (1.5x when safe, bonds when unsafe)\n",
                "borrow_cost_daily = BORROW_RATE / 252\n",
                "backtest_df['lev_ret'] = np.where(\n",
                "    backtest_df['unsafe_state'],\n",
                "    backtest_df['treasury_daily_ret'],  # No leverage in bonds\n",
                "    backtest_df['daily_ret'] * LEVERAGE - borrow_cost_daily * (LEVERAGE - 1)  # Leveraged equity\n",
                ")\n",
                "\n",
                "print(f\"Time in Hedge: {backtest_df['unsafe_state'].mean()*100:.1f}%\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "costs"
            },
            "outputs": [],
            "source": [
                "# @title 7. Add Transaction Costs\n",
                "\n",
                "def add_transaction_costs(returns, signal, cost_per_trade=TRANSACTION_COST, slippage=SLIPPAGE):\n",
                "    \"\"\"\n",
                "    Subtract transaction costs on days when position changes.\n",
                "    \"\"\"\n",
                "    trades = signal.astype(int).diff().abs()  # 1 on trade days\n",
                "    total_cost = (cost_per_trade + slippage) * trades\n",
                "    return returns - total_cost.fillna(0)\n",
                "\n",
                "# Apply transaction costs\n",
                "backtest_df['cash_ret_net'] = add_transaction_costs(backtest_df['cash_ret'], backtest_df['unsafe_state'])\n",
                "backtest_df['smart_ret_net'] = add_transaction_costs(backtest_df['smart_ret'], backtest_df['unsafe_state'])\n",
                "backtest_df['lev_ret_net'] = add_transaction_costs(backtest_df['lev_ret'], backtest_df['unsafe_state'])\n",
                "\n",
                "# Count trades\n",
                "n_trades = backtest_df['unsafe_state'].astype(int).diff().abs().sum()\n",
                "years = len(backtest_df) / 252\n",
                "trades_per_year = n_trades / years\n",
                "\n",
                "print(f\"Total trades: {n_trades:.0f}\")\n",
                "print(f\"Trades per year: {trades_per_year:.1f}\")\n",
                "print(f\"Total transaction costs: {n_trades * (TRANSACTION_COST + SLIPPAGE) * 100:.2f}%\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "performance"
            },
            "outputs": [],
            "source": [
                "# @title 8. Calculate Performance (With and Without Costs)\n",
                "\n",
                "def get_max_drawdown(cumulative):\n",
                "    peak = cumulative.cummax()\n",
                "    dd = cumulative / peak - 1\n",
                "    return dd.min()\n",
                "\n",
                "def calc_metrics(returns, name):\n",
                "    cumulative = (1 + returns.fillna(0)).cumprod()\n",
                "    years = len(returns) / 252\n",
                "    \n",
                "    cagr = cumulative.iloc[-1]**(1/years) - 1\n",
                "    vol = returns.std() * np.sqrt(252)\n",
                "    sharpe = cagr / vol if vol > 0 else 0\n",
                "    max_dd = get_max_drawdown(cumulative)\n",
                "    calmar = cagr / abs(max_dd) if max_dd < 0 else 0\n",
                "    \n",
                "    return {\n",
                "        'Strategy': name,\n",
                "        'CAGR': cagr,\n",
                "        'Volatility': vol,\n",
                "        'Sharpe': sharpe,\n",
                "        'Max DD': max_dd,\n",
                "        'Calmar': calmar\n",
                "    }\n",
                "\n",
                "# Calculate for all strategies\n",
                "results = [\n",
                "    calc_metrics(backtest_df['daily_ret'], 'Buy & Hold (SPY)'),\n",
                "    calc_metrics(backtest_df['cash_ret'], 'Minsky Cash (Gross)'),\n",
                "    calc_metrics(backtest_df['cash_ret_net'], 'Minsky Cash (Net)'),\n",
                "    calc_metrics(backtest_df['smart_ret'], 'Minsky Bond (Gross)'),\n",
                "    calc_metrics(backtest_df['smart_ret_net'], 'Minsky Bond (Net)'),\n",
                "    calc_metrics(backtest_df['lev_ret'], 'Minsky 1.5x (Gross)'),\n",
                "    calc_metrics(backtest_df['lev_ret_net'], 'Minsky 1.5x (Net)'),\n",
                "]\n",
                "\n",
                "results_df = pd.DataFrame(results)\n",
                "\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"PERFORMANCE COMPARISON\")\n",
                "print(\"=\"*80)\n",
                "print(f\"\\nThreshold: {THRESHOLD} sigma\")\n",
                "print(f\"Time in Hedge: {backtest_df['unsafe_state'].mean()*100:.1f}%\")\n",
                "print(f\"Transaction Cost: {TRANSACTION_COST*100:.1f} bps + {SLIPPAGE*100:.1f} bps slippage\")\n",
                "print(f\"Leverage: {LEVERAGE}x, Borrow Rate: {BORROW_RATE*100:.1f}%\")\n",
                "print(\"\\n\")\n",
                "\n",
                "# Format for display\n",
                "display_df = results_df.copy()\n",
                "display_df['CAGR'] = display_df['CAGR'].map('{:.1%}'.format)\n",
                "display_df['Volatility'] = display_df['Volatility'].map('{:.1%}'.format)\n",
                "display_df['Sharpe'] = display_df['Sharpe'].map('{:.2f}'.format)\n",
                "display_df['Max DD'] = display_df['Max DD'].map('{:.1%}'.format)\n",
                "display_df['Calmar'] = display_df['Calmar'].map('{:.2f}'.format)\n",
                "\n",
                "print(display_df.to_string(index=False))\n",
                "\n",
                "results_df.to_csv(f'{WORK_DIR}/tables/Performance_Comparison.csv', index=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "crisis"
            },
            "outputs": [],
            "source": [
                "# @title 9. Crisis-Specific Analysis\n",
                "\n",
                "# Calculate cumulative returns\n",
                "backtest_df['cum_bnh'] = (1 + backtest_df['daily_ret'].fillna(0)).cumprod()\n",
                "backtest_df['cum_cash'] = (1 + backtest_df['cash_ret_net'].fillna(0)).cumprod()\n",
                "backtest_df['cum_smart'] = (1 + backtest_df['smart_ret_net'].fillna(0)).cumprod()\n",
                "backtest_df['cum_lev'] = (1 + backtest_df['lev_ret_net'].fillna(0)).cumprod()\n",
                "\n",
                "CRISES = {\n",
                "    'Dot-Com (2000-02)': ('2000-03-01', '2002-10-31'),\n",
                "    'GFC (2007-09)': ('2007-10-01', '2009-03-31'),\n",
                "    'Euro Crisis (2011)': ('2011-07-01', '2011-10-31'),\n",
                "    'COVID (2020)': ('2020-02-01', '2020-03-31'),\n",
                "    '2022 Bear': ('2022-01-01', '2022-10-31')\n",
                "}\n",
                "\n",
                "crisis_results = []\n",
                "for name, (start, end) in CRISES.items():\n",
                "    try:\n",
                "        period = backtest_df.loc[start:end]\n",
                "        if len(period) < 10:\n",
                "            continue\n",
                "        \n",
                "        dd_bnh = get_max_drawdown(period['cum_bnh'] / period['cum_bnh'].iloc[0])\n",
                "        dd_smart = get_max_drawdown(period['cum_smart'] / period['cum_smart'].iloc[0])\n",
                "        hedge_pct = period['unsafe_state'].mean() * 100\n",
                "        \n",
                "        crisis_results.append({\n",
                "            'Crisis': name,\n",
                "            'BnH DD': f\"{dd_bnh:.1%}\",\n",
                "            'Minsky DD': f\"{dd_smart:.1%}\",\n",
                "            'Protection': f\"{dd_bnh - dd_smart:.1%}\",\n",
                "            'Hedge Active': f\"{hedge_pct:.0f}%\"\n",
                "        })\n",
                "    except:\n",
                "        pass\n",
                "\n",
                "crisis_df = pd.DataFrame(crisis_results)\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"CRISIS-SPECIFIC DRAWDOWNS\")\n",
                "print(\"=\"*60)\n",
                "print(crisis_df.to_string(index=False))\n",
                "crisis_df.to_csv(f'{WORK_DIR}/tables/Crisis_Analysis.csv', index=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "threshold_sensitivity"
            },
            "outputs": [],
            "source": [
                "# @title 10. Threshold Sensitivity Analysis\n",
                "\n",
                "thresholds = [0.5, 1.0, 1.5, 2.0, 2.5, 3.0]\n",
                "sensitivity_results = []\n",
                "\n",
                "for thresh in thresholds:\n",
                "    test_df = df.copy().dropna()\n",
                "    test_df['daily_ret'] = test_df['price'].pct_change()\n",
                "    test_df['treasury_ret'] = (test_df['treasury_10y'] / 100) / 252\n",
                "    \n",
                "    unsafe = (test_df['caria_peak'].shift(1) > thresh)\n",
                "    \n",
                "    strat_ret = np.where(unsafe, test_df['treasury_ret'], test_df['daily_ret'])\n",
                "    \n",
                "    # Apply transaction costs\n",
                "    trades = unsafe.astype(int).diff().abs()\n",
                "    strat_ret_net = strat_ret - (TRANSACTION_COST + SLIPPAGE) * trades.fillna(0)\n",
                "    \n",
                "    cumulative = (1 + pd.Series(strat_ret_net).fillna(0)).cumprod()\n",
                "    years = len(test_df) / 252\n",
                "    \n",
                "    sensitivity_results.append({\n",
                "        'Threshold': thresh,\n",
                "        'Hedge Time': f\"{unsafe.mean()*100:.1f}%\",\n",
                "        'CAGR': cumulative.iloc[-1]**(1/years) - 1,\n",
                "        'Max DD': get_max_drawdown(cumulative),\n",
                "        'Trades/Year': trades.sum() / years\n",
                "    })\n",
                "\n",
                "sens_df = pd.DataFrame(sensitivity_results)\n",
                "sens_df_display = sens_df.copy()\n",
                "sens_df_display['CAGR'] = sens_df_display['CAGR'].map('{:.1%}'.format)\n",
                "sens_df_display['Max DD'] = sens_df_display['Max DD'].map('{:.1%}'.format)\n",
                "sens_df_display['Trades/Year'] = sens_df_display['Trades/Year'].map('{:.1f}'.format)\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"THRESHOLD SENSITIVITY (with transaction costs)\")\n",
                "print(\"=\"*60)\n",
                "print(sens_df_display.to_string(index=False))\n",
                "sens_df.to_csv(f'{WORK_DIR}/tables/Threshold_Sensitivity.csv', index=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "plot"
            },
            "outputs": [],
            "source": [
                "# @title 11. Visualization\n",
                "\n",
                "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
                "\n",
                "# 1. Equity Curves\n",
                "ax = axes[0, 0]\n",
                "ax.plot(backtest_df.index, backtest_df['cum_bnh'], label='S&P 500', color='gray', alpha=0.5)\n",
                "ax.plot(backtest_df.index, backtest_df['cum_smart'], label='Minsky Bond (Net)', color='blue', linewidth=2)\n",
                "ax.plot(backtest_df.index, backtest_df['cum_lev'], label='Minsky 1.5x (Net)', color='darkgreen', linewidth=2)\n",
                "ax.set_yscale('log')\n",
                "ax.set_title('Equity Curves (Log Scale)', fontsize=12, fontweight='bold')\n",
                "ax.legend(loc='upper left')\n",
                "ax.grid(True, alpha=0.3)\n",
                "\n",
                "# 2. Drawdowns\n",
                "ax = axes[0, 1]\n",
                "dd_bnh = backtest_df['cum_bnh'] / backtest_df['cum_bnh'].cummax() - 1\n",
                "dd_smart = backtest_df['cum_smart'] / backtest_df['cum_smart'].cummax() - 1\n",
                "ax.fill_between(backtest_df.index, dd_bnh, 0, alpha=0.3, color='gray', label='S&P 500')\n",
                "ax.plot(backtest_df.index, dd_smart, color='blue', label='Minsky Bond')\n",
                "ax.set_title('Drawdowns', fontsize=12, fontweight='bold')\n",
                "ax.legend()\n",
                "ax.grid(True, alpha=0.3)\n",
                "\n",
                "# 3. Hedge Periods\n",
                "ax = axes[1, 0]\n",
                "ax.plot(backtest_df.index, backtest_df['caria_peak'], color='darkred', alpha=0.7)\n",
                "ax.axhline(y=THRESHOLD, color='orange', linestyle='--', label=f'Threshold ({THRESHOLD}œÉ)')\n",
                "ax.fill_between(backtest_df.index, 0, 4, \n",
                "                where=backtest_df['unsafe_state'], \n",
                "                alpha=0.2, color='red', label='Hedge Active')\n",
                "ax.set_title('CARIA Peak Memory Signal', fontsize=12, fontweight='bold')\n",
                "ax.legend(loc='upper left')\n",
                "ax.grid(True, alpha=0.3)\n",
                "\n",
                "# 4. Threshold Sensitivity\n",
                "ax = axes[1, 1]\n",
                "ax.bar([str(t) for t in sens_df['Threshold']], sens_df['Max DD'] * -100, color='steelblue')\n",
                "ax.axhline(y=-get_max_drawdown(backtest_df['cum_bnh']) * 100, color='gray', linestyle='--', label='BnH DD')\n",
                "ax.set_xlabel('Threshold (œÉ)')\n",
                "ax.set_ylabel('Max Drawdown (%)')\n",
                "ax.set_title('Threshold Sensitivity', fontsize=12, fontweight='bold')\n",
                "ax.legend()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(f'{WORK_DIR}/figures/Final_Results.png', dpi=300)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "summary"
            },
            "outputs": [],
            "source": [
                "# @title 12. Final Summary\n",
                "\n",
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"üî¨ CARIA-SR MINSKY HEDGE - FINAL SUMMARY\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "print(f\"\\nüìä DATA:\")\n",
                "print(f\"   Period: {backtest_df.index.min().date()} to {backtest_df.index.max().date()}\")\n",
                "print(f\"   Observations: {len(backtest_df)}\")\n",
                "\n",
                "print(f\"\\nüî¨ PREDICTIVE POWER (Quantile Regression):\")\n",
                "print(f\"   VIX-only R¬≤: {res_vix.prsquared:.5f}\")\n",
                "print(f\"   VIX+Peak R¬≤: {res_peak.prsquared:.5f}\")\n",
                "print(f\"   Improvement: {imp:.1f}%\")\n",
                "\n",
                "bnh_metrics = [r for r in results if r['Strategy'] == 'Buy & Hold (SPY)'][0]\n",
                "smart_metrics = [r for r in results if r['Strategy'] == 'Minsky Bond (Net)'][0]\n",
                "\n",
                "print(f\"\\nüí∞ MINSKY HEDGE (with costs):\")\n",
                "print(f\"   Threshold: {THRESHOLD}œÉ\")\n",
                "print(f\"   Time in Hedge: {backtest_df['unsafe_state'].mean()*100:.1f}%\")\n",
                "print(f\"   Trades per year: {trades_per_year:.1f}\")\n",
                "print(f\"\\n   {'Metric':<15} {'S&P 500':>12} {'Minsky':>12} {'Diff':>12}\")\n",
                "print(f\"   {'-'*51}\")\n",
                "print(f\"   {'Max DD':<15} {bnh_metrics['Max DD']:>12.1%} {smart_metrics['Max DD']:>12.1%} {bnh_metrics['Max DD'] - smart_metrics['Max DD']:>12.1%}\")\n",
                "print(f\"   {'CAGR':<15} {bnh_metrics['CAGR']:>12.1%} {smart_metrics['CAGR']:>12.1%} {smart_metrics['CAGR'] - bnh_metrics['CAGR']:>12.1%}\")\n",
                "print(f\"   {'Sharpe':<15} {bnh_metrics['Sharpe']:>12.2f} {smart_metrics['Sharpe']:>12.2f} {smart_metrics['Sharpe'] - bnh_metrics['Sharpe']:>12.2f}\")\n",
                "\n",
                "print(f\"\\nüìÅ Files saved to: {WORK_DIR}\")\n",
                "print(\"\\n‚úÖ DONE!\")"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}