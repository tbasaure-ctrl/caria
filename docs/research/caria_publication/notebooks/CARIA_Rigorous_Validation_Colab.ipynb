{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "header"
            },
            "source": [
                "# üî¨ CARIA-SR Rigorous Validation (Anti-Overfitting)\n",
                "\n",
                "**This notebook addresses overfitting concerns:**\n",
                "1. **Walk-Forward Cross-Validation** (train/test split with gap)\n",
                "2. **Permutation Tests** (compare to randomized signal)\n",
                "3. **Purge + Embargo** (60-day gap to prevent leakage)\n",
                "4. **Proper Baseline** (VIX-only vs VIX+Peak)\n",
                "5. **Out-of-Sample Performance Only**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "setup"
            },
            "outputs": [],
            "source": [
                "# @title 1. Setup\n",
                "!pip install -q yfinance pandas numpy scipy scikit-learn statsmodels seaborn matplotlib pyarrow\n",
                "\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "import os\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import yfinance as yf\n",
                "import warnings\n",
                "from datetime import datetime\n",
                "from tqdm import tqdm\n",
                "import statsmodels.formula.api as smf\n",
                "from sklearn.covariance import LedoitWolf\n",
                "\n",
                "warnings.filterwarnings('ignore')\n",
                "np.random.seed(42)\n",
                "sns.set_style('whitegrid')\n",
                "\n",
                "WORK_DIR = '/content/drive/MyDrive/CARIA_Rigorous'\n",
                "os.makedirs(f'{WORK_DIR}/figures', exist_ok=True)\n",
                "os.makedirs(f'{WORK_DIR}/tables', exist_ok=True)\n",
                "\n",
                "# Parameters\n",
                "START_DATE = \"1995-01-01\"\n",
                "END_DATE = datetime.now().strftime(\"%Y-%m-%d\")\n",
                "\n",
                "# Cross-validation params\n",
                "TRAIN_YEARS = 5\n",
                "TEST_YEARS = 1\n",
                "PURGE_DAYS = 60  # Gap between train and test\n",
                "EMBARGO_DAYS = 22  # Forward return horizon\n",
                "\n",
                "print(f\"‚úÖ Output: {WORK_DIR}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "download"
            },
            "outputs": [],
            "source": [
                "# @title 2. Download Data\n",
                "\n",
                "# S&P 500 sectors for cross-sectional analysis\n",
                "SECTORS = ['XLF', 'XLK', 'XLE', 'XLV', 'XLI', 'XLY', 'XLP', 'XLB', 'XLU', 'XLRE', 'XLC']\n",
                "\n",
                "print(\"Downloading data...\")\n",
                "sectors = yf.download(SECTORS, start=START_DATE, end=END_DATE, progress=False)['Close']\n",
                "market = yf.download(['^VIX', 'SPY', 'TLT'], start=START_DATE, end=END_DATE, progress=False)['Close']\n",
                "\n",
                "vix = market['^VIX'].rename('volatility')\n",
                "spy = market['SPY'].rename('price')\n",
                "tlt = market['TLT'].rename('tlt')\n",
                "\n",
                "print(f\"\\n‚úÖ Sectors: {sectors.shape}\")\n",
                "print(f\"‚úÖ Market: {START_DATE} to {END_DATE}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "functions"
            },
            "outputs": [],
            "source": [
                "# @title 3. Core Functions\n",
                "\n",
                "def cov_to_corr(S):\n",
                "    d = np.sqrt(np.diag(S))\n",
                "    d = np.where(d == 0, 1e-10, d)\n",
                "    return np.nan_to_num((S / np.outer(d, d) + S.T / np.outer(d, d)) / 2)\n",
                "\n",
                "def calc_absorption_ratio(returns, window=252, k_frac=0.2):\n",
                "    \"\"\"Calculate rolling Absorption Ratio.\"\"\"\n",
                "    returns = returns.dropna(axis=1, how='all')\n",
                "    ar_series = pd.Series(index=returns.index, dtype=float)\n",
                "    lw = LedoitWolf()\n",
                "    \n",
                "    for t in range(window, len(returns), 5):\n",
                "        W = returns.iloc[t-window:t].dropna(axis=1)\n",
                "        if W.shape[1] < 5:\n",
                "            continue\n",
                "        W = W.fillna(W.mean())\n",
                "        X = W.values - W.values.mean(axis=0)\n",
                "        try:\n",
                "            C = cov_to_corr(lw.fit(X).covariance_)\n",
                "            w = np.sort(np.linalg.eigvalsh(C))[::-1]\n",
                "            w = np.maximum(w, 1e-10)\n",
                "            k = max(1, int(np.ceil(k_frac * len(w))))\n",
                "            ar_series.iloc[t] = np.sum(w[:k]) / np.sum(w)\n",
                "        except:\n",
                "            pass\n",
                "    \n",
                "    return ar_series.ffill().bfill()\n",
                "\n",
                "def prepare_dataset(sectors, vix, spy, tlt, memory_window=60):\n",
                "    \"\"\"Prepare full dataset with all features.\"\"\"\n",
                "    returns = np.log(sectors).diff()\n",
                "    ar = calc_absorption_ratio(returns)\n",
                "    \n",
                "    # Z-score\n",
                "    ar_z = (ar - ar.rolling(252).mean()) / ar.rolling(252).std()\n",
                "    \n",
                "    # Peak Memory\n",
                "    peak = ar_z.rolling(memory_window).max()\n",
                "    \n",
                "    # Merge\n",
                "    idx = ar.dropna().index.intersection(vix.index).intersection(spy.index)\n",
                "    df = pd.DataFrame({\n",
                "        'ar': ar.loc[idx],\n",
                "        'ar_z': ar_z.loc[idx],\n",
                "        'peak': peak.loc[idx],\n",
                "        'volatility': vix.loc[idx],\n",
                "        'price': spy.loc[idx],\n",
                "        'tlt': tlt.reindex(idx).ffill()\n",
                "    }).dropna()\n",
                "    \n",
                "    # Target: 22-day forward return\n",
                "    df['ret_fwd'] = df['price'].pct_change(22).shift(-22)\n",
                "    \n",
                "    return df.dropna()\n",
                "\n",
                "print(\"‚úÖ Functions defined\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "prepare"
            },
            "outputs": [],
            "source": [
                "# @title 4. Prepare Dataset\n",
                "print(\"Calculating structural metrics...\")\n",
                "df = prepare_dataset(sectors, vix, spy, tlt)\n",
                "print(f\"\\n‚úÖ Dataset: {len(df)} observations\")\n",
                "print(f\"   Period: {df.index.min().date()} to {df.index.max().date()}\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "walkforward"
            },
            "outputs": [],
            "source": [
                "# @title 5. Walk-Forward Cross-Validation (THE KEY TEST)\n",
                "\n",
                "def walk_forward_cv(df, train_years=5, test_years=1, purge_days=60):\n",
                "    \"\"\"\n",
                "    Time-series cross-validation with purge gap.\n",
                "    \n",
                "    For each fold:\n",
                "    1. Train on years [0, train_years]\n",
                "    2. Skip purge_days (to avoid leakage)\n",
                "    3. Test on years [train_years + purge, train_years + purge + test_years]\n",
                "    4. Roll forward\n",
                "    \"\"\"\n",
                "    results = []\n",
                "    \n",
                "    train_days = train_years * 252\n",
                "    test_days = test_years * 252\n",
                "    \n",
                "    n_folds = (len(df) - train_days - purge_days - test_days) // test_days\n",
                "    print(f\"Running {n_folds} walk-forward folds...\")\n",
                "    \n",
                "    for fold in range(n_folds):\n",
                "        train_start = fold * test_days\n",
                "        train_end = train_start + train_days\n",
                "        test_start = train_end + purge_days\n",
                "        test_end = test_start + test_days\n",
                "        \n",
                "        if test_end > len(df):\n",
                "            break\n",
                "        \n",
                "        train = df.iloc[train_start:train_end]\n",
                "        test = df.iloc[test_start:test_end]\n",
                "        \n",
                "        # Filter low-vol regime in test (VIX < 20)\n",
                "        test_lowvol = test[test['volatility'] < 20]\n",
                "        \n",
                "        if len(test_lowvol) < 50:\n",
                "            continue\n",
                "        \n",
                "        try:\n",
                "            # Model A: VIX only (proper baseline)\n",
                "            mod_vix = smf.quantreg('ret_fwd ~ volatility', test_lowvol)\n",
                "            r2_vix = mod_vix.fit(q=0.05).prsquared\n",
                "            \n",
                "            # Model B: VIX + Peak (our signal)\n",
                "            mod_peak = smf.quantreg('ret_fwd ~ volatility + peak', test_lowvol)\n",
                "            r2_peak = mod_peak.fit(q=0.05).prsquared\n",
                "            \n",
                "            # Calculate improvement (handle near-zero baseline)\n",
                "            if r2_vix > 0.001:  # Only if baseline has some signal\n",
                "                improvement = (r2_peak - r2_vix) / r2_vix\n",
                "            else:\n",
                "                improvement = r2_peak - r2_vix  # Absolute improvement\n",
                "            \n",
                "            results.append({\n",
                "                'fold': fold,\n",
                "                'train_end': train.index[-1].date(),\n",
                "                'test_start': test.index[0].date(),\n",
                "                'test_end': test.index[-1].date(),\n",
                "                'n_test': len(test_lowvol),\n",
                "                'r2_vix': r2_vix,\n",
                "                'r2_peak': r2_peak,\n",
                "                'improvement': improvement\n",
                "            })\n",
                "        except Exception as e:\n",
                "            print(f\"   Fold {fold} error: {e}\")\n",
                "    \n",
                "    return pd.DataFrame(results)\n",
                "\n",
                "# Run cross-validation\n",
                "cv_results = walk_forward_cv(df, TRAIN_YEARS, TEST_YEARS, PURGE_DAYS)\n",
                "\n",
                "print(f\"\\n{'='*60}\")\n",
                "print(\"WALK-FORWARD CROSS-VALIDATION RESULTS\")\n",
                "print(f\"{'='*60}\")\n",
                "print(f\"\\nFolds completed: {len(cv_results)}\")\n",
                "print(f\"\\nMean R¬≤ (VIX only):      {cv_results['r2_vix'].mean():.5f}\")\n",
                "print(f\"Mean R¬≤ (VIX + Peak):    {cv_results['r2_peak'].mean():.5f}\")\n",
                "print(f\"Mean Improvement:        {cv_results['improvement'].mean():.1%}\")\n",
                "print(f\"\\nFolds where Peak > VIX:  {(cv_results['r2_peak'] > cv_results['r2_vix']).sum()}/{len(cv_results)}\")\n",
                "print(f\"Win Rate:                {(cv_results['r2_peak'] > cv_results['r2_vix']).mean():.1%}\")\n",
                "\n",
                "cv_results.to_csv(f'{WORK_DIR}/tables/WalkForward_CV.csv', index=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "permutation"
            },
            "outputs": [],
            "source": [
                "# @title 6. Permutation Test (Is Our Signal Better Than Random?)\n",
                "\n",
                "def permutation_test(df, n_permutations=500):\n",
                "    \"\"\"\n",
                "    Shuffle the 'peak' column and compare to real signal.\n",
                "    If our real improvement is in the top 5% of random improvements,\n",
                "    it's statistically significant.\n",
                "    \"\"\"\n",
                "    # Filter low-vol regime\n",
                "    test_df = df[df['volatility'] < 20].copy()\n",
                "    \n",
                "    # Real improvement\n",
                "    r2_vix_real = smf.quantreg('ret_fwd ~ volatility', test_df).fit(q=0.05).prsquared\n",
                "    r2_peak_real = smf.quantreg('ret_fwd ~ volatility + peak', test_df).fit(q=0.05).prsquared\n",
                "    real_improvement = r2_peak_real - r2_vix_real\n",
                "    \n",
                "    # Permutation distribution\n",
                "    perm_improvements = []\n",
                "    \n",
                "    print(f\"Running {n_permutations} permutations...\")\n",
                "    for i in range(n_permutations):\n",
                "        # Shuffle peak signal (break temporal structure)\n",
                "        test_df_perm = test_df.copy()\n",
                "        test_df_perm['peak'] = np.random.permutation(test_df_perm['peak'].values)\n",
                "        \n",
                "        try:\n",
                "            r2_perm = smf.quantreg('ret_fwd ~ volatility + peak', test_df_perm).fit(q=0.05).prsquared\n",
                "            perm_improvements.append(r2_perm - r2_vix_real)\n",
                "        except:\n",
                "            pass\n",
                "        \n",
                "        if (i+1) % 100 == 0:\n",
                "            print(f\"   {i+1}/{n_permutations}\")\n",
                "    \n",
                "    perm_improvements = np.array(perm_improvements)\n",
                "    \n",
                "    # P-value: fraction of permutations that beat real\n",
                "    p_value = (perm_improvements >= real_improvement).mean()\n",
                "    \n",
                "    return {\n",
                "        'real_improvement': real_improvement,\n",
                "        'perm_mean': perm_improvements.mean(),\n",
                "        'perm_std': perm_improvements.std(),\n",
                "        'perm_95th': np.percentile(perm_improvements, 95),\n",
                "        'p_value': p_value,\n",
                "        'significant': p_value < 0.05\n",
                "    }\n",
                "\n",
                "perm_results = permutation_test(df)\n",
                "\n",
                "print(f\"\\n{'='*60}\")\n",
                "print(\"PERMUTATION TEST RESULTS\")\n",
                "print(f\"{'='*60}\")\n",
                "print(f\"\\nReal Improvement (R¬≤):    {perm_results['real_improvement']:.5f}\")\n",
                "print(f\"Random Mean:              {perm_results['perm_mean']:.5f}\")\n",
                "print(f\"Random 95th Percentile:   {perm_results['perm_95th']:.5f}\")\n",
                "print(f\"\\nP-value:                  {perm_results['p_value']:.4f}\")\n",
                "print(f\"Significant (p < 0.05):   {'‚úÖ YES' if perm_results['significant'] else '‚ùå NO'}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "stability"
            },
            "outputs": [],
            "source": [
                "# @title 7. Parameter Stability Test (Is 60-day window robust?)\n",
                "\n",
                "def test_memory_windows(df, windows=[20, 40, 60, 90, 120]):\n",
                "    \"\"\"\n",
                "    Test different memory windows with PROPER out-of-sample evaluation.\n",
                "    Use first 70% for parameter selection, last 30% for final test.\n",
                "    \"\"\"\n",
                "    split = int(len(df) * 0.7)\n",
                "    train = df.iloc[:split]\n",
                "    test = df.iloc[split:]\n",
                "    \n",
                "    results = []\n",
                "    \n",
                "    for w in windows:\n",
                "        # Recalculate peak with this window\n",
                "        train_copy = train.copy()\n",
                "        test_copy = test.copy()\n",
                "        \n",
                "        train_copy['peak_w'] = train_copy['ar_z'].rolling(w).max()\n",
                "        test_copy['peak_w'] = test_copy['ar_z'].rolling(w).max()\n",
                "        \n",
                "        # Test on held-out data\n",
                "        test_lowvol = test_copy[test_copy['volatility'] < 20].dropna()\n",
                "        \n",
                "        if len(test_lowvol) < 100:\n",
                "            continue\n",
                "        \n",
                "        try:\n",
                "            r2_vix = smf.quantreg('ret_fwd ~ volatility', test_lowvol).fit(q=0.05).prsquared\n",
                "            r2_peak = smf.quantreg('ret_fwd ~ volatility + peak_w', test_lowvol).fit(q=0.05).prsquared\n",
                "            \n",
                "            results.append({\n",
                "                'window': w,\n",
                "                'r2_vix': r2_vix,\n",
                "                'r2_peak': r2_peak,\n",
                "                'improvement': r2_peak - r2_vix,\n",
                "                'beats_baseline': r2_peak > r2_vix\n",
                "            })\n",
                "        except:\n",
                "            pass\n",
                "    \n",
                "    return pd.DataFrame(results)\n",
                "\n",
                "window_results = test_memory_windows(df)\n",
                "\n",
                "print(f\"\\n{'='*60}\")\n",
                "print(\"PARAMETER STABILITY TEST (Out-of-Sample)\")\n",
                "print(f\"{'='*60}\")\n",
                "print(window_results.to_string(index=False))\n",
                "\n",
                "# Check if results are robust across windows\n",
                "if len(window_results) > 0:\n",
                "    wins = window_results['beats_baseline'].sum()\n",
                "    print(f\"\\nWindows that beat baseline: {wins}/{len(window_results)}\")\n",
                "    if wins == len(window_results):\n",
                "        print(\"‚úÖ ROBUST: Signal works across all memory windows\")\n",
                "    elif wins >= len(window_results) / 2:\n",
                "        print(\"‚ö†Ô∏è MODERATE: Signal works for some windows\")\n",
                "    else:\n",
                "        print(\"‚ùå FRAGILE: Signal is parameter-dependent\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "minsky_oos"
            },
            "outputs": [],
            "source": [
                "# @title 8. Minsky Hedge (Out-of-Sample Only)\n",
                "\n",
                "def minsky_hedge_oos(df, train_pct=0.7, entry_peak=1.0, exit_peak=0.5, vix_entry=20):\n",
                "    \"\"\"\n",
                "    Minsky Hedge with parameters chosen on TRAIN, evaluated on TEST.\n",
                "    \"\"\"\n",
                "    split = int(len(df) * train_pct)\n",
                "    test = df.iloc[split:].copy()\n",
                "    \n",
                "    test['daily_ret'] = np.log(test['price']).diff()\n",
                "    test['tlt_ret'] = np.log(test['tlt']).diff()\n",
                "    \n",
                "    # State machine\n",
                "    in_hedge = False\n",
                "    states = []\n",
                "    \n",
                "    for i in range(len(test)):\n",
                "        peak = test['peak'].iloc[i]\n",
                "        vix = test['volatility'].iloc[i]\n",
                "        \n",
                "        if pd.isna(peak):\n",
                "            states.append(False)\n",
                "            continue\n",
                "        \n",
                "        if not in_hedge:\n",
                "            if vix < vix_entry and peak > entry_peak:\n",
                "                in_hedge = True\n",
                "        else:\n",
                "            if peak < exit_peak:\n",
                "                in_hedge = False\n",
                "        \n",
                "        states.append(in_hedge)\n",
                "    \n",
                "    test['in_hedge'] = states\n",
                "    test['strat_ret'] = np.where(test['in_hedge'], test['tlt_ret'], test['daily_ret'])\n",
                "    \n",
                "    test['cum_bnh'] = (1 + test['daily_ret'].fillna(0)).cumprod()\n",
                "    test['cum_strat'] = (1 + test['strat_ret'].fillna(0)).cumprod()\n",
                "    \n",
                "    years = len(test) / 252\n",
                "    \n",
                "    dd_bnh = (test['cum_bnh'] / test['cum_bnh'].cummax() - 1).min()\n",
                "    dd_strat = (test['cum_strat'] / test['cum_strat'].cummax() - 1).min()\n",
                "    \n",
                "    cagr_bnh = test['cum_bnh'].iloc[-1]**(1/years) - 1\n",
                "    cagr_strat = test['cum_strat'].iloc[-1]**(1/years) - 1\n",
                "    \n",
                "    vol_bnh = test['daily_ret'].std() * np.sqrt(252)\n",
                "    vol_strat = test['strat_ret'].std() * np.sqrt(252)\n",
                "    \n",
                "    sharpe_bnh = cagr_bnh / vol_bnh if vol_bnh > 0 else 0\n",
                "    sharpe_strat = cagr_strat / vol_strat if vol_strat > 0 else 0\n",
                "    \n",
                "    return {\n",
                "        'test_start': test.index[0].date(),\n",
                "        'test_end': test.index[-1].date(),\n",
                "        'dd_bnh': dd_bnh,\n",
                "        'dd_strat': dd_strat,\n",
                "        'dd_reduction': dd_bnh - dd_strat,\n",
                "        'cagr_bnh': cagr_bnh,\n",
                "        'cagr_strat': cagr_strat,\n",
                "        'sharpe_bnh': sharpe_bnh,\n",
                "        'sharpe_strat': sharpe_strat,\n",
                "        'hedge_time': np.mean(states),\n",
                "        'test_df': test\n",
                "    }\n",
                "\n",
                "hedge_results = minsky_hedge_oos(df)\n",
                "\n",
                "print(f\"\\n{'='*60}\")\n",
                "print(\"MINSKY HEDGE (OUT-OF-SAMPLE ONLY)\")\n",
                "print(f\"{'='*60}\")\n",
                "print(f\"\\nTest Period: {hedge_results['test_start']} to {hedge_results['test_end']}\")\n",
                "print(f\"\\n{'Metric':<20} {'Benchmark':>12} {'Minsky':>12} {'Diff':>12}\")\n",
                "print(\"-\" * 56)\n",
                "print(f\"{'Max Drawdown':<20} {hedge_results['dd_bnh']:>12.1%} {hedge_results['dd_strat']:>12.1%} {hedge_results['dd_reduction']:>12.1%}\")\n",
                "print(f\"{'CAGR':<20} {hedge_results['cagr_bnh']:>12.1%} {hedge_results['cagr_strat']:>12.1%} {hedge_results['cagr_strat']-hedge_results['cagr_bnh']:>12.1%}\")\n",
                "print(f\"{'Sharpe':<20} {hedge_results['sharpe_bnh']:>12.2f} {hedge_results['sharpe_strat']:>12.2f} {hedge_results['sharpe_strat']-hedge_results['sharpe_bnh']:>12.2f}\")\n",
                "print(f\"\\nTime in Hedge: {hedge_results['hedge_time']*100:.1f}%\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "plot_oos"
            },
            "outputs": [],
            "source": [
                "# @title 9. Visualization\n",
                "\n",
                "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
                "\n",
                "# 1. Walk-Forward Results\n",
                "ax = axes[0, 0]\n",
                "ax.bar(cv_results['fold'], cv_results['improvement'] * 100, \n",
                "       color=['green' if x > 0 else 'red' for x in cv_results['improvement']])\n",
                "ax.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
                "ax.set_xlabel('Fold')\n",
                "ax.set_ylabel('Improvement (%)')\n",
                "ax.set_title('Walk-Forward CV: Out-of-Sample Improvement per Fold')\n",
                "\n",
                "# 2. Parameter Stability\n",
                "ax = axes[0, 1]\n",
                "ax.bar(window_results['window'].astype(str), window_results['improvement'] * 100,\n",
                "       color=['green' if x else 'red' for x in window_results['beats_baseline']])\n",
                "ax.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
                "ax.set_xlabel('Memory Window (days)')\n",
                "ax.set_ylabel('R¬≤ Improvement')\n",
                "ax.set_title('Parameter Stability (Out-of-Sample)')\n",
                "\n",
                "# 3. Equity Curves (OOS only)\n",
                "ax = axes[1, 0]\n",
                "test_df = hedge_results['test_df']\n",
                "ax.plot(test_df.index, test_df['cum_bnh'], label=f\"Buy&Hold (DD:{hedge_results['dd_bnh']:.1%})\")\n",
                "ax.plot(test_df.index, test_df['cum_strat'], label=f\"Minsky (DD:{hedge_results['dd_strat']:.1%})\")\n",
                "ax.set_yscale('log')\n",
                "ax.legend()\n",
                "ax.set_title('Minsky Hedge: Out-of-Sample Equity Curves')\n",
                "\n",
                "# 4. Drawdown comparison\n",
                "ax = axes[1, 1]\n",
                "dd_bnh = test_df['cum_bnh'] / test_df['cum_bnh'].cummax() - 1\n",
                "dd_strat = test_df['cum_strat'] / test_df['cum_strat'].cummax() - 1\n",
                "ax.fill_between(test_df.index, dd_bnh, 0, alpha=0.3, label='Buy&Hold DD')\n",
                "ax.plot(test_df.index, dd_strat, color='blue', label='Minsky DD')\n",
                "ax.legend()\n",
                "ax.set_title('Drawdown Comparison (OOS)')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(f'{WORK_DIR}/figures/Rigorous_Validation.png', dpi=300)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "summary"
            },
            "outputs": [],
            "source": [
                "# @title 10. Final Summary\n",
                "\n",
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"üî¨ CARIA-SR RIGOROUS VALIDATION SUMMARY\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "print(\"\\nüìä WALK-FORWARD CROSS-VALIDATION:\")\n",
                "win_rate = (cv_results['r2_peak'] > cv_results['r2_vix']).mean()\n",
                "print(f\"   Win Rate: {win_rate:.1%} ({(cv_results['r2_peak'] > cv_results['r2_vix']).sum()}/{len(cv_results)} folds)\")\n",
                "print(f\"   Mean OOS Improvement: {cv_results['improvement'].mean():.1%}\")\n",
                "\n",
                "print(\"\\nüìä PERMUTATION TEST:\")\n",
                "print(f\"   P-value: {perm_results['p_value']:.4f}\")\n",
                "print(f\"   Significant: {'‚úÖ YES' if perm_results['significant'] else '‚ùå NO'}\")\n",
                "\n",
                "print(\"\\nüìä PARAMETER STABILITY:\")\n",
                "stable = window_results['beats_baseline'].sum() / len(window_results)\n",
                "print(f\"   Windows that work: {window_results['beats_baseline'].sum()}/{len(window_results)} ({stable:.0%})\")\n",
                "\n",
                "print(\"\\nüìä MINSKY HEDGE (OOS):\")\n",
                "print(f\"   DD Reduction: {hedge_results['dd_reduction']:.1%}\")\n",
                "print(f\"   Sharpe Improvement: {hedge_results['sharpe_strat'] - hedge_results['sharpe_bnh']:.2f}\")\n",
                "\n",
                "# Overall verdict\n",
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"VERDICT:\")\n",
                "if win_rate > 0.6 and perm_results['significant'] and stable > 0.5:\n",
                "    print(\"‚úÖ SIGNAL IS ROBUST - Not overfitting\")\n",
                "elif win_rate > 0.5 or perm_results['significant']:\n",
                "    print(\"‚ö†Ô∏è SIGNAL SHOWS SOME PROMISE - But needs more data\")\n",
                "else:\n",
                "    print(\"‚ùå SIGNAL MAY BE OVERFITTING - Use with caution\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "# Save all results\n",
                "summary = {\n",
                "    'cv_win_rate': win_rate,\n",
                "    'perm_pvalue': perm_results['p_value'],\n",
                "    'perm_significant': perm_results['significant'],\n",
                "    'param_stability': stable,\n",
                "    'oos_dd_reduction': hedge_results['dd_reduction'],\n",
                "    'oos_sharpe_diff': hedge_results['sharpe_strat'] - hedge_results['sharpe_bnh']\n",
                "}\n",
                "pd.DataFrame([summary]).to_csv(f'{WORK_DIR}/tables/Final_Summary.csv', index=False)\n",
                "print(f\"\\n‚úÖ Results saved to {WORK_DIR}\")"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}