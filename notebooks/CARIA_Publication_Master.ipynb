{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# CARIA: Publication Master (The Definitive Validation)\n",
                "\n",
                "## Abstract\n",
                "This notebook generates the final empirical evidence for the CARIA model as a **Seminal Contribution** to Financial Physics.\n",
                "\n",
                "We rigorously benchmark **Smart CARIA (Synchronization + Trend)** against:\n",
                "- **Buy & Hold** (Baseline)\n",
                "- **Volatility Targeting** (VIX Proxy) - The standard \"Risk Parity\" approach.\n",
                "- **Naive Synchronization** (Great Caria v3) - Showing why \"Structure\" alone isn't enough.\n",
                "\n",
                "## The Physics Engine: Structural Momentum ($p = m \\times v$)\n",
                "We implement the **Vector Physics** model defined in the Technical Report:\n",
                "1.  **Velocity ($v$)**: Market Volatility (Speed of price change).\n",
                "2.  **Mass ($m$)**: Social Synchronization ($r$).\n",
                "    - Calculated by decomposing **Raw Returns** (Vector) into time scales and measuring Phase Alignment.\n",
                "    - *Critial Change*: We use Raw Returns, not Abs(Returns), to preserve the directional/cyclical nature of the \"Clocks\".\n",
                "3.  **Momentum ($p$)**: $p = r \\times v$ (The weight of the crash).\n",
                "4.  **Regime Filter**: Distinguishing Bubble ($r$ High, Trend Up) vs Crash ($r$ High, Trend Down)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install yfinance PyWavelets scikit-learn numpy pandas scipy matplotlib seaborn -q\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import yfinance as yf\n",
                "from scipy import stats, signal\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.metrics import matthews_corrcoef, f1_score, roc_auc_score, precision_score, recall_score, confusion_matrix\n",
                "from sklearn.feature_selection import mutual_info_regression\n",
                "\n",
                "# === I. DATA LOADER ===\n",
                "def fetch_data(ticker, start='2005-01-01'):\n",
                "    df = yf.download(ticker, start=start, progress=False)\n",
                "    if isinstance(df.columns, pd.MultiIndex): df = df.xs('Close', axis=1, level=0)\n",
                "    return df.iloc[:, 0].dropna() if isinstance(df, pd.DataFrame) else df.dropna()\n",
                "\n",
                "print(\"Fetching Market Data...\")\n",
                "sp500 = fetch_data('^GSPC')\n",
                "vix = fetch_data('^VIX') \n",
                "bond = fetch_data('TLT')\n",
                "gold = fetch_data('GC=F')\n",
                "print(\"Data Ready.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === II. VECTOR PHYSICS ENGINE ===\n",
                "SCALES = {\n",
                "    'fast':   {'window': 5,   'weight': 0.15},\n",
                "    'medium': {'window': 20,  'weight': 0.35}, \n",
                "    'slow':   {'window': 60, 'weight': 0.25},\n",
                "    'macro':  {'window': 200, 'weight': 0.25}\n",
                "}\n",
                "\n",
                "def calculate_vector_physics(price_series):\n",
                "    # 1. Input Vector: Raw Returns (Preserving Direction/Phase)\n",
                "    returns = price_series.pct_change().dropna()\n",
                "    \n",
                "    # 2. Decomposition (Bandpass on Raw Signal)\n",
                "    bands = {}\n",
                "    sorted_scales = sorted(SCALES.items(), key=lambda x: x[1]['window'])\n",
                "    \n",
                "    # We use the raw signal to decompose distinct time-horizon CYCLES ( Oscillations )\n",
                "    signal_in = returns\n",
                "    \n",
                "    for i, (name, config) in enumerate(sorted_scales):\n",
                "        w = config['window']\n",
                "        # Bandpass Logic: Moving Average(t) - Moving Average(t-1 scale)\n",
                "        # Using centered windows or carefully lagged ones to avoid lookahead\n",
                "        # Here we use standard rolling means. \n",
                "        # Note: Returns are already detrended prices, effectively.\n",
                "        smooth = signal_in.rolling(w).mean()\n",
                "        if i < len(sorted_scales) - 1:\n",
                "            next_w = sorted_scales[i+1][1]['window']\n",
                "            next_smooth = signal_in.rolling(next_w).mean()\n",
                "            bands[name] = smooth - next_smooth\n",
                "        else:\n",
                "            bands[name] = smooth\n",
                "            \n",
                "    bands_df = pd.DataFrame(bands).dropna()\n",
                "    \n",
                "    # 3. Phase Extraction (Hilbert on Cycles)\n",
                "    phases = {}\n",
                "    for col in bands_df.columns:\n",
                "        series = bands_df[col].values\n",
                "        # Hilbert requires oscillation around 0. Our bands (diff of means) naturally do this.\n",
                "        analytic = signal.hilbert(series)\n",
                "        phases[col] = np.angle(analytic)\n",
                "    \n",
                "    phases_df = pd.DataFrame(phases, index=bands_df.index)\n",
                "    \n",
                "    # 4. Synchronization (The Mass term 'm')\n",
                "    # r = |mean(e^i*phi)|\n",
                "    complex_phases = np.exp(1j * phases_df)\n",
                "    kuramoto_r = np.abs(complex_phases.mean(axis=1))\n",
                "    SYNC = pd.Series(kuramoto_r, index=phases_df.index, name='Sync')\n",
                "    \n",
                "    # 5. Volatility (The Velocity term 'v')\n",
                "    # We use a reactive volatility metric (e.g., 20d standard deviation)\n",
                "    VOL = returns.rolling(20).std() * np.sqrt(252)\n",
                "    # Align indices\n",
                "    VOL = VOL.reindex(SYNC.index).fillna(0)\n",
                "    \n",
                "    # 6. Structural Momentum (p = m * v)\n",
                "    # Fragility = Sync * Volatility\n",
                "    # This is the \"Weight of the Falling Anvil\"\n",
                "    MOMENTUM = SYNC * VOL\n",
                "    \n",
                "    # 7. Entropy (H)\n",
                "    def calc_entropy(row):\n",
                "        counts, _ = np.histogram(row, bins=8, range=(-np.pi, np.pi), density=True)\n",
                "        counts = counts[counts > 0]\n",
                "        return -np.sum(counts * np.log(counts))\n",
                "    entropy = phases_df.apply(calc_entropy, axis=1)\n",
                "    \n",
                "    return pd.DataFrame({\n",
                "        'Price': price_series,\n",
                "        'Returns': returns,\n",
                "        'Sync': SYNC,\n",
                "        'Volatility': VOL,\n",
                "        'Momentum': MOMENTUM, # The Core Physics Metric\n",
                "        'Entropy': entropy\n",
                "    }).dropna()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === III. VALIDATION & BENCHMARKS ===\n",
                "\n",
                "def run_vector_validation(name, df):\n",
                "    data = df.copy()\n",
                "    \n",
                "    # --- Signals ---\n",
                "    # 1. Volatility Only (Traditional Risk)\n",
                "    vol_thresh = data['Volatility'].rolling(252).quantile(0.8)\n",
                "    data['Signal_Vol'] = np.where(data['Volatility'] > vol_thresh, 0, 1)\n",
                "    \n",
                "    # 2. Naive CARIA (Sync Only) - The \"Consensus\" detector\n",
                "    # Using MOMENTUM (Sync*Vol) as the metric, but ignoring direction/trend\n",
                "    mom_thresh = data['Momentum'].rolling(252).quantile(0.8)\n",
                "    data['Signal_Naive'] = np.where(data['Momentum'] > mom_thresh, 0, 1)\n",
                "    \n",
                "    # 3. Smart CARIA (Vector Physics)\n",
                "    # Signal = Momentum(High) AND Trend(Down)\n",
                "    trend = data['Price'].pct_change(20)\n",
                "    is_heavy = data['Momentum'] > mom_thresh # High Mass * Speed\n",
                "    is_crash_vector = trend < 0 # Downward direction\n",
                "    \n",
                "    # If Heavy AND Crash Vector -> EXIT (0). Else -> STAY (1)\n",
                "    # Note: If Heavy AND Up Vector (Bubble) -> STAY\n",
                "    data['Signal_Smart'] = np.where(is_heavy & is_crash_vector, 0, 1)\n",
                "    data['Signal_BH'] = 1\n",
                "\n",
                "    # Lag adjustment: Trade at Close of Signal Day (effectively next day's return)\n",
                "    for col in ['Signal_BH', 'Signal_Vol', 'Signal_Naive', 'Signal_Smart']:\n",
                "        data[col] = data[col].shift(1).fillna(1)\n",
                "        \n",
                "    return data.dropna()\n",
                "\n",
                "def calc_stats_final(model, returns, signals, price_data):\n",
                "    cum = (1 + returns).cumprod()\n",
                "    ret_total = cum.iloc[-1] - 1\n",
                "    sharpe = returns.mean()/returns.std()*np.sqrt(252)\n",
                "    dd = (cum/cum.cummax()) - 1\n",
                "    \n",
                "    # Classification\n",
                "    y_true = (price_data.pct_change(20).shift(-20) < -0.05).astype(int)\n",
                "    y_pred = (signals == 0).astype(int)\n",
                "    valid = y_true.notna() & y_pred.notna()\n",
                "    yt, yp = y_true[valid], y_pred[valid]\n",
                "    \n",
                "    return {\n",
                "        'Model': model,\n",
                "        'Sharpe': sharpe,\n",
                "        'Return': f\"{ret_total*100:.0f}%\",\n",
                "        'MaxDD': dd.min(),\n",
                "        'AUC': roc_auc_score(yt, yp) if len(np.unique(yt))>1 else 0.5,\n",
                "        'MCC': matthews_corrcoef(yt, yp),\n",
                "        'F1': f1_score(yt, yp)\n",
                "    }\n",
                "\n",
                "# === RUN ENGINE ===\n",
                "assets = {'S&P 500': sp500, 'Bitcoin': btc, 'TLT': tlt, 'Gold': gold}\n",
                "\n",
                "for name, asset_data in assets.items():\n",
                "    if asset_data.empty: continue\n",
                "    print(f\"\\n=== {name} (Vector Physics) ===\")\n",
                "    df_phys = calculate_vector_physics(asset_data)\n",
                "    res = run_vector_validation(name, df_phys)\n",
                "    \n",
                "    stats_list = []\n",
                "    for strat in ['Buy & Hold', 'Vol Only', 'Naive CARIA', 'Smart CARIA']:\n",
                "        sig_map = {'Buy & Hold':'Signal_BH', 'Vol Only':'Signal_Vol', \n",
                "                   'Naive CARIA':'Signal_Naive', 'Smart CARIA':'Signal_Smart'}\n",
                "        strat_ret = res['Returns'] * res[sig_map[strat]]\n",
                "        stats_list.append(calc_stats_final(strat, strat_ret, res[sig_map[strat]], res['Price']))\n",
                "        \n",
                "    print(pd.DataFrame(stats_list).set_index('Model'))\n",
                "    \n",
                "    mi = mutual_info_regression(res[['Sync']].values, res['Returns'].shift(-20).fillna(0))\n",
                "    print(f\"Mutual Info (Sync->Returns): {mi[0]:.4f}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}