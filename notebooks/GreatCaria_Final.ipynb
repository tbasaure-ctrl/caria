{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# GREAT CARIA FINAL - Systemic Fragility Index\n",
                "\n",
                "## Simplified Model (Back to Basics)\n",
                "\n",
                "After extensive experimentation, this is the **definitive model** that maximizes signal while minimizing complexity.\n",
                "\n",
                "### Core Components:\n",
                "1. **Crisis Factor (CF)** - Correlation Ã— Volatility (AUC=0.705)\n",
                "2. **3-Band Decomposition** - Slow/Medium/Fast (not 5)\n",
                "3. **Factor Analysis** - Latent fragility F_t\n",
                "4. **Cusp Bifurcation** - Catastrophe theory for transitions\n",
                "\n",
                "### What was removed:\n",
                "- âŒ 5 temporal scales (overfitting)\n",
                "- âŒ Psychology as input (emergent, not cause)\n",
                "- âŒ Complex physics-first weights\n",
                "- âŒ Multi-scale Kuramoto"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === SETUP ===\n",
                "!pip install PyWavelets scikit-learn statsmodels -q\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from scipy import stats, signal\n",
                "from scipy.ndimage import gaussian_filter1d\n",
                "import pywt\n",
                "from sklearn.decomposition import FactorAnalysis, PCA\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "import matplotlib.pyplot as plt\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "print('=== GREAT CARIA FINAL ===')\n",
                "print('Simplified Model: CF + 3 Bands + Factor Analysis + Cusp')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === LOAD DATA ===\n",
                "DATA_PATH = '/content/drive/MyDrive/Caria/yahoo_market.parquet'\n",
                "df = pd.read_parquet(DATA_PATH)\n",
                "df.index = pd.to_datetime(df.index)\n",
                "\n",
                "COUNTRIES = ['USA', 'CHN', 'JPN', 'DEU', 'GBR', 'FRA', 'BRA', 'MEX', 'KOR', 'AUS', 'IND', 'ZAF']\n",
                "idx_cols = [f'{c}_index' for c in COUNTRIES if f'{c}_index' in df.columns]\n",
                "ret = df[idx_cols].pct_change().dropna()\n",
                "ret.columns = [c.replace('_index', '') for c in ret.columns]\n",
                "\n",
                "print(f'Data: {ret.shape[0]} days, {ret.shape[1]} countries')\n",
                "print(f'Period: {ret.index.min().date()} to {ret.index.max().date()}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === CRISIS CATALOG (13 events) ===\n",
                "CRISES = {\n",
                "    'DotCom': pd.Timestamp('2000-03-10'),\n",
                "    '9/11': pd.Timestamp('2001-09-11'),\n",
                "    'Lehman': pd.Timestamp('2008-09-15'),\n",
                "    'Flash_Crash': pd.Timestamp('2010-05-06'),\n",
                "    'Euro_Crisis': pd.Timestamp('2011-08-05'),\n",
                "    'Taper_Tantrum': pd.Timestamp('2013-05-22'),\n",
                "    'China_Crash': pd.Timestamp('2015-08-24'),\n",
                "    'Brexit': pd.Timestamp('2016-06-24'),\n",
                "    'Volmageddon': pd.Timestamp('2018-02-05'),\n",
                "    'Repo_Crisis': pd.Timestamp('2019-09-17'),\n",
                "    'COVID': pd.Timestamp('2020-03-11'),\n",
                "    'Gilt_Crisis': pd.Timestamp('2022-09-23'),\n",
                "    'SVB': pd.Timestamp('2023-03-10')\n",
                "}\n",
                "\n",
                "# Filter to available data\n",
                "CRISES = {k: v for k, v in CRISES.items() if v >= ret.index.min()}\n",
                "print(f'\\nCrises in data range: {len(CRISES)}')\n",
                "for name, date in CRISES.items():\n",
                "    print(f'  {name}: {date.date()}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# PART 1: CRISIS FACTOR (CF)\n",
                "\n",
                "The **star performer** (AUC = 0.705)\n",
                "\n",
                "$$CF_t = \\bar{\\rho}_t \\times \\bar{\\sigma}_t \\times 100$$\n",
                "\n",
                "Where:\n",
                "- $\\bar{\\rho}_t$ = average pairwise correlation in window\n",
                "- $\\bar{\\sigma}_t$ = average volatility in window"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === CRISIS FACTOR ===\n",
                "def compute_cf(r, window=20):\n",
                "    \"\"\"Crisis Factor = avg_correlation Ã— avg_volatility\"\"\"\n",
                "    cf = []\n",
                "    for i in range(window, len(r)):\n",
                "        wr = r.iloc[i-window:i]\n",
                "        corr_matrix = wr.corr().values\n",
                "        n = len(corr_matrix)\n",
                "        avg_corr = (corr_matrix.sum() - n) / (n * (n - 1))  # Off-diagonal mean\n",
                "        avg_vol = wr.std().mean()\n",
                "        cf.append(avg_corr * avg_vol * 100)\n",
                "    return pd.Series(cf, index=r.index[window:])\n",
                "\n",
                "CF = compute_cf(ret)\n",
                "print(f'Crisis Factor computed: {len(CF)} observations')\n",
                "print(f'CF range: [{CF.min():.3f}, {CF.max():.3f}]')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# PART 2: ADDITIONAL SIGNALS FOR FACTOR ANALYSIS"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === SYNCHRONIZATION (Simple Kuramoto) ===\n",
                "def compute_sync(returns, window=60):\n",
                "    \"\"\"Kuramoto order parameter - phase synchronization\"\"\"\n",
                "    # Extract phases via Hilbert transform\n",
                "    phases = returns.apply(lambda x: np.angle(signal.hilbert(x.fillna(0).values)))\n",
                "    \n",
                "    sync = []\n",
                "    for i in range(window, len(phases)):\n",
                "        ph = phases.iloc[i].values\n",
                "        r = np.abs(np.exp(1j * ph).mean())  # Order parameter\n",
                "        sync.append(r)\n",
                "    return pd.Series(sync, index=returns.index[window:])\n",
                "\n",
                "SYNC = compute_sync(ret)\n",
                "print(f'Synchronization: mean={SYNC.mean():.3f}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === EARLY WARNING SIGNALS (EWS) ===\n",
                "def compute_ews(series, window=120):\n",
                "    \"\"\"Critical slowing down indicators\"\"\"\n",
                "    acf1 = series.rolling(window).apply(lambda x: x.autocorr(1), raw=False)\n",
                "    var = series.rolling(window).var()\n",
                "    skew = series.rolling(window).skew()\n",
                "    return pd.DataFrame({'acf1': acf1, 'var': var, 'skew': skew})\n",
                "\n",
                "EWS = compute_ews(CF)\n",
                "print(f'EWS computed: ACF1, Variance, Skewness')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === NETWORK CURVATURE PROXY ===\n",
                "def rolling_avg_corr(r, window=60):\n",
                "    \"\"\"Average correlation as curvature proxy\"\"\"\n",
                "    corrs = []\n",
                "    for i in range(window, len(r)):\n",
                "        c = r.iloc[i-window:i].corr().values\n",
                "        n = len(c)\n",
                "        avg = (c.sum() - n) / (n * (n - 1))\n",
                "        corrs.append(avg)\n",
                "    return pd.Series(corrs, index=r.index[window:])\n",
                "\n",
                "# Low correlation = low curvature = fragile\n",
                "CURV = 1 - rolling_avg_corr(ret, 60)\n",
                "print(f'Curvature proxy computed')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# PART 3: FACTOR ANALYSIS â†’ LATENT F_t\n",
                "\n",
                "Extract a single latent factor that captures common fragility"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === ALIGN ALL SIGNALS ===\n",
                "common_idx = CF.index\n",
                "for sig in [SYNC, EWS['acf1'], EWS['var'], EWS['skew'], CURV]:\n",
                "    common_idx = common_idx.intersection(sig.dropna().index)\n",
                "\n",
                "signals_df = pd.DataFrame({\n",
                "    'cf': CF.loc[common_idx],\n",
                "    'sync': SYNC.loc[common_idx],\n",
                "    'acf1': EWS['acf1'].loc[common_idx],\n",
                "    'var': EWS['var'].loc[common_idx],\n",
                "    'skew': EWS['skew'].abs().loc[common_idx],\n",
                "    'curv': CURV.loc[common_idx]\n",
                "}).dropna()\n",
                "\n",
                "print(f'Aligned signals: {signals_df.shape}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === FACTOR ANALYSIS ===\n",
                "print('=== Factor Analysis for Latent Fragility F_t ===')\n",
                "\n",
                "scaler = StandardScaler()\n",
                "X = scaler.fit_transform(signals_df)\n",
                "\n",
                "# Extract single latent factor\n",
                "fa = FactorAnalysis(n_components=1, random_state=42)\n",
                "F_latent = fa.fit_transform(X).flatten()\n",
                "F_t = pd.Series(F_latent, index=signals_df.index, name='F_t')\n",
                "\n",
                "# Factor loadings\n",
                "loadings = pd.DataFrame({\n",
                "    'signal': signals_df.columns,\n",
                "    'loading': fa.components_[0]\n",
                "}).sort_values('loading', ascending=False)\n",
                "\n",
                "print('\\nFactor Loadings (contribution to latent fragility):')\n",
                "print(loadings.to_string(index=False))\n",
                "\n",
                "# Explained variance\n",
                "pca = PCA(n_components=1)\n",
                "pca.fit(X)\n",
                "print(f'\\nVariance explained by F_t: {pca.explained_variance_ratio_[0]:.1%}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# PART 4: 3-BAND TEMPORAL DECOMPOSITION\n",
                "\n",
                "Only 3 bands (not 5!):\n",
                "- **Slow** (>60d): Structural/Cycle\n",
                "- **Medium** (10-60d): Systemic Resonance\n",
                "- **Fast** (<10d): Critical Noise"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === WAVELET DECOMPOSITION ===\n",
                "def decompose_3bands(series, wavelet='db4'):\n",
                "    \"\"\"Decompose into slow/medium/fast bands\"\"\"\n",
                "    coeffs = pywt.wavedec(series.values, wavelet, level=6)\n",
                "    \n",
                "    # Fast (levels 0-2): ~1-8 days\n",
                "    fast_coeffs = [np.zeros_like(c) for c in coeffs]\n",
                "    for i in range(min(3, len(coeffs))):\n",
                "        fast_coeffs[i] = coeffs[i]\n",
                "    fast = pywt.waverec(fast_coeffs, wavelet)[:len(series)]\n",
                "    \n",
                "    # Medium (levels 3-4): ~8-64 days\n",
                "    med_coeffs = [np.zeros_like(c) for c in coeffs]\n",
                "    for i in range(3, min(5, len(coeffs))):\n",
                "        med_coeffs[i] = coeffs[i]\n",
                "    medium = pywt.waverec(med_coeffs, wavelet)[:len(series)]\n",
                "    \n",
                "    # Slow (levels 5+): >64 days\n",
                "    slow_coeffs = [np.zeros_like(c) for c in coeffs]\n",
                "    for i in range(5, len(coeffs)):\n",
                "        slow_coeffs[i] = coeffs[i]\n",
                "    slow = pywt.waverec(slow_coeffs, wavelet)[:len(series)]\n",
                "    \n",
                "    return {\n",
                "        'fast': pd.Series(fast, index=series.index),\n",
                "        'medium': pd.Series(medium, index=series.index),\n",
                "        'slow': pd.Series(slow, index=series.index)\n",
                "    }\n",
                "\n",
                "F_bands = decompose_3bands(F_t)\n",
                "print('3-Band decomposition complete: Slow, Medium, Fast')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === VISUALIZE BANDS ===\n",
                "fig, axes = plt.subplots(4, 1, figsize=(14, 12), sharex=True)\n",
                "\n",
                "axes[0].plot(F_t.index, F_t.values, 'k-', alpha=0.7)\n",
                "axes[0].set_ylabel('F_t (full)')\n",
                "axes[0].set_title('Latent Fragility and 3-Band Decomposition')\n",
                "\n",
                "axes[1].fill_between(F_bands['slow'].index, F_bands['slow'].values, alpha=0.5, color='blue')\n",
                "axes[1].set_ylabel('Slow (>60d)')\n",
                "\n",
                "axes[2].fill_between(F_bands['medium'].index, F_bands['medium'].values, alpha=0.5, color='orange')\n",
                "axes[2].set_ylabel('Medium (10-60d)')\n",
                "\n",
                "axes[3].fill_between(F_bands['fast'].index, F_bands['fast'].values, alpha=0.5, color='red')\n",
                "axes[3].set_ylabel('Fast (<10d)')\n",
                "\n",
                "for ax in axes:\n",
                "    for name, date in CRISES.items():\n",
                "        if date > F_t.index.min() and date < F_t.index.max():\n",
                "            ax.axvline(date, color='red', alpha=0.3, linestyle=':')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('/content/drive/MyDrive/Caria/great_caria_final_bands.png', dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# PART 5: CUSP BIFURCATION DETECTION"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === CUSP CATASTROPHE PARAMETERS ===\n",
                "def fit_cusp_params(series, window=120):\n",
                "    \"\"\"Estimate cusp parameters from distribution moments\"\"\"\n",
                "    a_params = []\n",
                "    b_params = []\n",
                "    bimodality = []\n",
                "    dates = []\n",
                "    \n",
                "    for i in range(window, len(series), 10):\n",
                "        window_data = series.iloc[i-window:i].values\n",
                "        \n",
                "        skew = stats.skew(window_data)\n",
                "        kurt = stats.kurtosis(window_data)\n",
                "        \n",
                "        # Bimodality coefficient (Sarle's)\n",
                "        bimod = (skew**2 + 1) / (kurt + 3 + 1e-8)\n",
                "        \n",
                "        # Map to cusp parameters\n",
                "        a = -np.sign(kurt) * np.abs(kurt) / 10  # Negative a = bistable\n",
                "        b = skew / 5\n",
                "        \n",
                "        a_params.append(a)\n",
                "        b_params.append(b)\n",
                "        bimodality.append(bimod)\n",
                "        dates.append(series.index[i])\n",
                "    \n",
                "    return pd.DataFrame({\n",
                "        'a': a_params,\n",
                "        'b': b_params,\n",
                "        'bimodality': bimodality\n",
                "    }, index=dates)\n",
                "\n",
                "cusp = fit_cusp_params(F_t)\n",
                "\n",
                "# Bifurcation risk: high when a < 0 and variance is high\n",
                "BIF_RISK = ((cusp['a'] < 0).astype(float) * (1 - cusp['a'].clip(-1, 0).abs())).rolling(5).mean()\n",
                "print(f'Cusp parameters computed: {len(cusp)} windows')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# PART 6: INTEGRATED FRAGILITY INDEX (IFI)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === CONSTRUCT IFI ===\n",
                "# Simple weighted combination\n",
                "# Weights based on theoretical importance, not data fitting\n",
                "\n",
                "def normalize(s):\n",
                "    return (s - s.min()) / (s.max() - s.min() + 1e-8)\n",
                "\n",
                "# Align indices\n",
                "ifi_idx = F_t.index.intersection(cusp.index)\n",
                "\n",
                "IFI = (\n",
                "    0.35 * normalize(F_t.loc[ifi_idx]) +              # Latent fragility (from FA)\n",
                "    0.25 * normalize(F_bands['slow'].loc[ifi_idx]) +   # Structural buildup\n",
                "    0.15 * normalize(F_bands['medium'].loc[ifi_idx]) + # Resonance zone\n",
                "    0.10 * normalize(F_bands['fast'].loc[ifi_idx]) +   # Fast noise\n",
                "    0.15 * normalize(BIF_RISK.loc[ifi_idx])            # Bifurcation risk\n",
                ")\n",
                "IFI = IFI.dropna()\n",
                "\n",
                "print(f'IFI computed: {len(IFI)} observations')\n",
                "print(f'IFI range: [{IFI.min():.3f}, {IFI.max():.3f}]')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === THRESHOLDS ===\n",
                "threshold_warning = IFI.quantile(0.75)\n",
                "threshold_critical = IFI.quantile(0.95)\n",
                "\n",
                "print(f'\\nThresholds:')\n",
                "print(f'  Warning (75th pct): {threshold_warning:.3f}')\n",
                "print(f'  Critical (95th pct): {threshold_critical:.3f}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# PART 7: STATISTICAL VALIDATION"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === CREATE LABELS ===\n",
                "def create_crisis_labels(index, crises, pre_window=20, post_window=10):\n",
                "    labels = pd.Series(0, index=index)\n",
                "    for name, date in crises.items():\n",
                "        start = date - pd.Timedelta(days=pre_window)\n",
                "        end = date + pd.Timedelta(days=post_window)\n",
                "        labels[(labels.index >= start) & (labels.index <= end)] = 1\n",
                "    return labels\n",
                "\n",
                "y_true = create_crisis_labels(IFI.index, CRISES)\n",
                "print(f'Crisis labels: {y_true.sum()} crisis days ({100*y_true.mean():.1f}%)')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === ROC/AUC COMPARISON ===\n",
                "models = {\n",
                "    'IFI (Integrated)': IFI,\n",
                "    'CF Only': normalize(CF.loc[IFI.index]),\n",
                "    'F_t (Factor Analysis)': normalize(F_t.loc[IFI.index]),\n",
                "    'Volatility Only': normalize(ret.std(axis=1).rolling(20).mean().loc[IFI.index])\n",
                "}\n",
                "\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# ROC\n",
                "ax1 = axes[0]\n",
                "auc_results = {}\n",
                "for name, score in models.items():\n",
                "    score_aligned = score.dropna()\n",
                "    y_aligned = y_true.loc[score_aligned.index]\n",
                "    fpr, tpr, _ = roc_curve(y_aligned, score_aligned)\n",
                "    roc_auc = auc(fpr, tpr)\n",
                "    auc_results[name] = roc_auc\n",
                "    ax1.plot(fpr, tpr, label=f'{name} (AUC={roc_auc:.3f})', linewidth=2)\n",
                "\n",
                "ax1.plot([0, 1], [0, 1], 'k--')\n",
                "ax1.set_xlabel('False Positive Rate')\n",
                "ax1.set_ylabel('True Positive Rate')\n",
                "ax1.set_title('ROC Curves')\n",
                "ax1.legend(loc='lower right')\n",
                "ax1.grid(True, alpha=0.3)\n",
                "\n",
                "# AUC bars\n",
                "ax2 = axes[1]\n",
                "names = list(auc_results.keys())\n",
                "aucs = list(auc_results.values())\n",
                "colors = ['#10b981' if auc_results[n] == max(aucs) else '#6b7280' for n in names]\n",
                "ax2.barh(names, aucs, color=colors)\n",
                "ax2.axvline(0.5, color='red', linestyle='--')\n",
                "ax2.set_xlabel('AUC')\n",
                "ax2.set_xlim(0.4, 0.9)\n",
                "ax2.set_title('AUC Comparison')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('/content/drive/MyDrive/Caria/great_caria_final_roc.png', dpi=150)\n",
                "plt.show()\n",
                "\n",
                "print('\\n=== AUC Results ===')\n",
                "for name, score in sorted(auc_results.items(), key=lambda x: -x[1]):\n",
                "    print(f'{name:25s}: {score:.3f}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === PERMUTATION TEST ===\n",
                "n_perm = 500\n",
                "null_aucs = []\n",
                "\n",
                "best_model = 'CF Only'\n",
                "score = models[best_model].dropna()\n",
                "y_test = y_true.loc[score.index]\n",
                "\n",
                "# Observed\n",
                "fpr, tpr, _ = roc_curve(y_test, score)\n",
                "observed_auc = auc(fpr, tpr)\n",
                "\n",
                "# Permutation\n",
                "for _ in range(n_perm):\n",
                "    y_perm = y_test.sample(frac=1).reset_index(drop=True)\n",
                "    fpr, tpr, _ = roc_curve(y_perm.values, score.values)\n",
                "    null_aucs.append(auc(fpr, tpr))\n",
                "\n",
                "p_value = (np.array(null_aucs) >= observed_auc).mean()\n",
                "\n",
                "plt.figure(figsize=(10, 4))\n",
                "plt.hist(null_aucs, bins=30, alpha=0.7, color='gray', label='Null distribution')\n",
                "plt.axvline(observed_auc, color='red', linewidth=2, label=f'Observed={observed_auc:.3f}')\n",
                "plt.xlabel('AUC')\n",
                "plt.ylabel('Frequency')\n",
                "plt.title(f'Permutation Test: p = {p_value:.4f}')\n",
                "plt.legend()\n",
                "plt.savefig('/content/drive/MyDrive/Caria/great_caria_final_permutation.png', dpi=150)\n",
                "plt.show()\n",
                "\n",
                "print(f'\\nPermutation Test (n={n_perm}):')\n",
                "print(f'  Observed AUC: {observed_auc:.4f}')\n",
                "print(f'  Null mean: {np.mean(null_aucs):.4f}')\n",
                "print(f'  p-value: {p_value:.4f}')\n",
                "print(f'  Significant: {\"YES âœ“\" if p_value < 0.05 else \"NO\"}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# PART 8: FINAL VISUALIZATION"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === MAIN FIGURE ===\n",
                "fig, axes = plt.subplots(4, 1, figsize=(14, 14), sharex=True)\n",
                "\n",
                "# A. Crisis Factor (the star)\n",
                "ax1 = axes[0]\n",
                "ax1.fill_between(CF.index, CF.values, alpha=0.4, color='red')\n",
                "ax1.plot(CF.index, CF.values, 'r-', linewidth=0.5)\n",
                "ax1.axhline(CF.quantile(0.75), color='orange', linestyle='--', label='75th pct')\n",
                "ax1.axhline(CF.quantile(0.95), color='darkred', linestyle='--', label='95th pct')\n",
                "ax1.set_ylabel('CF')\n",
                "ax1.set_title('A. Crisis Factor (AUC={:.3f})'.format(auc_results.get('CF Only', 0)))\n",
                "ax1.legend(loc='upper right')\n",
                "\n",
                "# B. Latent F_t\n",
                "ax2 = axes[1]\n",
                "ax2.fill_between(F_t.index, F_t.values, alpha=0.4, color='purple')\n",
                "ax2.plot(F_t.index, F_t.values, 'purple', linewidth=0.5)\n",
                "ax2.axhline(F_t.quantile(0.90), color='orange', linestyle='--')\n",
                "ax2.set_ylabel('F_t')\n",
                "ax2.set_title('B. Latent Fragility (Factor Analysis)')\n",
                "\n",
                "# C. IFI\n",
                "ax3 = axes[2]\n",
                "ax3.fill_between(IFI.index, IFI.values, alpha=0.4, color='blue')\n",
                "ax3.plot(IFI.index, IFI.values, 'b-', linewidth=0.5)\n",
                "ax3.axhline(threshold_warning, color='orange', linestyle='--', label='Warning')\n",
                "ax3.axhline(threshold_critical, color='darkred', linestyle='--', label='Critical')\n",
                "ax3.set_ylabel('IFI')\n",
                "ax3.set_title('C. Integrated Fragility Index')\n",
                "ax3.legend(loc='upper right')\n",
                "\n",
                "# D. Bifurcation status\n",
                "ax4 = axes[3]\n",
                "ax4.fill_between(cusp.index, cusp['a'], 0, \n",
                "                 where=cusp['a'] < 0, alpha=0.5, color='red', label='Bistable')\n",
                "ax4.fill_between(cusp.index, cusp['a'], 0,\n",
                "                 where=cusp['a'] >= 0, alpha=0.3, color='green', label='Stable')\n",
                "ax4.axhline(0, color='black', linestyle='-', linewidth=0.5)\n",
                "ax4.set_ylabel('Cusp a')\n",
                "ax4.set_title('D. Bifurcation Status (a < 0 = critical regime)')\n",
                "ax4.legend(loc='upper right')\n",
                "\n",
                "# Add crisis lines\n",
                "for ax in axes:\n",
                "    for name, date in CRISES.items():\n",
                "        if date > CF.index.min() and date < CF.index.max():\n",
                "            ax.axvline(date, color='blue', alpha=0.3, linestyle=':')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('/content/drive/MyDrive/Caria/great_caria_final_summary.png', dpi=200, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === LEAD TIME ANALYSIS ===\n",
                "print('\\n=== Pre-Crisis Levels and Lead Times ===')\n",
                "\n",
                "def get_precisis_value(series, crisis_date, days_before=20):\n",
                "    pre = series[(series.index < crisis_date) & \n",
                "                 (series.index > crisis_date - pd.Timedelta(days=days_before))]\n",
                "    return pre.mean() if len(pre) > 0 else np.nan\n",
                "\n",
                "results = []\n",
                "for crisis_name, crisis_date in CRISES.items():\n",
                "    if crisis_date < CF.index.min() + pd.Timedelta(days=200):\n",
                "        continue\n",
                "    if crisis_date > CF.index.max():\n",
                "        continue\n",
                "        \n",
                "    cf_pre = get_precisis_value(CF, crisis_date)\n",
                "    ifi_pre = get_precisis_value(IFI, crisis_date) if crisis_date in IFI.index or crisis_date > IFI.index.min() else np.nan\n",
                "    \n",
                "    results.append({\n",
                "        'Crisis': crisis_name,\n",
                "        'Date': crisis_date.date(),\n",
                "        'CF_pre': cf_pre,\n",
                "        'IFI_pre': ifi_pre\n",
                "    })\n",
                "\n",
                "results_df = pd.DataFrame(results)\n",
                "print(results_df.to_string(index=False))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === EXPORT ===\n",
                "import json\n",
                "from datetime import datetime\n",
                "\n",
                "# Current values\n",
                "current = {\n",
                "    'cf': float(CF.iloc[-1]),\n",
                "    'f_t': float(F_t.iloc[-1]),\n",
                "    'ifi': float(IFI.iloc[-1]),\n",
                "    'bifurcation_stable': bool(cusp['a'].iloc[-1] >= 0)\n",
                "}\n",
                "\n",
                "# Determine status\n",
                "if current['ifi'] >= threshold_critical:\n",
                "    status = 'CRITICAL'\n",
                "elif current['ifi'] >= threshold_warning:\n",
                "    status = 'WARNING'\n",
                "else:\n",
                "    status = 'STABLE'\n",
                "\n",
                "export = {\n",
                "    'version': 'Great Caria Final (Simplified)',\n",
                "    'generated': datetime.now().isoformat(),\n",
                "    'methodology': 'CF + 3-Band Decomposition + Factor Analysis + Cusp Bifurcation',\n",
                "    'status': status,\n",
                "    'current': current,\n",
                "    'thresholds': {\n",
                "        'warning': float(threshold_warning),\n",
                "        'critical': float(threshold_critical)\n",
                "    },\n",
                "    'factor_loadings': loadings.set_index('signal')['loading'].to_dict(),\n",
                "    'auc_scores': auc_results,\n",
                "    'permutation_test': {\n",
                "        'p_value': float(p_value),\n",
                "        'significant': p_value < 0.05\n",
                "    },\n",
                "    'crises_validated': len(results_df)\n",
                "}\n",
                "\n",
                "with open('/content/drive/MyDrive/Caria/great_caria_final.json', 'w') as f:\n",
                "    json.dump(export, f, indent=2)\n",
                "\n",
                "print('\\nâœ“ Exported: great_caria_final.json')\n",
                "print(json.dumps(export, indent=2))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === FINAL SUMMARY ===\n",
                "print('\\n' + '='*70)\n",
                "print('GREAT CARIA FINAL - SUMMARY')\n",
                "print('='*70)\n",
                "\n",
                "print('\\nðŸ“Š MODEL COMPONENTS:')\n",
                "print('  1. Crisis Factor (CF) = correlation Ã— volatility')\n",
                "print('  2. Factor Analysis â†’ Latent F_t')\n",
                "print('  3. 3-Band Decomposition (Slow/Medium/Fast)')\n",
                "print('  4. Cusp Bifurcation Detection')\n",
                "\n",
                "print('\\nðŸ“ˆ PERFORMANCE:')\n",
                "for name, score in sorted(auc_results.items(), key=lambda x: -x[1]):\n",
                "    star = 'â­' if score == max(auc_results.values()) else '  '\n",
                "    print(f'  {star} {name:25s}: AUC = {score:.3f}')\n",
                "\n",
                "print(f'\\nðŸ”¬ SIGNAL AUTHENTICITY:')\n",
                "print(f'  Permutation test p-value: {p_value:.4f}')\n",
                "print(f'  Result: {\"REAL SIGNAL âœ“\" if p_value < 0.05 else \"Not significant\"}')\n",
                "\n",
                "print(f'\\nâš ï¸ CURRENT STATUS: {status}')\n",
                "print(f'  IFI: {current[\"ifi\"]:.3f}')\n",
                "print(f'  Bifurcation: {\"Stable\" if current[\"bifurcation_stable\"] else \"BISTABLE\"}')\n",
                "\n",
                "print('\\n' + '='*70)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}