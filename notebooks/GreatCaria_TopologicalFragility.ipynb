{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Great Caria: Topological Fragility Engine\n",
                "\n",
                "**Goal**: Detect systemic fragility using Topological Data Analysis.\n",
                "\n",
                "Core insight: Before crises, market structure **simplifies**. Correlations\n",
                "collapse, the \"sponge\" becomes a \"rod\". TDA detects this geometrically."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install gudhi numpy pandas scipy matplotlib seaborn yfinance -q\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import gudhi\n",
                "from scipy.spatial.distance import pdist, squareform\n",
                "from scipy.sparse.csgraph import minimum_spanning_tree\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from tqdm.auto import tqdm\n",
                "\n",
                "print(f\"GUDHI version: {gudhi.__version__}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Market Data\n",
                "\n",
                "We need daily returns for the correlation-based distance metric."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import yfinance as yf\n",
                "\n",
                "# Global indices representing major economies\n",
                "INDICES = {\n",
                "    'USA': '^GSPC',     # S&P 500\n",
                "    'CHN': '000001.SS', # Shanghai Composite\n",
                "    'JPN': '^N225',     # Nikkei 225\n",
                "    'DEU': '^GDAXI',    # DAX\n",
                "    'GBR': '^FTSE',     # FTSE 100\n",
                "    'FRA': '^FCHI',     # CAC 40\n",
                "    'IND': '^BSESN',    # BSE SENSEX\n",
                "    'BRA': '^BVSP',     # Bovespa\n",
                "    'CAN': '^GSPTSE',   # TSX Composite\n",
                "    'KOR': '^KS11',     # KOSPI\n",
                "    'AUS': '^AXJO',     # ASX 200\n",
                "    'MEX': '^MXX',      # IPC Mexico\n",
                "}\n",
                "\n",
                "def load_index_returns(indices, start='2000-01-01'):\n",
                "    \"\"\"Load daily returns for global indices.\"\"\"\n",
                "    returns = {}\n",
                "    \n",
                "    for name, ticker in tqdm(indices.items(), desc=\"Loading indices\"):\n",
                "        try:\n",
                "            df = yf.download(ticker, start=start, progress=False)\n",
                "            if len(df) > 0:\n",
                "                returns[name] = df['Close'].pct_change().dropna()\n",
                "        except Exception as e:\n",
                "            print(f\"Warning: {name} failed: {e}\")\n",
                "    \n",
                "    # Align all series\n",
                "    df_returns = pd.DataFrame(returns)\n",
                "    df_returns = df_returns.dropna()\n",
                "    \n",
                "    print(f\"Loaded {len(df_returns)} days, {len(df_returns.columns)} countries\")\n",
                "    return df_returns\n",
                "\n",
                "returns_df = load_index_returns(INDICES)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Persistence Diagram Computation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def compute_distance_matrix(returns, window=60):\n",
                "    \"\"\"\n",
                "    Compute correlation-based distance matrix.\n",
                "    d(x,y) = sqrt(2 * (1 - correlation(x,y)))\n",
                "    \"\"\"\n",
                "    if isinstance(returns, pd.DataFrame):\n",
                "        corr = returns.corr().values\n",
                "    else:\n",
                "        corr = np.corrcoef(returns.T)\n",
                "    \n",
                "    # Handle numerical issues\n",
                "    corr = np.clip(corr, -1, 1)\n",
                "    dist = np.sqrt(2 * (1 - corr))\n",
                "    np.fill_diagonal(dist, 0)\n",
                "    \n",
                "    return dist\n",
                "\n",
                "def compute_persistence_diagram(dist_matrix, max_edge=2.0):\n",
                "    \"\"\"\n",
                "    Compute persistence diagram using Rips complex.\n",
                "    \n",
                "    Returns:\n",
                "        diag: List of (dimension, (birth, death)) tuples\n",
                "    \"\"\"\n",
                "    rips = gudhi.RipsComplex(distance_matrix=dist_matrix, max_edge_length=max_edge)\n",
                "    st = rips.create_simplex_tree(max_dimension=2)\n",
                "    diag = st.persistence()\n",
                "    \n",
                "    return diag\n",
                "\n",
                "def compute_fragility_score(diag):\n",
                "    \"\"\"\n",
                "    Compute fragility score from persistence diagram.\n",
                "    \n",
                "    Fragility = 1 - complexity\n",
                "    Low Betti-1 (few loops) = simple structure = high fragility\n",
                "    High Betti-1 (many loops) = complex structure = low fragility\n",
                "    \"\"\"\n",
                "    # Count persistent features in dimension 1 (loops)\n",
                "    h1_features = []\n",
                "    total_persistence = 0\n",
                "    \n",
                "    for dim, (birth, death) in diag:\n",
                "        if dim == 1:  # 1-dimensional holes (loops)\n",
                "            if death == float('inf'):\n",
                "                life = 2.0 - birth  # Assume max edge = 2.0\n",
                "            else:\n",
                "                life = death - birth\n",
                "            \n",
                "            if life > 0.1:  # Filter noise\n",
                "                h1_features.append(life)\n",
                "                total_persistence += life\n",
                "    \n",
                "    # Complexity score: normalized total persistence\n",
                "    complexity = min(total_persistence * 10, 100)\n",
                "    \n",
                "    # Fragility is inverse of complexity\n",
                "    fragility = 100 - complexity\n",
                "    \n",
                "    return {\n",
                "        'fragility': fragility,\n",
                "        'complexity': complexity,\n",
                "        'n_loops': len(h1_features),\n",
                "        'total_persistence': total_persistence\n",
                "    }\n",
                "\n",
                "# Test on recent data\n",
                "recent_returns = returns_df.tail(60)\n",
                "dist_matrix = compute_distance_matrix(recent_returns)\n",
                "diag = compute_persistence_diagram(dist_matrix)\n",
                "score = compute_fragility_score(diag)\n",
                "\n",
                "print(f\"\\nCurrent Fragility Score: {score['fragility']:.1f}%\")\n",
                "print(f\"Complexity: {score['complexity']:.1f}\")\n",
                "print(f\"Persistent Loops: {score['n_loops']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Rolling Fragility Signal (250-day early warning)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def compute_rolling_fragility(returns_df, window=60, step=5):\n",
                "    \"\"\"\n",
                "    Compute rolling fragility score over time.\n",
                "    \n",
                "    This is the key early warning indicator:\n",
                "    Rising fragility = market structure simplifying = crisis approaching\n",
                "    \"\"\"\n",
                "    dates = []\n",
                "    fragilities = []\n",
                "    complexities = []\n",
                "    \n",
                "    for i in tqdm(range(window, len(returns_df), step), desc=\"Computing fragility\"):\n",
                "        window_returns = returns_df.iloc[i-window:i]\n",
                "        \n",
                "        try:\n",
                "            dist = compute_distance_matrix(window_returns)\n",
                "            diag = compute_persistence_diagram(dist)\n",
                "            score = compute_fragility_score(diag)\n",
                "            \n",
                "            dates.append(returns_df.index[i])\n",
                "            fragilities.append(score['fragility'])\n",
                "            complexities.append(score['complexity'])\n",
                "        except Exception as e:\n",
                "            pass\n",
                "    \n",
                "    result = pd.DataFrame({\n",
                "        'date': dates,\n",
                "        'fragility': fragilities,\n",
                "        'complexity': complexities\n",
                "    }).set_index('date')\n",
                "    \n",
                "    return result\n",
                "\n",
                "# Compute rolling fragility\n",
                "fragility_series = compute_rolling_fragility(returns_df, window=60, step=5)\n",
                "\n",
                "print(f\"\\nFragility series: {len(fragility_series)} observations\")\n",
                "print(f\"Date range: {fragility_series.index.min()} to {fragility_series.index.max()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Visualize: Fragility vs Crisis Events"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Known crisis dates\n",
                "CRISIS_EVENTS = {\n",
                "    '2000-03-10': 'Dot-Com Peak',\n",
                "    '2007-10-09': 'Pre-GFC Peak',\n",
                "    '2008-09-15': 'Lehman Collapse',\n",
                "    '2020-02-19': 'COVID Peak',\n",
                "    '2022-01-03': 'Rate Hike Cycle'\n",
                "}\n",
                "\n",
                "fig, axes = plt.subplots(2, 1, figsize=(16, 10), sharex=True)\n",
                "\n",
                "# Fragility\n",
                "ax1 = axes[0]\n",
                "ax1.fill_between(fragility_series.index, fragility_series['fragility'], \n",
                "                 alpha=0.3, color='red')\n",
                "ax1.plot(fragility_series.index, fragility_series['fragility'], \n",
                "         color='red', linewidth=1.5, label='Fragility')\n",
                "\n",
                "# Mark crisis events\n",
                "for date, name in CRISIS_EVENTS.items():\n",
                "    try:\n",
                "        ax1.axvline(pd.Timestamp(date), color='black', linestyle='--', alpha=0.7)\n",
                "        ax1.text(pd.Timestamp(date), ax1.get_ylim()[1]*0.95, name, \n",
                "                rotation=45, fontsize=8, ha='right')\n",
                "    except:\n",
                "        pass\n",
                "\n",
                "ax1.set_ylabel('Fragility Score', fontsize=12)\n",
                "ax1.set_title('Great Caria: Topological Fragility Early Warning Signal', fontsize=14)\n",
                "ax1.axhline(70, color='orange', linestyle=':', label='Warning Threshold (70)')\n",
                "ax1.axhline(85, color='red', linestyle=':', label='Critical Threshold (85)')\n",
                "ax1.legend(loc='upper left')\n",
                "ax1.grid(True, alpha=0.3)\n",
                "\n",
                "# Market index (S&P 500 as reference)\n",
                "ax2 = axes[1]\n",
                "if 'USA' in returns_df.columns:\n",
                "    cumulative = (1 + returns_df['USA']).cumprod()\n",
                "    ax2.plot(cumulative.index, cumulative, color='blue', linewidth=1.5)\n",
                "    ax2.set_ylabel('S&P 500 (Cumulative)', fontsize=12)\n",
                "    ax2.set_yscale('log')\n",
                "    \n",
                "    # Mark crisis events\n",
                "    for date, name in CRISIS_EVENTS.items():\n",
                "        try:\n",
                "            ax2.axvline(pd.Timestamp(date), color='black', linestyle='--', alpha=0.7)\n",
                "        except:\n",
                "            pass\n",
                "\n",
                "ax2.grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('great_caria_fragility_history.png', dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Export Fragility Signal"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "\n",
                "# Current fragility status\n",
                "current = fragility_series.iloc[-1]\n",
                "\n",
                "# Determine status\n",
                "if current['fragility'] >= 85:\n",
                "    status = 'CRITICAL'\n",
                "    color = 'red'\n",
                "elif current['fragility'] >= 70:\n",
                "    status = 'WARNING'\n",
                "    color = 'orange'\n",
                "elif current['fragility'] >= 50:\n",
                "    status = 'ELEVATED'\n",
                "    color = 'yellow'\n",
                "else:\n",
                "    status = 'STABLE'\n",
                "    color = 'green'\n",
                "\n",
                "fragility_output = {\n",
                "    'timestamp': pd.Timestamp.now().isoformat(),\n",
                "    'current': {\n",
                "        'fragility': float(current['fragility']),\n",
                "        'complexity': float(current['complexity']),\n",
                "        'status': status,\n",
                "        'color': color\n",
                "    },\n",
                "    'history': {\n",
                "        'dates': [d.isoformat() for d in fragility_series.index[-30:]],\n",
                "        'fragility': fragility_series['fragility'].tail(30).tolist()\n",
                "    },\n",
                "    'interpretation': {\n",
                "        'CRITICAL': 'Market topology collapsed. Correlation approaching 1. Systemic risk extreme.',\n",
                "        'WARNING': 'Structure simplifying. Diversification failing. Heightened fragility.',\n",
                "        'ELEVATED': 'Some stress detected. Monitor closely.',\n",
                "        'STABLE': 'Complex, sponge-like topology. Healthy market structure.'\n",
                "    }\n",
                "}\n",
                "\n",
                "with open('great_caria_fragility.json', 'w') as f:\n",
                "    json.dump(fragility_output, f, indent=2)\n",
                "\n",
                "print(f\"\\n\" + \"=\"*50)\n",
                "print(f\"GREAT CARIA FRAGILITY STATUS: {status}\")\n",
                "print(f\"=\"*50)\n",
                "print(f\"Fragility Score: {current['fragility']:.1f}%\")\n",
                "print(f\"Complexity: {current['complexity']:.1f}\")\n",
                "print(f\"\\nExported to great_caria_fragility.json\")"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}