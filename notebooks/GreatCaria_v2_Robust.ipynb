{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# GREAT CARIA v2.0 - Robust Implementation\n\nWith proper purge/embargo validation and CF change-of-direction target."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.metrics import accuracy_score\n",
                "from tqdm.auto import tqdm\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Device: {device}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === 1. LOAD DATA ===\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "MARKET_PATH = '/content/drive/MyDrive/CARIA/data/raw/yahoo_market.parquet'\n",
                "df_daily = pd.read_parquet(MARKET_PATH)\n",
                "COUNTRIES = ['USA', 'CHN', 'JPN', 'DEU', 'GBR', 'FRA', 'BRA', 'MEX', 'KOR', 'AUS']\n",
                "print(f\"Loaded: {df_daily.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === 2. COMPUTE CRISIS FACTOR ===\n",
                "index_cols = [f'{c}_index' for c in COUNTRIES if f'{c}_index' in df_daily.columns]\n",
                "returns = df_daily[index_cols].pct_change().dropna()\n",
                "returns.columns = [c.replace('_index', '') for c in returns.columns]\n",
                "\n",
                "def compute_cf(returns, window=20):\n",
                "    cf = []\n",
                "    for i in range(window, len(returns)):\n",
                "        w = returns.iloc[i-window:i]\n",
                "        corr = w.corr().values\n",
                "        avg_corr = (corr.sum() - len(corr)) / (len(corr) * (len(corr) - 1))\n",
                "        avg_vol = w.std().mean()\n",
                "        cf.append(avg_corr * avg_vol * 100)\n",
                "    return pd.Series(cf, index=returns.index[window:])\n",
                "\n",
                "CF = compute_cf(returns)\n",
                "print(f\"CF computed: {len(CF)} samples\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === 3. TARGET: CF CHANGE-OF-DIRECTION ===\n",
                "HORIZON = 5\n",
                "cf_future = CF.shift(-HORIZON)\n",
                "cf_change = (cf_future > CF).astype(int)  # 1 = CF will increase\n",
                "cf_change = cf_change.dropna()\n",
                "print(f\"Target samples: {len(cf_change)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === 4. FEATURES ===\n",
                "features = pd.DataFrame(index=cf_change.index)\n",
                "features['cf_now'] = CF.loc[cf_change.index]\n",
                "features['cf_ma5'] = CF.rolling(5).mean().loc[cf_change.index]\n",
                "features['cf_ma20'] = CF.rolling(20).mean().loc[cf_change.index]\n",
                "features['vix'] = df_daily['VIX'].loc[cf_change.index]\n",
                "features['dxy'] = df_daily['DXY'].loc[cf_change.index]\n",
                "features['ret_usa'] = returns['USA'].rolling(5).mean().loc[cf_change.index]\n",
                "features['ret_bra'] = returns['BRA'].rolling(5).mean().loc[cf_change.index] if 'BRA' in returns else 0\n",
                "\n",
                "features = features.dropna()\n",
                "target = cf_change.loc[features.index]\n",
                "print(f\"Final samples: {len(features)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === 5. PURGED TEMPORAL SPLIT ===\n",
                "PURGE = 20\n",
                "EMBARGO = 10\n",
                "train_end = int(len(features) * 0.7)\n",
                "test_start = train_end + PURGE + EMBARGO\n",
                "\n",
                "X_train = features.iloc[:train_end].values\n",
                "y_train = target.iloc[:train_end].values\n",
                "X_test = features.iloc[test_start:].values\n",
                "y_test = target.iloc[test_start:].values\n",
                "\n",
                "mu, sigma = X_train.mean(axis=0), X_train.std(axis=0) + 1e-8\n",
                "X_train = (X_train - mu) / sigma\n",
                "X_test = (X_test - mu) / sigma\n",
                "\n",
                "print(f\"Train: {len(X_train)}, Test: {len(X_test)} (purge={PURGE}, embargo={EMBARGO})\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === 6. LOGISTIC REGRESSION BASELINE ===\n",
                "lr = LogisticRegression(max_iter=1000, C=0.1)\n",
                "lr.fit(X_train, y_train)\n",
                "y_pred_lr = lr.predict(X_test)\n",
                "acc_lr = accuracy_score(y_test, y_pred_lr)\n",
                "print(f\"\\nLogistic Regression Accuracy (purged): {acc_lr:.1%}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === 7. SHUFFLE TEST ===\n",
                "y_train_shuffled = np.random.permutation(y_train)\n",
                "lr_shuffle = LogisticRegression(max_iter=1000, C=0.1)\n",
                "lr_shuffle.fit(X_train, y_train_shuffled)\n",
                "y_pred_shuffle = lr_shuffle.predict(X_test)\n",
                "acc_shuffle = accuracy_score(y_test, y_pred_shuffle)\n",
                "print(f\"Shuffled Accuracy: {acc_shuffle:.1%}\")\n",
                "print(f\"Lift over random: {(acc_lr - acc_shuffle)*100:.1f}pp\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === 8. ROLLING OOS VALIDATION ===\n",
                "n_folds = 5\n",
                "fold_size = len(features) // (n_folds + 1)\n",
                "rolling_accs = []\n",
                "\n",
                "for i in range(n_folds):\n",
                "    train_end = (i + 1) * fold_size\n",
                "    test_start = train_end + PURGE + EMBARGO\n",
                "    test_end = test_start + fold_size\n",
                "    \n",
                "    if test_end > len(features):\n",
                "        break\n",
                "    \n",
                "    X_tr = features.iloc[:train_end].values\n",
                "    y_tr = target.iloc[:train_end].values\n",
                "    X_te = features.iloc[test_start:test_end].values\n",
                "    y_te = target.iloc[test_start:test_end].values\n",
                "    \n",
                "    mu, sigma = X_tr.mean(axis=0), X_tr.std(axis=0) + 1e-8\n",
                "    X_tr = (X_tr - mu) / sigma\n",
                "    X_te = (X_te - mu) / sigma\n",
                "    \n",
                "    lr_fold = LogisticRegression(max_iter=1000, C=0.1)\n",
                "    lr_fold.fit(X_tr, y_tr)\n",
                "    acc = accuracy_score(y_te, lr_fold.predict(X_te))\n",
                "    rolling_accs.append(acc)\n",
                "    print(f\"  Fold {i+1}: {acc:.1%}\")\n",
                "\n",
                "print(f\"\\nRolling OOS Mean: {np.mean(rolling_accs):.1%} ± {np.std(rolling_accs):.1%}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === 9. SUMMARY ===\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"GREAT CARIA v2.0 VALIDATION RESULTS\")\n",
                "print(\"=\"*50)\n",
                "print(f\"Main accuracy (purged): {acc_lr:.1%}\")\n",
                "print(f\"Shuffle accuracy:       {acc_shuffle:.1%}\")\n",
                "print(f\"Lift over random:       {(acc_lr - acc_shuffle)*100:.1f}pp\")\n",
                "print(f\"Rolling OOS mean:       {np.mean(rolling_accs):.1%}\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "if acc_lr > 0.55 and (acc_lr - acc_shuffle) > 0.03:\n",
                "    print(\"✓ PASSED - Real signal detected\")\n",
                "else:\n",
                "    print(\"✗ FAILED - Signal is marginal or noise\")"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4"
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}