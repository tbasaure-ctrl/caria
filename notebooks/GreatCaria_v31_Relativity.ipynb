{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# GREAT CARIA v3.1 - Relatividad General Financiera (Final)\n",
                "\n",
                "## La Funci√≥n de Onda de Colapso Œ®(t)\n",
                "\n",
                "$$\\Psi(t) = \\frac{\\mu_{stress}(t)}{\\sqrt{H_{total}(t)^2 + \\hbar^2}}$$\n",
                "\n",
                "### Mejoras v3.1:\n",
                "\n",
                "1. **‚Ñè (h_bar)**: Constante de Planck Financiera (m√≠nima volatilidad hist√≥rica)\n",
                "2. **Esp√≠n Geogr√°fico**: G7 inestable es M√ÅS peligroso que EM inestable\n",
                "3. **Horizonte de Sucesos**: Visualizaci√≥n cuando W(t) < umbral cr√≠tico\n",
                "\n",
                "### Nomenclatura\n",
                "\n",
                "| S√≠mbolo | Significado |\n",
                "|---------|-------------|\n",
                "| Œ®(t) | Funci√≥n de Onda de Colapso (IFI) |\n",
                "| Œº | Masa inercial (consenso del mercado) |\n",
                "| H | Curvatura espacio-tiempo (sincronizaci√≥n) |\n",
                "| ‚Ñè | L√≠mite f√≠sico de liquidez |\n",
                "| W(t) | Ancho del cono de probabilidad |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === SETUP ===\n",
                "!pip install PyWavelets scikit-learn -q\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from scipy import stats, signal\n",
                "import pywt\n",
                "from sklearn.metrics import roc_curve, auc\n",
                "import matplotlib.pyplot as plt\n",
                "from matplotlib.colors import LinearSegmentedColormap\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "print('='*70)\n",
                "print('GREAT CARIA v3.1 - RELATIVIDAD GENERAL FINANCIERA')\n",
                "print('La Funci√≥n de Onda de Colapso: Œ®(t) = Œº / ‚àö(H¬≤ + ‚Ñè¬≤)')\n",
                "print('='*70)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === LOAD DATA ===\n",
                "DATA_PATH = '/content/drive/MyDrive/Caria/yahoo_market.parquet'\n",
                "df = pd.read_parquet(DATA_PATH)\n",
                "df.index = pd.to_datetime(df.index)\n",
                "\n",
                "# Geographic blocks\n",
                "G7 = ['USA', 'GBR', 'DEU', 'FRA', 'JPN', 'CAN']\n",
                "EM = ['CHN', 'BRA', 'IND', 'MEX', 'KOR', 'ZAF', 'AUS']\n",
                "\n",
                "all_countries = [c.replace('_index', '') for c in df.columns if '_index' in c]\n",
                "g7_avail = [c for c in G7 if c in all_countries]\n",
                "em_avail = [c for c in EM if c in all_countries]\n",
                "\n",
                "print(f'G7: {g7_avail}')\n",
                "print(f'EM: {em_avail}')\n",
                "\n",
                "# Returns\n",
                "idx_cols = [f'{c}_index' for c in all_countries]\n",
                "ret = df[idx_cols].pct_change().dropna()\n",
                "ret.columns = [c.replace('_index', '') for c in ret.columns]\n",
                "\n",
                "ret_g7 = ret[[c for c in g7_avail if c in ret.columns]]\n",
                "ret_em = ret[[c for c in em_avail if c in ret.columns]]\n",
                "\n",
                "print(f'\\nData: {ret.shape[0]} days')\n",
                "print(f'Period: {ret.index.min().date()} to {ret.index.max().date()}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === CRISIS CATALOG ===\n",
                "CRISES = {\n",
                "    'Lehman': pd.Timestamp('2008-09-15'),\n",
                "    'Flash_Crash': pd.Timestamp('2010-05-06'),\n",
                "    'Euro_Crisis': pd.Timestamp('2011-08-05'),\n",
                "    'China_Crash': pd.Timestamp('2015-08-24'),\n",
                "    'Brexit': pd.Timestamp('2016-06-24'),\n",
                "    'COVID': pd.Timestamp('2020-03-11'),\n",
                "    'Gilt_Crisis': pd.Timestamp('2022-09-23'),\n",
                "    'SVB': pd.Timestamp('2023-03-10')\n",
                "}\n",
                "CRISES = {k: v for k, v in CRISES.items() if v >= ret.index.min()}\n",
                "print(f'Crises: {len(CRISES)}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# PART 1: CRISIS FACTOR & TEMPORAL DECOMPOSITION"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === CRISIS FACTOR ===\n",
                "def compute_cf(r, window=20):\n",
                "    cf = []\n",
                "    for i in range(window, len(r)):\n",
                "        wr = r.iloc[i-window:i]\n",
                "        corr = wr.corr().values\n",
                "        n = len(corr)\n",
                "        avg_corr = (corr.sum() - n) / (n * (n - 1))\n",
                "        avg_vol = wr.std().mean()\n",
                "        cf.append(avg_corr * avg_vol * 100)\n",
                "    return pd.Series(cf, index=r.index[window:])\n",
                "\n",
                "CF = compute_cf(ret)\n",
                "print(f'CF computed: {len(CF)} obs')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === 3-BAND DECOMPOSITION ===\n",
                "def decompose_3bands(series, wavelet='db4'):\n",
                "    coeffs = pywt.wavedec(series.values, wavelet, level=6)\n",
                "    \n",
                "    # Fast (<10d)\n",
                "    fast_c = [np.zeros_like(c) for c in coeffs]\n",
                "    for i in range(min(3, len(coeffs))):\n",
                "        fast_c[i] = coeffs[i]\n",
                "    fast = pywt.waverec(fast_c, wavelet)[:len(series)]\n",
                "    \n",
                "    # Medium (10-60d)\n",
                "    med_c = [np.zeros_like(c) for c in coeffs]\n",
                "    for i in range(3, min(5, len(coeffs))):\n",
                "        med_c[i] = coeffs[i]\n",
                "    medium = pywt.waverec(med_c, wavelet)[:len(series)]\n",
                "    \n",
                "    # Slow (>60d)\n",
                "    slow_c = [np.zeros_like(c) for c in coeffs]\n",
                "    for i in range(5, len(coeffs)):\n",
                "        slow_c[i] = coeffs[i]\n",
                "    slow = pywt.waverec(slow_c, wavelet)[:len(series)]\n",
                "    \n",
                "    return {\n",
                "        'fast': pd.Series(fast, index=series.index),\n",
                "        'medium': pd.Series(medium, index=series.index),\n",
                "        'slow': pd.Series(slow, index=series.index)\n",
                "    }\n",
                "\n",
                "bands = decompose_3bands(CF)\n",
                "print('3 Bands: Fast, Medium, Slow')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# PART 2: GEOGRAPHIC RELATIVITY WITH SPIN"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === MODIFICATION 2: GEOGRAPHIC SPIN ===\n",
                "# G7 instability is MORE dangerous than EM instability\n",
                "\n",
                "def compute_geographic_with_spin(ret_g7, ret_em, window=60, alpha=0.5):\n",
                "    \"\"\"\n",
                "    H_geo = Œî_geo √ó (1 + Œ± √ó sign(œÉ¬≤_EM - œÉ¬≤_G7))\n",
                "    \n",
                "    When G7 > EM: spin term is negative, H_geo decreases ‚Üí MORE DANGER\n",
                "    When EM > G7: spin term is positive, H_geo increases ‚Üí LESS DANGER (normal)\n",
                "    \"\"\"\n",
                "    var_g7 = ret_g7.var(axis=1).rolling(window).mean()\n",
                "    var_em = ret_em.var(axis=1).rolling(window).mean()\n",
                "    \n",
                "    # Raw delta\n",
                "    delta_geo = (var_g7 - var_em).abs()\n",
                "    \n",
                "    # Spin: sign of (EM - G7)\n",
                "    # If EM > G7: spin = +1 (normal, healthy)\n",
                "    # If G7 > EM: spin = -1 (inverted, dangerous)\n",
                "    spin = np.sign(var_em - var_g7)\n",
                "    \n",
                "    # H_geo with spin adjustment\n",
                "    H_geo = delta_geo * (1 + alpha * spin)\n",
                "    \n",
                "    # When G7 > EM, H_geo is reduced (more synchronized = more dangerous)\n",
                "    return H_geo, delta_geo, var_g7, var_em, spin\n",
                "\n",
                "H_GEO, DELTA_GEO, VAR_G7, VAR_EM, SPIN = compute_geographic_with_spin(ret_g7, ret_em)\n",
                "\n",
                "print('Geographic Spin Analysis:')\n",
                "print(f'  G7 > EM periods: {(SPIN < 0).sum()} days ({100*(SPIN < 0).mean():.1f}%)')\n",
                "print(f'  EM > G7 periods: {(SPIN > 0).sum()} days ({100*(SPIN > 0).mean():.1f}%)')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === VISUALIZE SPIN ===\n",
                "fig, axes = plt.subplots(3, 1, figsize=(14, 10), sharex=True)\n",
                "\n",
                "# Panel A: G7 vs EM variance\n",
                "ax1 = axes[0]\n",
                "ax1.plot(VAR_G7.index, VAR_G7.values, 'b-', label='G7 (Core)', linewidth=1)\n",
                "ax1.plot(VAR_EM.index, VAR_EM.values, 'orange', label='EM (Periphery)', linewidth=1)\n",
                "ax1.set_ylabel('Variance')\n",
                "ax1.set_title('A. Temporal Relativity: G7 vs Emerging Markets')\n",
                "ax1.legend()\n",
                "\n",
                "# Panel B: Spin (which is unstable?)\n",
                "ax2 = axes[1]\n",
                "ax2.fill_between(SPIN.index, SPIN.values, 0, \n",
                "                 where=SPIN > 0, alpha=0.5, color='green', label='EM > G7 (Healthy)')\n",
                "ax2.fill_between(SPIN.index, SPIN.values, 0, \n",
                "                 where=SPIN <= 0, alpha=0.5, color='red', label='G7 > EM (DANGER)')\n",
                "ax2.axhline(0, color='black', linewidth=0.5)\n",
                "ax2.set_ylabel('Spin S')\n",
                "ax2.set_title('B. Geographic Spin: Core Instability = DANGER')\n",
                "ax2.legend()\n",
                "\n",
                "# Panel C: H_geo with spin adjustment\n",
                "ax3 = axes[2]\n",
                "ax3.fill_between(H_GEO.index, H_GEO.values, alpha=0.5, color='purple')\n",
                "ax3.plot(H_GEO.index, H_GEO.values, 'purple', linewidth=0.5)\n",
                "ax3.set_ylabel('H_geo (with spin)')\n",
                "ax3.set_title('C. Geographic Uncertainty (reduced when G7 is unstable)')\n",
                "\n",
                "for ax in axes:\n",
                "    for name, date in CRISES.items():\n",
                "        if date > VAR_G7.index.min() and date < VAR_G7.index.max():\n",
                "            ax.axvline(date, color='gray', alpha=0.3, linestyle=':')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('/content/drive/MyDrive/Caria/great_caria_v31_spin.png', dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# PART 3: THE FINANCIAL PLANCK CONSTANT (‚Ñè)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === MODIFICATION 1: PLANCK CONSTANT ===\n",
                "# ‚Ñè = minimum irreducible volatility (physical limit of liquidity)\n",
                "\n",
                "def compute_planck_constant(returns, window=252):\n",
                "    \"\"\"\n",
                "    The Financial Planck Constant (‚Ñè) is the minimum historical volatility.\n",
                "    This represents the irreducible \"quantum noise\" of the market:\n",
                "    - Transaction costs\n",
                "    - Latency\n",
                "    - Minimum liquidity\n",
                "    \"\"\"\n",
                "    # Rolling volatility\n",
                "    rolling_vol = returns.std(axis=1).rolling(window).mean()\n",
                "    \n",
                "    # ‚Ñè = minimum of the 5th percentile (robust to outliers)\n",
                "    h_bar = rolling_vol.quantile(0.05)\n",
                "    \n",
                "    return h_bar\n",
                "\n",
                "H_BAR = compute_planck_constant(ret)\n",
                "\n",
                "print('=== Financial Planck Constant ===')\n",
                "print(f'‚Ñè = {H_BAR:.6f}')\n",
                "print(f'Interpretation: This is the minimum \"quantum blur\" of the market.')\n",
                "print(f'Uncertainty can never fall below this level.')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# PART 4: THE WAVEFUNCTION Œ®(t)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === COMPUTE Œº (Mean Stress) ===\n",
                "def normalize(s):\n",
                "    return (s - s.mean()) / (s.std() + 1e-8)\n",
                "\n",
                "WEIGHTS = {'fast': 0.15, 'medium': 0.35, 'slow': 0.50}\n",
                "\n",
                "s_fast = normalize(bands['fast'])\n",
                "s_medium = normalize(bands['medium'])\n",
                "s_slow = normalize(bands['slow'])\n",
                "\n",
                "MU = (WEIGHTS['fast'] * s_fast + \n",
                "      WEIGHTS['medium'] * s_medium + \n",
                "      WEIGHTS['slow'] * s_slow)\n",
                "\n",
                "print(f'Œº computed: mean={MU.mean():.3f}, std={MU.std():.3f}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === COMPUTE H_temp (Temporal Uncertainty) ===\n",
                "H_TEMP = np.sqrt(\n",
                "    WEIGHTS['fast'] * (s_fast - MU)**2 +\n",
                "    WEIGHTS['medium'] * (s_medium - MU)**2 +\n",
                "    WEIGHTS['slow'] * (s_slow - MU)**2\n",
                ")\n",
                "\n",
                "print(f'H_temp computed: mean={H_TEMP.mean():.3f}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === COMPUTE H_total WITH PLANCK LIMIT ===\n",
                "# H_total = H_temp + Œª * H_geo\n",
                "# But now we use the Lorentzian smoothing: ‚àö(H¬≤ + ‚Ñè¬≤)\n",
                "\n",
                "LAMBDA = 0.3  # Geographic sensitivity\n",
                "\n",
                "# Align indices\n",
                "common_idx = MU.index.intersection(H_GEO.dropna().index)\n",
                "\n",
                "h_temp_aligned = H_TEMP.loc[common_idx]\n",
                "h_geo_aligned = normalize(H_GEO.loc[common_idx]).abs()  # Normalize to same scale\n",
                "mu_aligned = MU.loc[common_idx]\n",
                "\n",
                "# Total uncertainty (before Planck limit)\n",
                "H_raw = h_temp_aligned + LAMBDA * h_geo_aligned\n",
                "\n",
                "# Scale ‚Ñè to match H units\n",
                "h_bar_scaled = H_BAR * 100  # Scale factor\n",
                "\n",
                "# THE LORENTZIAN SMOOTHING: ‚àö(H¬≤ + ‚Ñè¬≤)\n",
                "H_TOTAL = np.sqrt(H_raw**2 + h_bar_scaled**2)\n",
                "\n",
                "print(f'H_total (with Planck limit): mean={H_TOTAL.mean():.3f}')\n",
                "print(f'Minimum possible H: {H_TOTAL.min():.3f} (never zero!)')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === THE WAVEFUNCTION Œ®(t) ===\n",
                "# Œ® = Œº / ‚àö(H¬≤ + ‚Ñè¬≤)\n",
                "\n",
                "# Shift Œº to positive for meaningful division\n",
                "mu_positive = mu_aligned - mu_aligned.min() + 0.1\n",
                "\n",
                "# The Wavefunction (collapse indicator)\n",
                "PSI = mu_positive / H_TOTAL\n",
                "\n",
                "# Normalize to [0, 1]\n",
                "PSI_norm = (PSI - PSI.min()) / (PSI.max() - PSI.min())\n",
                "\n",
                "print(f'Œ®(t) computed: range=[{PSI_norm.min():.3f}, {PSI_norm.max():.3f}]')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# PART 5: THE EVENT HORIZON"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === MODIFICATION 3: EVENT HORIZON ===\n",
                "# When cone width W(t) < critical threshold, we're inside the black hole\n",
                "\n",
                "K = 2.0  # Standard deviations for cone\n",
                "\n",
                "# Cone width: W(t) = 2 * k * H(t)\n",
                "CONE_WIDTH = 2 * K * H_TOTAL\n",
                "\n",
                "# Schwarzschild Radius: 10th percentile of cone width\n",
                "SCHWARZSCHILD = CONE_WIDTH.quantile(0.10)\n",
                "\n",
                "# Event Horizon: when inside (W < Rs)\n",
                "INSIDE_HORIZON = CONE_WIDTH < SCHWARZSCHILD\n",
                "\n",
                "print('=== Event Horizon Detection ===')\n",
                "print(f'Schwarzschild Radius (Rs): {SCHWARZSCHILD:.3f}')\n",
                "print(f'Days inside horizon: {INSIDE_HORIZON.sum()} ({100*INSIDE_HORIZON.mean():.1f}%)')\n",
                "\n",
                "# Upper/Lower bounds of the cone\n",
                "UPPER = mu_aligned + K * H_TOTAL\n",
                "LOWER = mu_aligned - K * H_TOTAL"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === THE CARIA UNCERTAINTY PRINCIPLE - FINAL VISUALIZATION ===\n",
                "\n",
                "fig, axes = plt.subplots(2, 1, figsize=(14, 10), sharex=True)\n",
                "\n",
                "# Panel A: Multi-Scale Dynamics\n",
                "ax1 = axes[0]\n",
                "ax1.plot(s_slow.loc[common_idx].index, s_slow.loc[common_idx].values, \n",
                "         'b-', linewidth=1.5, label='Slow (Structure)')\n",
                "ax1.plot(s_medium.loc[common_idx].index, s_medium.loc[common_idx].values, \n",
                "         color='gold', linewidth=1, label='Medium (Resonance)')\n",
                "ax1.plot(s_fast.loc[common_idx].index, s_fast.loc[common_idx].values, \n",
                "         'gray', alpha=0.5, linewidth=0.5, label='Fast (Noise)')\n",
                "ax1.set_ylabel('Stress Level')\n",
                "ax1.set_title('A. Multi-Scale Dynamics (Dissociated vs. Synchronized)')\n",
                "ax1.legend(loc='upper left')\n",
                "\n",
                "# Panel B: The Probability Cone with Event Horizon\n",
                "ax2 = axes[1]\n",
                "\n",
                "# Regular cone (pink)\n",
                "ax2.fill_between(mu_aligned.index, LOWER.values, UPPER.values, \n",
                "                 where=~INSIDE_HORIZON, alpha=0.3, color='pink', \n",
                "                 label='Heisenberg Uncertainty (H)')\n",
                "\n",
                "# EVENT HORIZON (black) - when cone collapses\n",
                "ax2.fill_between(mu_aligned.index, LOWER.values, UPPER.values, \n",
                "                 where=INSIDE_HORIZON, alpha=0.7, color='black', \n",
                "                 label='üï≥Ô∏è Event Horizon (No escape)')\n",
                "\n",
                "# Wavefunction collapse markers\n",
                "collapse_dates = mu_aligned.index[INSIDE_HORIZON]\n",
                "for i, d in enumerate(collapse_dates):\n",
                "    if i == 0 or (d - collapse_dates[i-1]).days > 30:\n",
                "        ax2.annotate('Collapse\\n(Sync)', xy=(d, UPPER.loc[d]), \n",
                "                     fontsize=8, color='red', ha='center')\n",
                "\n",
                "# Mean line\n",
                "ax2.plot(mu_aligned.index, mu_aligned.values, 'darkred', \n",
                "         linewidth=1.5, label='Œ® (Mean State)')\n",
                "\n",
                "ax2.set_ylabel('Systemic Fragility (Probabilistic)')\n",
                "ax2.set_title('B. Caria Uncertainty Principle: The Probability Cone')\n",
                "ax2.legend(loc='upper left')\n",
                "\n",
                "# Add annotation for key concepts\n",
                "ax2.annotate('High Uncertainty\\n(Decoupled)', \n",
                "             xy=(common_idx[int(len(common_idx)*0.3)], UPPER.iloc[int(len(common_idx)*0.3)]),\n",
                "             fontsize=9, color='gray', ha='center')\n",
                "\n",
                "# Crisis markers\n",
                "for ax in axes:\n",
                "    for name, date in CRISES.items():\n",
                "        if date in common_idx or (date > common_idx.min() and date < common_idx.max()):\n",
                "            ax.axvline(date, color='blue', alpha=0.3, linestyle=':')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('/content/drive/MyDrive/Caria/great_caria_v31_uncertainty.png', dpi=200)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# PART 6: VALIDATION"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === ROC/AUC VALIDATION ===\n",
                "\n",
                "# Crisis labels\n",
                "def create_labels(index, crises, pre=20, post=10):\n",
                "    labels = pd.Series(0, index=index)\n",
                "    for name, date in crises.items():\n",
                "        start = date - pd.Timedelta(days=pre)\n",
                "        end = date + pd.Timedelta(days=post)\n",
                "        labels[(labels.index >= start) & (labels.index <= end)] = 1\n",
                "    return labels\n",
                "\n",
                "y_true = create_labels(PSI_norm.index, CRISES)\n",
                "\n",
                "# Baselines\n",
                "cf_aligned = CF.loc[PSI_norm.index]\n",
                "cf_norm = (cf_aligned - cf_aligned.min()) / (cf_aligned.max() - cf_aligned.min())\n",
                "\n",
                "inverse_H = 1 / H_TOTAL\n",
                "inverse_H_norm = (inverse_H - inverse_H.min()) / (inverse_H.max() - inverse_H.min())\n",
                "\n",
                "models = {\n",
                "    'Œ®(t) = Œº/‚àö(H¬≤+‚Ñè¬≤)': PSI_norm,\n",
                "    'CF Only': cf_norm,\n",
                "    '1/H (Sync Danger)': inverse_H_norm,\n",
                "    'Event Horizon': INSIDE_HORIZON.astype(float)\n",
                "}\n",
                "\n",
                "# ROC\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "ax1 = axes[0]\n",
                "auc_results = {}\n",
                "for name, score in models.items():\n",
                "    fpr, tpr, _ = roc_curve(y_true, score)\n",
                "    roc_auc = auc(fpr, tpr)\n",
                "    auc_results[name] = roc_auc\n",
                "    lw = 2.5 if 'Œ®' in name else 1.5\n",
                "    ax1.plot(fpr, tpr, label=f'{name} (AUC={roc_auc:.3f})', linewidth=lw)\n",
                "\n",
                "ax1.plot([0, 1], [0, 1], 'k--')\n",
                "ax1.set_xlabel('False Positive Rate')\n",
                "ax1.set_ylabel('True Positive Rate')\n",
                "ax1.set_title('ROC Curves: Œ®(t) vs Baselines')\n",
                "ax1.legend(loc='lower right')\n",
                "ax1.grid(True, alpha=0.3)\n",
                "\n",
                "# AUC bar\n",
                "ax2 = axes[1]\n",
                "colors = ['#10b981' if 'Œ®' in k else '#6b7280' for k in auc_results.keys()]\n",
                "ax2.barh(list(auc_results.keys()), list(auc_results.values()), color=colors)\n",
                "ax2.axvline(0.5, color='red', linestyle='--', label='Random')\n",
                "ax2.set_xlabel('AUC')\n",
                "ax2.set_xlim(0.4, 0.9)\n",
                "ax2.set_title('AUC Comparison')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('/content/drive/MyDrive/Caria/great_caria_v31_roc.png', dpi=150)\n",
                "plt.show()\n",
                "\n",
                "print('\\n=== AUC Results ===')\n",
                "for name, score in sorted(auc_results.items(), key=lambda x: -x[1]):\n",
                "    print(f'{name:25s}: {score:.3f}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === FINAL SUMMARY VISUALIZATION ===\n",
                "fig, axes = plt.subplots(4, 1, figsize=(14, 16), sharex=True)\n",
                "\n",
                "# A. Œ®(t) - The Wavefunction\n",
                "ax1 = axes[0]\n",
                "ax1.fill_between(PSI_norm.index, PSI_norm.values, alpha=0.5, color='red')\n",
                "ax1.plot(PSI_norm.index, PSI_norm.values, 'darkred', linewidth=0.5)\n",
                "ax1.axhline(PSI_norm.quantile(0.75), color='orange', linestyle='--', label='Warning (75%)')\n",
                "ax1.axhline(PSI_norm.quantile(0.95), color='red', linestyle='--', label='Critical (95%)')\n",
                "ax1.set_ylabel('Œ®(t)')\n",
                "ax1.set_title(f'A. Wavefunction of Collapse Œ®(t) = Œº/‚àö(H¬≤+‚Ñè¬≤) - AUC={auc_results.get(\"Œ®(t) = Œº/‚àö(H¬≤+‚Ñè¬≤)\", 0):.3f}')\n",
                "ax1.legend(loc='upper right')\n",
                "\n",
                "# B. H_total with Planck floor\n",
                "ax2 = axes[1]\n",
                "ax2.fill_between(H_TOTAL.index, H_TOTAL.values, alpha=0.5, color='purple')\n",
                "ax2.plot(H_TOTAL.index, H_TOTAL.values, 'purple', linewidth=0.5)\n",
                "ax2.axhline(h_bar_scaled, color='cyan', linestyle='--', label=f'‚Ñè (Planck floor) = {h_bar_scaled:.3f}')\n",
                "ax2.set_ylabel('H (Uncertainty)')\n",
                "ax2.set_title('B. Total Uncertainty H = ‚àö(H_temp + ŒªH_geo)¬≤ + ‚Ñè¬≤')\n",
                "ax2.legend()\n",
                "\n",
                "# C. Cone Width with Schwarzschild Radius\n",
                "ax3 = axes[2]\n",
                "ax3.fill_between(CONE_WIDTH.index, CONE_WIDTH.values, alpha=0.5, color='blue')\n",
                "ax3.plot(CONE_WIDTH.index, CONE_WIDTH.values, 'blue', linewidth=0.5)\n",
                "ax3.axhline(SCHWARZSCHILD, color='black', linewidth=2, linestyle='--', \n",
                "            label=f'üï≥Ô∏è Schwarzschild Radius = {SCHWARZSCHILD:.3f}')\n",
                "ax3.fill_between(CONE_WIDTH.index, 0, CONE_WIDTH.values, \n",
                "                 where=CONE_WIDTH < SCHWARZSCHILD, alpha=0.7, color='black')\n",
                "ax3.set_ylabel('W(t) = 2kH')\n",
                "ax3.set_title('C. Cone Width (Event Horizon when W < Rs)')\n",
                "ax3.legend()\n",
                "\n",
                "# D. S&P 500 with Event Horizon warnings\n",
                "ax4 = axes[3]\n",
                "if 'USA_index' in df.columns:\n",
                "    sp500 = df['USA_index'].loc[common_idx]\n",
                "    ax4.plot(sp500.index, sp500.values, 'k-', linewidth=0.5)\n",
                "    \n",
                "    # Event horizons (black holes)\n",
                "    ax4.fill_between(sp500.index, sp500.min(), sp500.max(),\n",
                "                     where=INSIDE_HORIZON, alpha=0.5, color='black', \n",
                "                     label='üï≥Ô∏è Inside Event Horizon')\n",
                "\n",
                "ax4.set_ylabel('S&P 500')\n",
                "ax4.set_title('D. Market with Event Horizon Warnings')\n",
                "ax4.set_yscale('log')\n",
                "ax4.legend()\n",
                "\n",
                "# Crisis markers\n",
                "for ax in axes:\n",
                "    for name, date in CRISES.items():\n",
                "        if date > common_idx.min() and date < common_idx.max():\n",
                "            ax.axvline(date, color='blue', alpha=0.3, linestyle=':')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('/content/drive/MyDrive/Caria/great_caria_v31_final.png', dpi=200, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === EXPORT ===\n",
                "import json\n",
                "from datetime import datetime\n",
                "\n",
                "current = {\n",
                "    'psi': float(PSI_norm.iloc[-1]),\n",
                "    'mu': float(mu_aligned.iloc[-1]),\n",
                "    'H_total': float(H_TOTAL.iloc[-1]),\n",
                "    'cone_width': float(CONE_WIDTH.iloc[-1]),\n",
                "    'inside_horizon': bool(INSIDE_HORIZON.iloc[-1]),\n",
                "    'spin': float(SPIN.iloc[-1]) if not pd.isna(SPIN.iloc[-1]) else 0\n",
                "}\n",
                "\n",
                "if current['psi'] >= PSI_norm.quantile(0.95):\n",
                "    status = 'CRITICAL'\n",
                "elif current['psi'] >= PSI_norm.quantile(0.75) or current['inside_horizon']:\n",
                "    status = 'WARNING'\n",
                "else:\n",
                "    status = 'STABLE'\n",
                "\n",
                "export = {\n",
                "    'version': 'Great Caria v3.1 (General Financial Relativity)',\n",
                "    'generated': datetime.now().isoformat(),\n",
                "    'equation': 'Œ®(t) = Œº / ‚àö(H¬≤ + ‚Ñè¬≤)',\n",
                "    'status': status,\n",
                "    'current': current,\n",
                "    'constants': {\n",
                "        'h_bar': float(h_bar_scaled),\n",
                "        'schwarzschild_radius': float(SCHWARZSCHILD),\n",
                "        'lambda_geo': LAMBDA\n",
                "    },\n",
                "    'thresholds': {\n",
                "        'warning': float(PSI_norm.quantile(0.75)),\n",
                "        'critical': float(PSI_norm.quantile(0.95))\n",
                "    },\n",
                "    'auc_scores': auc_results,\n",
                "    'physics': {\n",
                "        'h_bar_meaning': 'Minimum market quantum blur (irreducible volatility)',\n",
                "        'spin_meaning': 'G7 instability is more dangerous than EM instability',\n",
                "        'event_horizon': 'When cone width < Schwarzschild radius, no escape'\n",
                "    }\n",
                "}\n",
                "\n",
                "with open('/content/drive/MyDrive/Caria/great_caria_v31.json', 'w') as f:\n",
                "    json.dump(export, f, indent=2)\n",
                "\n",
                "print('\\n' + '='*70)\n",
                "print('GREAT CARIA v3.1 - FINAL SUMMARY')\n",
                "print('='*70)\n",
                "print(json.dumps(export, indent=2))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}