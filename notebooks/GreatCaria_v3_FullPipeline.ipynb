{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# GREAT CARIA v3.0 - Full ML Pipeline\n\n- Grid search hyperparameter tuning\n- Multiple models (LR, RF, XGBoost)\n- Systematic feature ablation with L1/L2\n- Multiple horizons (5, 10, 20 days)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install xgboost -q\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
                "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
                "from xgboost import XGBClassifier\n",
                "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
                "from sklearn.metrics import accuracy_score, roc_auc_score\n",
                "from tqdm.auto import tqdm\n",
                "import matplotlib.pyplot as plt\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "print('Setup complete')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === LOAD DATA ===\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "MARKET_PATH = '/content/drive/MyDrive/CARIA/data/raw/yahoo_market.parquet'\n",
                "df = pd.read_parquet(MARKET_PATH)\n",
                "COUNTRIES = ['USA', 'CHN', 'JPN', 'DEU', 'GBR', 'FRA', 'BRA', 'MEX', 'KOR', 'AUS']\n",
                "print(f'Loaded: {df.shape}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === CRISIS FACTOR ===\n",
                "idx_cols = [f'{c}_index' for c in COUNTRIES if f'{c}_index' in df.columns]\n",
                "ret = df[idx_cols].pct_change().dropna()\n",
                "ret.columns = [c.replace('_index', '') for c in ret.columns]\n",
                "\n",
                "def compute_cf(r, w=20):\n",
                "    cf = []\n",
                "    for i in range(w, len(r)):\n",
                "        wr = r.iloc[i-w:i]\n",
                "        c = wr.corr().values\n",
                "        ac = (c.sum() - len(c)) / (len(c) * (len(c) - 1))\n",
                "        cf.append(ac * wr.std().mean() * 100)\n",
                "    return pd.Series(cf, index=r.index[w:])\n",
                "\n",
                "CF = compute_cf(ret)\n",
                "print(f'CF: {len(CF)} samples')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === FEATURES (extended) ===\n",
                "def build_features(CF, df, ret):\n",
                "    f = pd.DataFrame(index=CF.index)\n",
                "    \n",
                "    # CF features\n",
                "    f['cf'] = CF\n",
                "    f['cf_ma5'] = CF.rolling(5).mean()\n",
                "    f['cf_ma20'] = CF.rolling(20).mean()\n",
                "    f['cf_std5'] = CF.rolling(5).std()\n",
                "    f['cf_change5'] = CF.diff(5)\n",
                "    \n",
                "    # Market features\n",
                "    f['vix'] = df['VIX'].loc[CF.index]\n",
                "    f['vix_ma5'] = df['VIX'].rolling(5).mean().loc[CF.index]\n",
                "    f['dxy'] = df['DXY'].loc[CF.index]\n",
                "    \n",
                "    # Returns features\n",
                "    for c in ['USA', 'BRA', 'CHN']:\n",
                "        if c in ret.columns:\n",
                "            f[f'ret_{c}_5'] = ret[c].rolling(5).mean().loc[CF.index]\n",
                "            f[f'ret_{c}_20'] = ret[c].rolling(20).mean().loc[CF.index]\n",
                "    \n",
                "    return f.dropna()\n",
                "\n",
                "features = build_features(CF, df, ret)\n",
                "print(f'Features: {features.shape}')\n",
                "print(f'Columns: {list(features.columns)}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === TARGETS: Multiple horizons ===\n",
                "HORIZONS = [5, 10, 20]\n",
                "targets = {}\n",
                "for h in HORIZONS:\n",
                "    cf_future = CF.shift(-h)\n",
                "    targets[h] = (cf_future > CF).astype(int).loc[features.index].dropna()\n",
                "    print(f'H={h}: {len(targets[h])} samples, balance={targets[h].mean():.1%}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === PURGED TEMPORAL SPLIT ===\n",
                "PURGE, EMBARGO = 20, 10\n",
                "\n",
                "def purged_split(X, y, train_pct=0.7):\n",
                "    n = len(X)\n",
                "    train_end = int(n * train_pct)\n",
                "    test_start = train_end + PURGE + EMBARGO\n",
                "    \n",
                "    X_train, y_train = X.iloc[:train_end], y.iloc[:train_end]\n",
                "    X_test, y_test = X.iloc[test_start:], y.iloc[test_start:]\n",
                "    \n",
                "    # Normalize\n",
                "    mu, std = X_train.mean(), X_train.std() + 1e-8\n",
                "    X_train = (X_train - mu) / std\n",
                "    X_test = (X_test - mu) / std\n",
                "    \n",
                "    return X_train.values, X_test.values, y_train.values, y_test.values"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === MODEL DEFINITIONS ===\n",
                "models = {\n",
                "    'LogReg_L1': LogisticRegression(penalty='l1', solver='saga', max_iter=1000),\n",
                "    'LogReg_L2': LogisticRegression(penalty='l2', max_iter=1000),\n",
                "    'RandomForest': RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42),\n",
                "    'GradientBoosting': GradientBoostingClassifier(n_estimators=100, max_depth=3, random_state=42),\n",
                "    'XGBoost': XGBClassifier(n_estimators=100, max_depth=3, random_state=42, verbosity=0)\n",
                "}\n",
                "\n",
                "# Grid search params\n",
                "param_grids = {\n",
                "    'LogReg_L1': {'C': [0.01, 0.1, 1.0, 10.0]},\n",
                "    'LogReg_L2': {'C': [0.01, 0.1, 1.0, 10.0]},\n",
                "    'RandomForest': {'n_estimators': [50, 100], 'max_depth': [3, 5, 7]},\n",
                "    'GradientBoosting': {'n_estimators': [50, 100], 'max_depth': [2, 3, 5]},\n",
                "    'XGBoost': {'n_estimators': [50, 100], 'max_depth': [2, 3, 5]}\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === RUN EXPERIMENTS ===\n",
                "results = []\n",
                "\n",
                "for h in HORIZONS:\n",
                "    print(f'\\n=== HORIZON {h} days ===')\n",
                "    y = targets[h]\n",
                "    X = features.loc[y.index]\n",
                "    \n",
                "    X_train, X_test, y_train, y_test = purged_split(X, y)\n",
                "    print(f'Train: {len(X_train)}, Test: {len(X_test)}')\n",
                "    \n",
                "    for name, model in models.items():\n",
                "        # Grid search with time series CV\n",
                "        tscv = TimeSeriesSplit(n_splits=3)\n",
                "        grid = GridSearchCV(model, param_grids[name], cv=tscv, scoring='accuracy', n_jobs=-1)\n",
                "        grid.fit(X_train, y_train)\n",
                "        \n",
                "        best = grid.best_estimator_\n",
                "        y_pred = best.predict(X_test)\n",
                "        acc = accuracy_score(y_test, y_pred)\n",
                "        \n",
                "        # Shuffle test\n",
                "        y_shuffled = np.random.permutation(y_train)\n",
                "        best_shuffle = grid.best_estimator_.__class__(**grid.best_params_)\n",
                "        best_shuffle.fit(X_train, y_shuffled)\n",
                "        acc_shuffle = accuracy_score(y_test, best_shuffle.predict(X_test))\n",
                "        \n",
                "        results.append({\n",
                "            'horizon': h,\n",
                "            'model': name,\n",
                "            'accuracy': acc,\n",
                "            'shuffle_acc': acc_shuffle,\n",
                "            'lift': acc - acc_shuffle,\n",
                "            'best_params': grid.best_params_\n",
                "        })\n",
                "        \n",
                "        print(f'{name}: {acc:.1%} (shuffle: {acc_shuffle:.1%}, lift: {(acc-acc_shuffle)*100:.1f}pp)')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === FEATURE ABLATION (L1 regularization) ===\n",
                "print('\\n=== FEATURE IMPORTANCE (L1) ===')\n",
                "\n",
                "h = 10  # Use 10-day horizon\n",
                "y = targets[h]\n",
                "X = features.loc[y.index]\n",
                "X_train, X_test, y_train, y_test = purged_split(X, y)\n",
                "\n",
                "# Fit L1 model\n",
                "l1 = LogisticRegressionCV(penalty='l1', solver='saga', cv=3, max_iter=1000)\n",
                "l1.fit(X_train, y_train)\n",
                "\n",
                "# Feature importance\n",
                "importance = pd.DataFrame({\n",
                "    'feature': features.columns,\n",
                "    'coef': np.abs(l1.coef_[0])\n",
                "}).sort_values('coef', ascending=False)\n",
                "\n",
                "print('\\nTop features:')\n",
                "print(importance.head(10).to_string(index=False))\n",
                "\n",
                "# Ablation: remove top features one by one\n",
                "print('\\nAblation test:')\n",
                "base_acc = accuracy_score(y_test, l1.predict(X_test))\n",
                "print(f'Full model: {base_acc:.1%}')\n",
                "\n",
                "for feat in importance['feature'].head(5):\n",
                "    X_ablated = X.drop(columns=[feat])\n",
                "    X_tr, X_te, y_tr, y_te = purged_split(X_ablated, y)\n",
                "    l1_abl = LogisticRegression(penalty='l1', solver='saga', C=l1.C_[0], max_iter=1000)\n",
                "    l1_abl.fit(X_tr, y_tr)\n",
                "    abl_acc = accuracy_score(y_te, l1_abl.predict(X_te))\n",
                "    print(f'  Without {feat}: {abl_acc:.1%} (drop: {(base_acc-abl_acc)*100:.1f}pp)')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === SUMMARY ===\n",
                "print('\\n' + '='*60)\n",
                "print('GREAT CARIA v3.0 - FULL RESULTS')\n",
                "print('='*60)\n",
                "\n",
                "df_results = pd.DataFrame(results)\n",
                "print('\\nAll experiments:')\n",
                "print(df_results.to_string(index=False))\n",
                "\n",
                "# Best result\n",
                "best = df_results.loc[df_results['accuracy'].idxmax()]\n",
                "print(f'\\nðŸ† Best: {best[\"model\"]} @ H={best[\"horizon\"]}d')\n",
                "print(f'   Accuracy: {best[\"accuracy\"]:.1%}')\n",
                "print(f'   Lift: {best[\"lift\"]*100:.1f}pp')\n",
                "\n",
                "# Verdict\n",
                "if best['accuracy'] > 0.55 and best['lift'] > 0.03:\n",
                "    print('\\nâœ“ PASSED - Real signal detected')\n",
                "else:\n",
                "    print('\\nâœ— FAILED - Signal is marginal')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === VISUALIZATION ===\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# Accuracy by horizon\n",
                "for h in HORIZONS:\n",
                "    subset = df_results[df_results['horizon'] == h]\n",
                "    axes[0].bar([f'{m}\\n(H={h})' for m in subset['model']], subset['accuracy'])\n",
                "axes[0].axhline(0.5, color='red', linestyle='--', label='Random')\n",
                "axes[0].set_ylabel('Accuracy')\n",
                "axes[0].set_title('Accuracy by Model & Horizon')\n",
                "axes[0].tick_params(axis='x', rotation=45)\n",
                "\n",
                "# Lift by model\n",
                "pivot = df_results.pivot(index='model', columns='horizon', values='lift')\n",
                "pivot.plot(kind='bar', ax=axes[1])\n",
                "axes[1].axhline(0.03, color='green', linestyle='--', label='Min lift (3%)')\n",
                "axes[1].set_ylabel('Lift over shuffle')\n",
                "axes[1].set_title('Lift by Model & Horizon')\n",
                "axes[1].legend()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4"
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}