{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# GREAT CARIA v3.0 - Relatividad General Financiera\n",
                "\n",
                "## La Gran Teoría Unificada: Espacio, Tiempo e Incertidumbre\n",
                "\n",
                "### Marco Teórico\n",
                "\n",
                "**El sistema financiero es un espacio-tiempo curvo donde:**\n",
                "- **Geografía** (G7 vs EM) = Espacio\n",
                "- **Escalas temporales** (Fast/Medium/Slow) = Tiempo\n",
                "- **Incertidumbre H** = Energía de desacople\n",
                "\n",
                "### La Ecuación Maestra\n",
                "\n",
                "$$\\mu_{MSFI}(t) = \\sum_{i} w_i \\cdot s_i(t) \\quad \\text{(Media ponderada)}$$\n",
                "\n",
                "$$H_{temp}(t) = \\sqrt{\\sum_{i} w_i (s_i - \\mu)^2} \\quad \\text{(Dispersión temporal)}$$\n",
                "\n",
                "$$\\Delta_{geo}(t) = |\\sigma^2_{G7} - \\sigma^2_{EM}| \\quad \\text{(Desacople espacial)}$$\n",
                "\n",
                "$$H_{total} = H_{temp} + \\lambda \\cdot \\Delta_{geo} \\quad \\text{(Incertidumbre total)}$$\n",
                "\n",
                "### La Predicción\n",
                "\n",
                "- **H alto** → Sistema desacoplado → Robusto\n",
                "- **H → 0** → Sincronización total → CRISIS"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === SETUP ===\n",
                "!pip install PyWavelets scikit-learn -q\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from scipy import stats, signal\n",
                "import pywt\n",
                "from sklearn.metrics import roc_curve, auc\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "import matplotlib.pyplot as plt\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "print('='*60)\n",
                "print('GREAT CARIA v3.0')\n",
                "print('Relatividad General Financiera: Espacio × Tiempo × Incertidumbre')\n",
                "print('='*60)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === LOAD DATA ===\n",
                "DATA_PATH = '/content/drive/MyDrive/Caria/yahoo_market.parquet'\n",
                "df = pd.read_parquet(DATA_PATH)\n",
                "df.index = pd.to_datetime(df.index)\n",
                "\n",
                "# Geographic blocks\n",
                "G7 = ['USA', 'GBR', 'DEU', 'FRA', 'JPN', 'CAN']  # + ITA but may not be in data\n",
                "EM = ['CHN', 'BRA', 'IND', 'MEX', 'KOR', 'ZAF', 'AUS']\n",
                "\n",
                "# Get available countries\n",
                "all_countries = [c.replace('_index', '') for c in df.columns if '_index' in c]\n",
                "g7_avail = [c for c in G7 if c in all_countries]\n",
                "em_avail = [c for c in EM if c in all_countries]\n",
                "\n",
                "print(f'G7 available: {g7_avail}')\n",
                "print(f'EM available: {em_avail}')\n",
                "\n",
                "# Returns\n",
                "idx_cols = [f'{c}_index' for c in all_countries]\n",
                "ret = df[idx_cols].pct_change().dropna()\n",
                "ret.columns = [c.replace('_index', '') for c in ret.columns]\n",
                "\n",
                "ret_g7 = ret[[c for c in g7_avail if c in ret.columns]]\n",
                "ret_em = ret[[c for c in em_avail if c in ret.columns]]\n",
                "\n",
                "print(f'\\nData: {ret.shape[0]} days')\n",
                "print(f'Period: {ret.index.min().date()} to {ret.index.max().date()}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === CRISIS CATALOG ===\n",
                "CRISES = {\n",
                "    'Lehman': pd.Timestamp('2008-09-15'),\n",
                "    'Flash_Crash': pd.Timestamp('2010-05-06'),\n",
                "    'Euro_Crisis': pd.Timestamp('2011-08-05'),\n",
                "    'Taper_Tantrum': pd.Timestamp('2013-05-22'),\n",
                "    'China_Crash': pd.Timestamp('2015-08-24'),\n",
                "    'Brexit': pd.Timestamp('2016-06-24'),\n",
                "    'Volmageddon': pd.Timestamp('2018-02-05'),\n",
                "    'COVID': pd.Timestamp('2020-03-11'),\n",
                "    'Gilt_Crisis': pd.Timestamp('2022-09-23'),\n",
                "    'SVB': pd.Timestamp('2023-03-10')\n",
                "}\n",
                "CRISES = {k: v for k, v in CRISES.items() if v >= ret.index.min()}\n",
                "print(f'Crises in range: {len(CRISES)}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# PART 1: CRISIS FACTOR (La señal base)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === CRISIS FACTOR (global) ===\n",
                "def compute_cf(r, window=20):\n",
                "    cf = []\n",
                "    for i in range(window, len(r)):\n",
                "        wr = r.iloc[i-window:i]\n",
                "        corr = wr.corr().values\n",
                "        n = len(corr)\n",
                "        avg_corr = (corr.sum() - n) / (n * (n - 1))\n",
                "        avg_vol = wr.std().mean()\n",
                "        cf.append(avg_corr * avg_vol * 100)\n",
                "    return pd.Series(cf, index=r.index[window:])\n",
                "\n",
                "CF = compute_cf(ret)\n",
                "CF_G7 = compute_cf(ret_g7)\n",
                "CF_EM = compute_cf(ret_em)\n",
                "\n",
                "print(f'CF computed: Global, G7, EM')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# PART 2: TEMPORAL DECOMPOSITION (3 Bandas)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === 3-BAND DECOMPOSITION ===\n",
                "def decompose_3bands(series, wavelet='db4'):\n",
                "    coeffs = pywt.wavedec(series.values, wavelet, level=6)\n",
                "    \n",
                "    # Fast (<10d)\n",
                "    fast_c = [np.zeros_like(c) for c in coeffs]\n",
                "    for i in range(min(3, len(coeffs))):\n",
                "        fast_c[i] = coeffs[i]\n",
                "    fast = pywt.waverec(fast_c, wavelet)[:len(series)]\n",
                "    \n",
                "    # Medium (10-60d)\n",
                "    med_c = [np.zeros_like(c) for c in coeffs]\n",
                "    for i in range(3, min(5, len(coeffs))):\n",
                "        med_c[i] = coeffs[i]\n",
                "    medium = pywt.waverec(med_c, wavelet)[:len(series)]\n",
                "    \n",
                "    # Slow (>60d)\n",
                "    slow_c = [np.zeros_like(c) for c in coeffs]\n",
                "    for i in range(5, len(coeffs)):\n",
                "        slow_c[i] = coeffs[i]\n",
                "    slow = pywt.waverec(slow_c, wavelet)[:len(series)]\n",
                "    \n",
                "    return {\n",
                "        'fast': pd.Series(fast, index=series.index),\n",
                "        'medium': pd.Series(medium, index=series.index),\n",
                "        'slow': pd.Series(slow, index=series.index)\n",
                "    }\n",
                "\n",
                "bands = decompose_3bands(CF)\n",
                "print('3-Band decomposition: Fast, Medium, Slow')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# PART 3: GEOGRAPHIC RELATIVITY (Δ_geo)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === GEOGRAPHIC DISPERSION ===\n",
                "def compute_geographic_dispersion(ret_g7, ret_em, window=60):\n",
                "    \"\"\"Δ_geo = |σ²_G7 - σ²_EM| (spatial decoupling)\"\"\"\n",
                "    var_g7 = ret_g7.var(axis=1).rolling(window).mean()\n",
                "    var_em = ret_em.var(axis=1).rolling(window).mean()\n",
                "    delta_geo = (var_g7 - var_em).abs()\n",
                "    return delta_geo, var_g7, var_em\n",
                "\n",
                "DELTA_GEO, VAR_G7, VAR_EM = compute_geographic_dispersion(ret_g7, ret_em)\n",
                "\n",
                "# Visualize\n",
                "fig, axes = plt.subplots(2, 1, figsize=(14, 8), sharex=True)\n",
                "\n",
                "ax1 = axes[0]\n",
                "ax1.plot(VAR_G7.index, VAR_G7.values, 'b-', label='G7', linewidth=1)\n",
                "ax1.plot(VAR_EM.index, VAR_EM.values, 'orange', label='EM', linewidth=1)\n",
                "ax1.set_ylabel('Variance (long scale)')\n",
                "ax1.set_title('Temporal Relativity: G7 vs Emerging Markets (60-250d scale)')\n",
                "ax1.legend()\n",
                "\n",
                "ax2 = axes[1]\n",
                "diff = VAR_G7 - VAR_EM\n",
                "ax2.fill_between(diff.index, diff.values, 0, where=diff > 0, \n",
                "                 alpha=0.5, color='blue', label='G7 higher')\n",
                "ax2.fill_between(diff.index, diff.values, 0, where=diff <= 0, \n",
                "                 alpha=0.5, color='orange', label='EM higher')\n",
                "ax2.axhline(0, color='black', linewidth=0.5)\n",
                "ax2.set_ylabel('G7 - EM')\n",
                "ax2.set_title('Which group perceives risk earlier?')\n",
                "ax2.legend()\n",
                "\n",
                "for ax in axes:\n",
                "    for name, date in CRISES.items():\n",
                "        if date > VAR_G7.index.min() and date < VAR_G7.index.max():\n",
                "            ax.axvline(date, color='gray', alpha=0.3, linestyle=':')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('/content/drive/MyDrive/Caria/great_caria_v3_geographic.png', dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# PART 4: THE CARIA UNCERTAINTY PRINCIPLE (H)\n",
                "\n",
                "$$H_{total} = H_{temp} + \\lambda \\cdot \\Delta_{geo}$$\n",
                "\n",
                "**H alto** = sistema desacoplado = robusto\n",
                "**H → 0** = sincronización = CRISIS"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === PHYSICS-FIRST WEIGHTS ===\n",
                "WEIGHTS = {\n",
                "    'fast': 0.15,   # Noise\n",
                "    'medium': 0.35, # Resonance (critical)\n",
                "    'slow': 0.50    # Structural\n",
                "}\n",
                "\n",
                "print('Temporal weights:')\n",
                "for k, v in WEIGHTS.items():\n",
                "    print(f'  {k}: {v:.0%}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === COMPUTE μ_MSFI (Mean State) ===\n",
                "def normalize(s):\n",
                "    return (s - s.mean()) / (s.std() + 1e-8)\n",
                "\n",
                "# Normalize bands\n",
                "s_fast = normalize(bands['fast'])\n",
                "s_medium = normalize(bands['medium'])\n",
                "s_slow = normalize(bands['slow'])\n",
                "\n",
                "# μ = weighted mean\n",
                "MU = (WEIGHTS['fast'] * s_fast + \n",
                "      WEIGHTS['medium'] * s_medium + \n",
                "      WEIGHTS['slow'] * s_slow)\n",
                "\n",
                "print(f'μ_MSFI computed: mean={MU.mean():.3f}, std={MU.std():.3f}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === COMPUTE H_temp (Temporal Uncertainty) ===\n",
                "def compute_H_temp(s_fast, s_medium, s_slow, mu, weights):\n",
                "    \"\"\"H_temp = sqrt(Σ w_i (s_i - μ)²)\"\"\"\n",
                "    H = np.sqrt(\n",
                "        weights['fast'] * (s_fast - mu)**2 +\n",
                "        weights['medium'] * (s_medium - mu)**2 +\n",
                "        weights['slow'] * (s_slow - mu)**2\n",
                "    )\n",
                "    return H\n",
                "\n",
                "H_TEMP = compute_H_temp(s_fast, s_medium, s_slow, MU, WEIGHTS)\n",
                "print(f'H_temp computed: mean={H_TEMP.mean():.3f}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === COMPUTE H_total ===\n",
                "# H_total = H_temp + λ * Δ_geo\n",
                "\n",
                "# Align indices\n",
                "common_idx = MU.index.intersection(DELTA_GEO.dropna().index)\n",
                "\n",
                "# Normalize Δ_geo to same scale as H_temp\n",
                "delta_geo_norm = normalize(DELTA_GEO.loc[common_idx])\n",
                "h_temp_aligned = H_TEMP.loc[common_idx]\n",
                "mu_aligned = MU.loc[common_idx]\n",
                "\n",
                "# Lambda = sensitivity to geographic decoupling\n",
                "LAMBDA = 0.3  # Can be tuned\n",
                "\n",
                "H_TOTAL = h_temp_aligned + LAMBDA * delta_geo_norm.abs()\n",
                "H_TOTAL = H_TOTAL.clip(lower=0.01)  # Avoid division by zero\n",
                "\n",
                "print(f'H_total computed: mean={H_TOTAL.mean():.3f}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# PART 5: THE PROBABILITY CONE"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === PROBABILITY CONE ===\n",
                "# Upper/Lower = μ ± k * H_total\n",
                "K = 2.0  # Number of standard deviations\n",
                "\n",
                "UPPER = mu_aligned + K * H_TOTAL\n",
                "LOWER = mu_aligned - K * H_TOTAL\n",
                "\n",
                "# The CRISIS INDICATOR: Inverse of H (low H = high danger)\n",
                "# When H collapses, it means synchronization\n",
                "SYNC_DANGER = 1 / (H_TOTAL + 0.1)  # Inverse H\n",
                "\n",
                "print(f'Probability cone computed')\n",
                "print(f'Sync Danger range: [{SYNC_DANGER.min():.2f}, {SYNC_DANGER.max():.2f}]')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === THE CARIA UNCERTAINTY VISUALIZATION ===\n",
                "fig, axes = plt.subplots(3, 1, figsize=(14, 12), sharex=True)\n",
                "\n",
                "# Panel A: Multi-Scale Dynamics\n",
                "ax1 = axes[0]\n",
                "ax1.plot(s_slow.loc[common_idx].index, s_slow.loc[common_idx].values, \n",
                "         'b-', linewidth=1.5, label='Slow (Structure)')\n",
                "ax1.plot(s_medium.loc[common_idx].index, s_medium.loc[common_idx].values, \n",
                "         color='gold', linewidth=1, label='Medium (Resonance)')\n",
                "ax1.plot(s_fast.loc[common_idx].index, s_fast.loc[common_idx].values, \n",
                "         'gray', alpha=0.5, linewidth=0.5, label='Fast (Noise)')\n",
                "ax1.set_ylabel('Stress Level')\n",
                "ax1.set_title('A. Multi-Scale Dynamics (Dissociated vs. Synchronized)')\n",
                "ax1.legend(loc='upper left')\n",
                "\n",
                "# Panel B: The Probability Cone\n",
                "ax2 = axes[1]\n",
                "ax2.fill_between(mu_aligned.index, LOWER.values, UPPER.values, \n",
                "                 alpha=0.3, color='pink', label='Heisenberg Uncertainty (H)')\n",
                "ax2.plot(mu_aligned.index, mu_aligned.values, 'darkred', \n",
                "         linewidth=1.5, label='MSFI (Mean State)')\n",
                "ax2.set_ylabel('Systemic Fragility')\n",
                "ax2.set_title('B. The Caria Uncertainty Principle: Probability Cone')\n",
                "ax2.legend(loc='upper left')\n",
                "\n",
                "# Panel C: Synchronization Danger (1/H)\n",
                "ax3 = axes[2]\n",
                "ax3.fill_between(SYNC_DANGER.index, SYNC_DANGER.values, alpha=0.5, color='red')\n",
                "ax3.plot(SYNC_DANGER.index, SYNC_DANGER.values, 'darkred', linewidth=0.5)\n",
                "threshold = SYNC_DANGER.quantile(0.90)\n",
                "ax3.axhline(threshold, color='orange', linestyle='--', label=f'Danger threshold (90th pct)')\n",
                "ax3.set_ylabel('1/H (Sync Danger)')\n",
                "ax3.set_title('C. Synchronization Danger (When H collapses → Crisis)')\n",
                "ax3.legend()\n",
                "\n",
                "# Add crisis markers\n",
                "for ax in axes:\n",
                "    for name, date in CRISES.items():\n",
                "        if date in common_idx or (date > common_idx.min() and date < common_idx.max()):\n",
                "            ax.axvline(date, color='blue', alpha=0.3, linestyle=':')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('/content/drive/MyDrive/Caria/great_caria_v3_uncertainty.png', dpi=200)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# PART 6: THE INTEGRATED FRAGILITY INDEX v3\n",
                "\n",
                "$$IFI_{v3} = \\mu_{MSFI} \\times \\frac{1}{H_{total}} = \\frac{\\mu}{H}$$\n",
                "\n",
                "This combines:\n",
                "- **High μ** = high stress\n",
                "- **Low H** = synchronization\n",
                "\n",
                "Both conditions must be met for crisis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === IFI v3: μ / H ===\n",
                "# Raw: μ * (1/H)\n",
                "# But we want high values = danger, so:\n",
                "# If μ > 0: divide by H (low H = high danger)\n",
                "# We use a modified formula to handle negative μ\n",
                "\n",
                "# Shift μ to be positive (add offset)\n",
                "mu_positive = mu_aligned - mu_aligned.min() + 0.1\n",
                "\n",
                "# IFI = μ * (1/H) = μ / H\n",
                "IFI_v3 = mu_positive / H_TOTAL\n",
                "\n",
                "# Normalize to [0, 1]\n",
                "IFI_v3_norm = (IFI_v3 - IFI_v3.min()) / (IFI_v3.max() - IFI_v3.min())\n",
                "\n",
                "print(f'IFI v3 computed: range=[{IFI_v3_norm.min():.3f}, {IFI_v3_norm.max():.3f}]')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === VALIDATE IFI v3 ===\n",
                "\n",
                "# Crisis labels\n",
                "def create_crisis_labels(index, crises, pre=20, post=10):\n",
                "    labels = pd.Series(0, index=index)\n",
                "    for name, date in crises.items():\n",
                "        start = date - pd.Timedelta(days=pre)\n",
                "        end = date + pd.Timedelta(days=post)\n",
                "        labels[(labels.index >= start) & (labels.index <= end)] = 1\n",
                "    return labels\n",
                "\n",
                "y_true = create_crisis_labels(IFI_v3_norm.index, CRISES)\n",
                "\n",
                "# Compare models\n",
                "cf_aligned = CF.loc[IFI_v3_norm.index]\n",
                "cf_norm = (cf_aligned - cf_aligned.min()) / (cf_aligned.max() - cf_aligned.min())\n",
                "\n",
                "models = {\n",
                "    'IFI v3 (μ/H)': IFI_v3_norm,\n",
                "    'CF Only': cf_norm,\n",
                "    '1/H (Sync Danger)': (SYNC_DANGER - SYNC_DANGER.min()) / (SYNC_DANGER.max() - SYNC_DANGER.min())\n",
                "}\n",
                "\n",
                "# ROC\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "ax1 = axes[0]\n",
                "auc_results = {}\n",
                "for name, score in models.items():\n",
                "    fpr, tpr, _ = roc_curve(y_true, score)\n",
                "    roc_auc = auc(fpr, tpr)\n",
                "    auc_results[name] = roc_auc\n",
                "    ax1.plot(fpr, tpr, label=f'{name} (AUC={roc_auc:.3f})', linewidth=2)\n",
                "\n",
                "ax1.plot([0, 1], [0, 1], 'k--')\n",
                "ax1.set_xlabel('False Positive Rate')\n",
                "ax1.set_ylabel('True Positive Rate')\n",
                "ax1.set_title('ROC Curves: IFI v3 vs Baselines')\n",
                "ax1.legend(loc='lower right')\n",
                "ax1.grid(True, alpha=0.3)\n",
                "\n",
                "# AUC bar\n",
                "ax2 = axes[1]\n",
                "colors = ['#10b981' if v == max(auc_results.values()) else '#6b7280' \n",
                "          for v in auc_results.values()]\n",
                "ax2.barh(list(auc_results.keys()), list(auc_results.values()), color=colors)\n",
                "ax2.axvline(0.5, color='red', linestyle='--')\n",
                "ax2.set_xlabel('AUC')\n",
                "ax2.set_xlim(0.4, 0.9)\n",
                "ax2.set_title('AUC Comparison')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('/content/drive/MyDrive/Caria/great_caria_v3_roc.png', dpi=150)\n",
                "plt.show()\n",
                "\n",
                "print('\\n=== AUC Results ===')\n",
                "for name, score in sorted(auc_results.items(), key=lambda x: -x[1]):\n",
                "    print(f'{name:20s}: {score:.3f}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === FINAL VISUALIZATION ===\n",
                "fig, axes = plt.subplots(4, 1, figsize=(14, 14), sharex=True)\n",
                "\n",
                "# A. IFI v3\n",
                "ax1 = axes[0]\n",
                "ax1.fill_between(IFI_v3_norm.index, IFI_v3_norm.values, alpha=0.5, color='red')\n",
                "ax1.plot(IFI_v3_norm.index, IFI_v3_norm.values, 'darkred', linewidth=0.5)\n",
                "ax1.axhline(IFI_v3_norm.quantile(0.75), color='orange', linestyle='--', label='Warning (75%)')\n",
                "ax1.axhline(IFI_v3_norm.quantile(0.95), color='red', linestyle='--', label='Critical (95%)')\n",
                "ax1.set_ylabel('IFI v3')\n",
                "ax1.set_title(f'A. Integrated Fragility Index v3 (μ/H) - AUC={auc_results.get(\"IFI v3 (μ/H)\", 0):.3f}')\n",
                "ax1.legend(loc='upper right')\n",
                "\n",
                "# B. Uncertainty H\n",
                "ax2 = axes[1]\n",
                "ax2.fill_between(H_TOTAL.index, H_TOTAL.values, alpha=0.5, color='purple')\n",
                "ax2.plot(H_TOTAL.index, H_TOTAL.values, 'purple', linewidth=0.5)\n",
                "ax2.set_ylabel('H (Uncertainty)')\n",
                "ax2.set_title('B. System Uncertainty (High = Decoupled = Robust)')\n",
                "\n",
                "# C. Geographic Delta\n",
                "ax3 = axes[2]\n",
                "ax3.fill_between(DELTA_GEO.loc[common_idx].index, \n",
                "                 DELTA_GEO.loc[common_idx].values, \n",
                "                 alpha=0.5, color='blue')\n",
                "ax3.set_ylabel('Δ_geo')\n",
                "ax3.set_title('C. Geographic Decoupling |G7 - EM|')\n",
                "\n",
                "# D. S&P 500 with warnings\n",
                "ax4 = axes[3]\n",
                "if 'USA_index' in df.columns:\n",
                "    sp500 = df['USA_index'].loc[common_idx]\n",
                "    ax4.plot(sp500.index, sp500.values, 'k-', linewidth=0.5)\n",
                "    \n",
                "    # Add danger zones\n",
                "    danger_threshold = IFI_v3_norm.quantile(0.90)\n",
                "    danger_periods = IFI_v3_norm > danger_threshold\n",
                "    ax4.fill_between(IFI_v3_norm.index, sp500.min(), sp500.max(),\n",
                "                     where=danger_periods, alpha=0.3, color='red')\n",
                "\n",
                "ax4.set_ylabel('S&P 500')\n",
                "ax4.set_title('D. Market with Danger Zones (IFI > 90th pct)')\n",
                "ax4.set_yscale('log')\n",
                "\n",
                "# Crisis lines\n",
                "for ax in axes:\n",
                "    for name, date in CRISES.items():\n",
                "        if date > common_idx.min() and date < common_idx.max():\n",
                "            ax.axvline(date, color='blue', alpha=0.3, linestyle=':')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('/content/drive/MyDrive/Caria/great_caria_v3_final.png', dpi=200, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === PRE-CRISIS ANALYSIS ===\n",
                "print('\\n=== Pre-Crisis Analysis (20 days before) ===')\n",
                "\n",
                "def get_pre_value(series, date, days=20):\n",
                "    pre = series[(series.index < date) & \n",
                "                 (series.index > date - pd.Timedelta(days=days))]\n",
                "    return pre.mean() if len(pre) > 0 else np.nan\n",
                "\n",
                "results = []\n",
                "for name, date in CRISES.items():\n",
                "    if date < common_idx.min() + pd.Timedelta(days=200) or date > common_idx.max():\n",
                "        continue\n",
                "    \n",
                "    results.append({\n",
                "        'Crisis': name,\n",
                "        'Date': date.date(),\n",
                "        'IFI_v3': get_pre_value(IFI_v3_norm, date),\n",
                "        'H_total': get_pre_value(H_TOTAL, date),\n",
                "        'CF': get_pre_value(cf_norm, date)\n",
                "    })\n",
                "\n",
                "results_df = pd.DataFrame(results)\n",
                "print(results_df.to_string(index=False))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === EXPORT ===\n",
                "import json\n",
                "from datetime import datetime\n",
                "\n",
                "# Current state\n",
                "current = {\n",
                "    'ifi_v3': float(IFI_v3_norm.iloc[-1]),\n",
                "    'mu': float(mu_aligned.iloc[-1]),\n",
                "    'H_total': float(H_TOTAL.iloc[-1]),\n",
                "    'H_temp': float(h_temp_aligned.iloc[-1]),\n",
                "    'delta_geo': float(DELTA_GEO.iloc[-1]),\n",
                "    'cf': float(CF.iloc[-1])\n",
                "}\n",
                "\n",
                "# Status based on IFI v3\n",
                "if current['ifi_v3'] >= IFI_v3_norm.quantile(0.95):\n",
                "    status = 'CRITICAL'\n",
                "elif current['ifi_v3'] >= IFI_v3_norm.quantile(0.75):\n",
                "    status = 'WARNING'\n",
                "else:\n",
                "    status = 'STABLE'\n",
                "\n",
                "export = {\n",
                "    'version': 'Great Caria v3.0 (General Financial Relativity)',\n",
                "    'generated': datetime.now().isoformat(),\n",
                "    'theory': 'IFI = μ/H where μ=mean fragility, H=uncertainty (temporal + geographic)',\n",
                "    'status': status,\n",
                "    'current': current,\n",
                "    'thresholds': {\n",
                "        'warning': float(IFI_v3_norm.quantile(0.75)),\n",
                "        'critical': float(IFI_v3_norm.quantile(0.95))\n",
                "    },\n",
                "    'auc_scores': auc_results,\n",
                "    'crises_validated': len(results_df),\n",
                "    'interpretation': {\n",
                "        'high_H': 'System decoupled (G7/EM divergent, scales divergent) = ROBUST',\n",
                "        'low_H': 'System synchronized (all aligned) = CRISIS IMMINENT'\n",
                "    }\n",
                "}\n",
                "\n",
                "with open('/content/drive/MyDrive/Caria/great_caria_v3.json', 'w') as f:\n",
                "    json.dump(export, f, indent=2)\n",
                "\n",
                "print('\\n' + '='*60)\n",
                "print('GREAT CARIA v3.0 - FINAL SUMMARY')\n",
                "print('='*60)\n",
                "print(json.dumps(export, indent=2))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}