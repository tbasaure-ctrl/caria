{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "intro_v4_unified"
            },
            "source": [
                "# GREAT CARIA v4: UNIFIED FIELD THEORY (Final)\n",
                "\n",
                "## The Synthesis of Empirical Power and Theoretical Elegance\n",
                "\n",
                "**Objective:** Restore peak predictive performance (AUC > 0.705) while maintaining the \"General Financial Relativity\" theoretical framework.\n",
                "\n",
                "### The Unified Field Equation $\\Psi(t)$\n",
                "\n",
                "We define the Market Stress Wavefunction as the ratio of **Systemic Mass** (Consensus) to **Spacetime Uncertainty** (Dispersion), modulated by **Geographic Spin**.\n",
                "\n",
                "$$ \\Psi(t) = \\frac{\\mu(t) \\times \\text{Spin}(t)}{\\sqrt{H(t)^2 + \\hbar^2}} $$\n",
                "\n",
                "Where:\n",
                "1.  **Mass ($\\mu$)**: The **Crisis Factor (CF)**. Empirically the strongest signal (Correlation $\\times$ Volatility). Represents the \"gravitational pull\" of the market crash.\n",
                "2.  **Uncertainty ($H$)**: **3-Band Dispersion**. The divergence between Fast, Medium, and Slow temporal scales. Low $H$ = \"Synchronization\" (Danger).\n",
                "3.  **Spin**: **Geographic Relativity**. A risk multiplier. If G7 volatility > EM volatility, the system is fundamentally more unstable (Spin > 1.0).\n",
                "4.  **$\\hbar$**: Financial Planck Constant. The minimum uncertainty limit to prevent singularities.\n",
                "\n",
                "### The Event Horizon\n",
                "The \"Event Horizon\" is visualized when the **Probability Cone** (defined by $\\mu \\pm k \\cdot H$) narrows below the Schwarzschild Radius ($R_s$). This corresponds to a state of **Critical Synchronization** where alternative futures collapse into a single crisis trajectory."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "setup_v4"
            },
            "outputs": [],
            "source": [
                "# === SETUP ===\n",
                "!pip install PyWavelets scikit-learn numpy pandas scipy matplotlib -q\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from scipy import stats, signal\n",
                "import pywt\n",
                "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
                "from sklearn.metrics import roc_curve, auc\n",
                "import matplotlib.pyplot as plt\n",
                "import warnings\n",
                "import json\n",
                "from datetime import datetime\n",
                "\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "print('='*80)\n",
                "print('GREAT CARIA v4: UNIFIED FIELD THEORY')\n",
                "print('Synthesizing Empirical CF with Relativistic H')\n",
                "print('='*80)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "load_data_v4"
            },
            "outputs": [],
            "source": [
                "# === LOAD DATA ===\n",
                "DATA_PATH = '/content/drive/MyDrive/Caria/yahoo_market.parquet'\n",
                "try:\n",
                "    df = pd.read_parquet(DATA_PATH)\n",
                "except FileNotFoundError:\n",
                "    # Fallback path if folder structure differs\n",
                "    DATA_PATH = '/content/drive/MyDrive/CARIA/data/raw/yahoo_market.parquet'\n",
                "    df = pd.read_parquet(DATA_PATH)\n",
                "\n",
                "df.index = pd.to_datetime(df.index)\n",
                "\n",
                "# Geographic Blocks\n",
                "G7_COUNTRIES = ['USA', 'GBR', 'DEU', 'FRA', 'JPN', 'CAN']\n",
                "EM_COUNTRIES = ['CHN', 'BRA', 'IND', 'MEX', 'KOR', 'ZAF', 'AUS'] # adding AUS to EM block for commodity sensitivity\n",
                "\n",
                "# Extract Indices\n",
                "all_cols = [c for c in df.columns if '_index' in c]\n",
                "ret = df[all_cols].pct_change().dropna()\n",
                "ret.columns = [c.replace('_index', '') for c in ret.columns]\n",
                "\n",
                "# Separate Blocks\n",
                "g7_cols = [c for c in G7_COUNTRIES if c in ret.columns]\n",
                "em_cols = [c for c in EM_COUNTRIES if c in ret.columns]\n",
                "\n",
                "ret_g7 = ret[g7_cols]\n",
                "ret_em = ret[em_cols]\n",
                "\n",
                "print(f'Data: {ret.shape[0]} days')\n",
                "print(f'G7 Block: {g7_cols}')\n",
                "print(f'EM Block: {em_cols}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "ground_truth_v4"
            },
            "outputs": [],
            "source": [
                "# === GROUND TRUTH: CRISIS CATALOG ===\n",
                "CRISES = {\n",
                "    'Lehman': pd.Timestamp('2008-09-15'),\n",
                "    'Flash_Crash': pd.Timestamp('2010-05-06'),\n",
                "    'Euro_Crisis': pd.Timestamp('2011-08-05'),\n",
                "    'China_Crash': pd.Timestamp('2015-08-24'),\n",
                "    'Brexit': pd.Timestamp('2016-06-24'),\n",
                "    'Volmageddon': pd.Timestamp('2018-02-05'),\n",
                "    'COVID': pd.Timestamp('2020-03-11'),\n",
                "    'Gilt_Crisis': pd.Timestamp('2022-09-23'),\n",
                "    'SVB': pd.Timestamp('2023-03-10')\n",
                "}\n",
                "\n",
                "# Filter crises in data range\n",
                "CRISES = {k: v for k, v in CRISES.items() if v >= ret.index.min() and v <= ret.index.max()}\n",
                "print(f'Valid Crises for Validation: {len(CRISES)}')\n",
                "for k, v in CRISES.items():\n",
                "    print(f'  - {k}: {v.date()}')\n",
                "\n",
                "# Binary Target for AUC\n",
                "def create_crisis_labels(index, crises, pre_window=20, post_window=10):\n",
                "    labels = pd.Series(0, index=index)\n",
                "    for name, date in crises.items():\n",
                "        start = date - pd.Timedelta(days=pre_window)\n",
                "        end = date + pd.Timedelta(days=post_window)\n",
                "        labels[(labels.index >= start) & (labels.index <= end)] = 1\n",
                "    return labels\n",
                "\n",
                "y_true = create_crisis_labels(ret.index, CRISES)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "mass_cf"
            },
            "source": [
                "---\n",
                "## Part 1: Systemic Mass ($\\mu$) - The Crisis Factor\n",
                "Total market stress is defined by mass $\\mu$, which is the product of **Correlation** and **Volatility**.\n",
                "High $\\mu$ means the market is both moving violently AND moving together (heavy object falling)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "calc_cf"
            },
            "outputs": [],
            "source": [
                "def compute_cf(r, window=20):\n",
                "    \"\"\"Crisis Factor (Mass) = avg_correlation * avg_volatility\"\"\"\n",
                "    cf = []\n",
                "    for i in range(window, len(r)):\n",
                "        wr = r.iloc[i-window:i]\n",
                "        corr_matrix = wr.corr().values\n",
                "        n = len(corr_matrix)\n",
                "        # Average off-diagonal correlation\n",
                "        avg_corr = (corr_matrix.sum() - n) / (n * (n - 1))\n",
                "        # Average volatility\n",
                "        avg_vol = wr.std().mean()\n",
                "        # CF Signal\n",
                "        cf.append(avg_corr * avg_vol * 100)\n",
                "    return pd.Series(cf, index=r.index[window:])\n",
                "\n",
                "MU = compute_cf(ret)\n",
                "# Normalize Mass [0, 1] for physics equations\n",
                "MU_NORM = (MU - MU.min()) / (MU.max() - MU.min())\n",
                "\n",
                "print(f'Systemic Mass (CF) computed. Mean: {MU.mean():.4f}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "uncertainty_h"
            },
            "source": [
                "---\n",
                "## Part 2: Uncertainty ($H$) - 3-Band Dispersion\n",
                "Uncertainty corresponds to the **Dispersion** of market signals across time scales.\n",
                "- **High $H$**: Signals are scattered. Fast, Medium, and Slow traders disagree. (Stable)\n",
                "- **Low $H$**: Signals align. Synchronization across timescales. (Danger)\n",
                "\n",
                "We use wavelet decomposition (Slow, Medium, Fast) and calculate the standard deviation between them."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "calc_h"
            },
            "outputs": [],
            "source": [
                "def compute_uncertainty_h(series, wavelet='db4'):\n",
                "    \"\"\"H = Dispersion between temporal bands\"\"\"\n",
                "    # Decompose\n",
                "    coeffs = pywt.wavedec(series.values, wavelet, level=6)\n",
                "    \n",
                "    # Reconstruct 3 Bands\n",
                "    # Fast: levels 0-2\n",
                "    fast = pywt.waverec([coeffs[0], coeffs[1], coeffs[2]] + [np.zeros_like(c) for c in coeffs[3:]], wavelet)[:len(series)]\n",
                "    # Medium: levels 3-4\n",
                "    med = pywt.waverec([np.zeros_like(c) for c in coeffs[:3]] + [coeffs[3], coeffs[4]] + [np.zeros_like(c) for c in coeffs[5:]], wavelet)[:len(series)]\n",
                "    # Slow: levels 5+\n",
                "    slow = pywt.waverec([np.zeros_like(c) for c in coeffs[:5]] + [coeffs[5], coeffs[6]], wavelet)[:len(series)]\n",
                "    \n",
                "    # Calculate Dispersion (Standard Deviation across bands at each t)\n",
                "    bands = np.vstack([fast, med, slow])\n",
                "    dispersion = np.std(bands, axis=0)\n",
                "    \n",
                "    return pd.Series(dispersion, index=series.index)\n",
                "\n",
                "H = compute_uncertainty_h(MU_NORM)\n",
                "\n",
                "# Planck Constant (min uncertainty)\n",
                "H_BAR = H.quantile(0.05)\n",
                "print(f'Uncertainty (H) computed. Planck Constant (h_bar): {H_BAR:.4f}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "spin_geo"
            },
            "source": [
                "---\n",
                "## Part 3: Geographic Spin - The Risk Multiplier\n",
                "Relativity dictates that the observer's frame matters. In global finance, the stability of the G7 Core is the reference frame.\n",
                "- **Normal State**: EM Volatility > G7 Volatility. (Spin $\\approx$ 1.0). Risk is standard.\n",
                "- **Crisis State**: G7 Volatility > EM Volatility. (Spin > 1.0). The core is unstable. Risk is multiplied.\n",
                "\n",
                "$$ \\text{Spin}(t) = 1 + \\alpha \\cdot \\max(0, \\sigma^2_{G7} - \\sigma^2_{EM}) $$"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "calc_spin"
            },
            "outputs": [],
            "source": [
                "def compute_spin(g7, em, window=60, alpha=5.0):\n",
                "    \"\"\"Calculate Spin Multiplier\"\"\"\n",
                "    vol_g7 = g7.std(axis=1).rolling(window).mean()\n",
                "    vol_em = em.std(axis=1).rolling(window).mean()\n",
                "    \n",
                "    # Difference (G7 - EM)\n",
                "    diff = vol_g7 - vol_em\n",
                "    \n",
                "    # Only penalize if G7 > EM (diff > 0)\n",
                "    # We normalize diff to be meaningful\n",
                "    # We assume 'alpha' is the sensitivity parameter\n",
                "    \n",
                "    spin_term = diff.apply(lambda x: max(0, x))\n",
                "    \n",
                "    # Spin starts at 1.0 and increases when G7 is unstable\n",
                "    # We scale spin_term by a factor to make it impactful (e.g. 10x the raw var difference)\n",
                "    spin = 1 + (spin_term * alpha)\n",
                "    \n",
                "    return spin\n",
                "\n",
                "# Use smaller window for spin to capture shock\n",
                "SPIN = compute_spin(ret_g7, ret_em, window=40, alpha=20.0)\n",
                "SPIN = SPIN.reindex(MU.index).fillna(1.0)\n",
                "\n",
                "print(f'Geographic Spin computed. Max Spin: {SPIN.max():.2f} (during G7 instability)')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "unified_field"
            },
            "source": [
                "---\n",
                "## Part 4: The Unified Field $\\Psi(t)$ and Event Horizon\n",
                "\n",
                "$$ \\Psi(t) = \\frac{\\mu(t) \\cdot \\text{Spin}(t)}{\\sqrt{H(t)^2 + \\hbar^2}} $$\n",
                "\n",
                "- The denominator $\\sqrt{H^2 + \\hbar^2}$ represents the \"Lorentzian width\" of the probability cone.\n",
                "- As $H \\to 0$, the cone narrows. $\\Psi$ spikes.\n",
                "- $\\text{Spin}$ amplifies the mass when the G7 core is shaking."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "calc_psi"
            },
            "outputs": [],
            "source": [
                "# === CALCULATE PSI ===\n",
                "denominator = np.sqrt(H**2 + H_BAR**2)\n",
                "PSI = (MU_NORM * SPIN) / denominator\n",
                "\n",
                "# Smooth slightly to remove daily noise\n",
                "PSI = PSI.rolling(5).mean()\n",
                "\n",
                "# Replace infs if any\n",
                "PSI = PSI.replace([np.inf, -np.inf], np.nan).fillna(method='ffill')\n",
                "\n",
                "print(f'Psi Calculated. Range: {PSI.min():.2f} to {PSI.max():.2f}')\n",
                "\n",
                "# === EVENT HORIZON CONDITION ===\n",
                "# Horizon is breached when Uncertainty is critically low relative to Mass\n",
                "# We define 'Cone Width' as H(t)\n",
                "# Schwarzschild Radius (Rs) is the critical width\n",
                "\n",
                "Rs = H.quantile(0.10) # 10th percentile of uncertainty\n",
                "\n",
                "EVENT_HORIZON = (H < Rs).astype(int)\n",
                "print(f'Event Horizon Radius (Rs): {Rs:.4f}')\n",
                "print(f'Time inside Event Horizon: {EVENT_HORIZON.sum()} days ({EVENT_HORIZON.mean()*100:.1f}%)')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "validation"
            },
            "source": [
                "---\n",
                "## Part 5: Validation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "valid_auc"
            },
            "outputs": [],
            "source": [
                "# Align Data\n",
                "valid_idx = y_true.index.intersection(PSI.dropna().index)\n",
                "y_test = y_true.loc[valid_idx]\n",
                "psi_test = PSI.loc[valid_idx]\n",
                "h_test = H.loc[valid_idx]\n",
                "mu_test = MU_NORM.loc[valid_idx]\n",
                "\n",
                "# Baseline: Raw Volatility\n",
                "vol_test = ret.std(axis=1).rolling(20).mean().loc[valid_idx]\n",
                "\n",
                "# Compare Models\n",
                "results = {}\n",
                "for name, score in [\n",
                "    ('Great Caria v4 (Psi)', psi_test),\n",
                "    #('Event Horizon Only (1/H)', 1/(h_test + 0.001)), # Simple inverse H\n",
                "    ('Mass Only (CF)', mu_test),\n",
                "    ('Volatility (Baseline)', vol_test)\n",
                "]:\n",
                "    fpr, tpr, _ = roc_curve(y_test, score.fillna(0))\n",
                "    roc_auc = auc(fpr, tpr)\n",
                "    results[name] = roc_auc\n",
                "    \n",
                "print('=== PREDICTIVE POWER (AUC) ===')\n",
                "for name, res in sorted(results.items(), key=lambda x: -x[1]):\n",
                "    print(f'{name:25s}: {res:.3f}')\n",
                "\n",
                "# Plot ROC\n",
                "plt.figure(figsize=(8, 6))\n",
                "for name in results.keys():\n",
                "    score = [psi_test, 1/h_test, mu_test, vol_test]\n",
                "    # Re-calc for plot loop simplicity\n",
                "    s = psi_test if name == 'Great Caria v4 (Psi)' else (mu_test if name == 'Mass Only (CF)' else vol_test)\n",
                "    fpr, tpr, _ = roc_curve(y_test, s.fillna(0))\n",
                "    plt.plot(fpr, tpr, label=f'{name} (AUC={results[name]:.3f})')\n",
                "plt.plot([0, 1], [0, 1], 'k--')\n",
                "plt.xlabel('False Positive Rate')\n",
                "plt.ylabel('True Positive Rate')\n",
                "plt.title('Great Caria v4 Validation')\n",
                "plt.legend(loc='lower right')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "visualization"
            },
            "source": [
                "---\n",
                "## Part 6: Relativistic Visualization (The Cone)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "viz_cone"
            },
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(3, 1, figsize=(15, 12), sharex=True)\n",
                "\n",
                "# 1. Mass and Spin\n",
                "ax1 = axes[0]\n",
                "ax1.plot(MU.index, MU_NORM, color='blue', label='Mass (CF)', alpha=0.7)\n",
                "ax1.plot(SPIN.index, (SPIN-1), color='purple', label='Spin Bonus (G7 Risk)', alpha=0.5)\n",
                "ax1.set_title('Component 1: Mass & Spin')\n",
                "ax1.legend()\n",
                "\n",
                "# 2. The Probability Cone (Uncertainty)\n",
                "ax2 = axes[1]\n",
                "mean_line = pd.Series(0, index=H.index)\n",
                "# Cone Boundary\n",
                "ax2.fill_between(H.index, -H, H, color='green', alpha=0.2, label='Probability Cone (W = 2H)')\n",
                "# Event Horizon Zone (Black)\n",
                "horizon_mask = H < Rs\n",
                "ax2.fill_between(H.index, -0.5, 0.5, where=horizon_mask, color='black', alpha=0.3, label='Event Horizon (Collapsed)')\n",
                "ax2.set_ylim(-0.5, 0.5)\n",
                "ax2.set_title(f'Component 2: Spacetime Uncertainty (Event Horizon at W < {Rs:.3f})')\n",
                "ax2.legend(loc='upper right')\n",
                "\n",
                "# 3. Final Wavefunction Psi\n",
                "ax3 = axes[2]\n",
                "ax3.plot(PSI.index, PSI, color='red', linewidth=1.5, label='Psi(t) - Collapse Probability')\n",
                "# Thresholds\n",
                "thresh_crit = PSI.quantile(0.95)\n",
                "thresh_warn = PSI.quantile(0.80)\n",
                "ax3.axhline(thresh_crit, color='darkred', linestyle='--', label='Critical')\n",
                "ax3.axhline(thresh_warn, color='orange', linestyle='--', label='Warning')\n",
                "\n",
                "ax3.set_title(f'Great Caria v4: Unified Field (AUC = {results[\"Great Caria v4 (Psi)\"]:.3f})')\n",
                "ax3.legend()\n",
                "\n",
                "# Mark Crises\n",
                "for ax in axes:\n",
                "    for name, date in CRISES.items():\n",
                "        ax.axvline(date, color='black', linestyle=':', alpha=0.5)\n",
                "        if ax == axes[0]:\n",
                "            ax.text(date, 1.05, name, rotation=90, verticalalignment='bottom', fontsize=8)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('/content/drive/MyDrive/Caria/great_caria_v4_unified.png', dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "export_json"
            },
            "outputs": [],
            "source": [
                "# === EXPORT ===\n",
                "latest_date = df.index[-1]\n",
                "current_psi = PSI.iloc[-1]\n",
                "current_h = H.iloc[-1]\n",
                "in_horizon = current_h < Rs\n",
                "\n",
                "status = \"STABLE\"\n",
                "if current_psi > thresh_crit: status = \"CRITICAL\"\n",
                "elif current_psi > thresh_warn: status = \"WARNING\"\n",
                "\n",
                "export_data = {\n",
                "    \"version\": \"v4.0 (Unified Field)\",\n",
                "    \"generated_at\": datetime.now().isoformat(),\n",
                "    \"last_market_date\": latest_date.strftime('%Y-%m-%d'),\n",
                "    \"status\": status,\n",
                "    \"metrics\": {\n",
                "        \"psi\": float(current_psi),\n",
                "        \"mass_cf\": float(MU.iloc[-1]),\n",
                "        \"uncertainty_h\": float(current_h),\n",
                "        \"spin\": float(SPIN.iloc[-1])\n",
                "    },\n",
                "    \"event_horizon\": {\n",
                "        \"is_inside\": bool(in_horizon),\n",
                "        \"schwarzschild_radius\": float(Rs),\n",
                "        \"current_width\": float(current_h)\n",
                "    },\n",
                "    \"thresholds\": {\n",
                "        \"warning\": float(thresh_warn),\n",
                "        \"critical\": float(thresh_crit)\n",
                "    },\n",
                "    \"auc_score\": float(results['Great Caria v4 (Psi)']),\n",
                "    \"history\": {\n",
                "        \"dates\": [d.strftime('%Y-%m-%d') for d in PSI.index[-100:]],\n",
                "        \"psi\": PSI.iloc[-100:].tolist(),\n",
                "        \"upper_cone\": H.iloc[-100:].tolist(),\n",
                "        \"lower_cone\": (-H.iloc[-100:]).tolist()\n",
                "    }\n",
                "}\n",
                "\n",
                "with open('/content/drive/MyDrive/Caria/great_caria_v4.json', 'w') as f:\n",
                "    json.dump(export_data, f, indent=2)\n",
                "\n",
                "print(\"Exported v4 JSON successfully.\")"
            ]
        }
    ],
    "metadata": {
        "colab": {
            "name": "GreatCaria_v4_Unified.ipynb",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}